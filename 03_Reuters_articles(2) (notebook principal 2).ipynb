{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jeu de données 1 : Reuters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## titre + corps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dans ce notebook, on fait la même chose que précédemment, en ajoutant le titre au corps de l'article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 indique que ce n'est pas un spam\n",
    "# 1 indique que c'est un spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture du jeu de données et comptes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReutersSGMLParser():\n",
    "    \"\"\"A helper class for parsing Reuters-21578 XGML file formats\"\"\"\n",
    "    def __init__(self):\n",
    "        self.bad_char_pattern = re.compile(r\"&#\\d*;\")\n",
    "        self.document_pattern = re.compile(r\"<REUTERS.*?<\\/REUTERS>\", re.S)\n",
    "        self.date_pattern = re.compile(r'[0-9]+-[A-Z]{3}-[0-9]{4} *[0-9]{2}:[0-9]{2}:[0-9]{2}\\.[0-9]+')\n",
    "\n",
    "    def empty_row(self):\n",
    "        \"\"\"Get an empty rows which can be transformed into a dataframe\"\"\"\n",
    "        rows = {\n",
    "            'old_id'     : [],\n",
    "            'new_id'     : [],\n",
    "            'has_topics' : [],\n",
    "            'date'       : [],\n",
    "            'topics'     : [],\n",
    "            'places'     : [],\n",
    "            'people'     : [],\n",
    "            'orgs'       : [],\n",
    "            'exchanges'  : [],\n",
    "            'companies'  : [],\n",
    "            'title'      : [],\n",
    "            'dateline'   : [],\n",
    "            'body'       : [],\n",
    "            'author'     : [],\n",
    "            'cgi_split'  : [],\n",
    "            'lewis_split': []\n",
    "        }\n",
    "        return rows\n",
    "\n",
    "    def get_text(self, elem, tagname, d_tag = False):\n",
    "        \"\"\"Get the text of a tag or empty string\"\"\"\n",
    "        txt = getattr(elem, tagname, '')\n",
    "        if txt == '':\n",
    "            return ''\n",
    "        if d_tag:\n",
    "            txt = txt.D\n",
    "        txt = txt.text.strip()\n",
    "        return txt\n",
    "\n",
    "    def get_date(self, elem, tagname):\n",
    "        \"\"\"Get the datetime of a tag or empty string\"\"\"\n",
    "        date_str = getattr(elem, tagname, '')\n",
    "        if date_str == '':\n",
    "            return ''\n",
    "        date_str = date_str.text.strip()\n",
    "        try:\n",
    "            date_str = self.date_pattern.findall(date_str)[0]\n",
    "        except IndexError as ie:\n",
    "            print('Cannot find date patter in: %s' % date_str)\n",
    "            return ''\n",
    "        date = datetime.strptime(date_str, '%d-%b-%Y %H:%M:%S.%f')\n",
    "        return date\n",
    "\n",
    "    def parse_header(self, rows, doc):\n",
    "        \"\"\"parse the header.\n",
    "        e.g. <REUTERS TOPICS=\"YES\" LEWISSPLIT=\"TRAIN\" CGISPLIT=\"TRAINING-SET\" OLDID=\"5544\" NEWID=\"1\">\"\"\"\n",
    "        items = dict(doc.items())\n",
    "        rows[   'old_id'  ].append(items.get('OLDID', ''))\n",
    "        rows[   'new_id'  ].append(items.get('NEWID', ''))\n",
    "        rows[ 'has_topics'].append(bool(items.get('TOPICS', '')))\n",
    "        rows[ 'cgi_split' ].append(items.get('CGISPLIT', ''))\n",
    "        rows['lewis_split'].append(items.get('LEWISSPLIT', ''))\n",
    "\n",
    "    def parse_string(self, str):\n",
    "        # remove bad characters\n",
    "        xml_data = self.bad_char_pattern.sub('', str)\n",
    "        # find documents\n",
    "        documents = self.document_pattern.findall(xml_data)\n",
    "        # parse document's elements\n",
    "        rows = self.empty_row()\n",
    "        for doc in documents:\n",
    "            xml_doc = objectify.fromstring(doc)\n",
    "            # parse attributes of the header\n",
    "            self.parse_header(rows, xml_doc)\n",
    "            # read DATE\n",
    "            rows[  'date'  ].append(self.get_date(xml_doc, 'DATE'))\n",
    "            # read TOPICS\n",
    "            rows[  'topics'  ].append(self.get_text(xml_doc,'TOPICS', True))\n",
    "            # read PLACES\n",
    "            rows[  'places'  ].append(self.get_text(xml_doc, 'PLACES', True))\n",
    "            # read PEOPLE\n",
    "            rows[ 'people'  ].append(self.get_text(xml_doc, 'PEOPLE', True))\n",
    "            # read ORGS\n",
    "            rows[ 'orgs'  ].append(self.get_text(xml_doc, 'ORGS', True))\n",
    "            # read EXCHANGES\n",
    "            rows[ 'exchanges'  ].append(self.get_text(xml_doc, 'EXCHANGES', True))\n",
    "            # read COMPANIES\n",
    "            rows[ 'companies'  ].append(self.get_text(xml_doc, 'COMPANIES', True))\n",
    "            # read the TEXT tag\n",
    "            text = xml_doc.TEXT\n",
    "            rows[ 'title'  ].append(self.get_text(text, 'TITLE'))\n",
    "            rows['dateline'].append(self.get_text(text, 'DATELINE'))\n",
    "            rows[  'body'  ].append(self.get_text(text, 'BODY'))\n",
    "            rows[  'author'  ].append(self.get_text(text, 'AUTHOR'))\n",
    "        return rows\n",
    "\n",
    "    def parse(self, path):\n",
    "        \"\"\"parse a file from the Reuters dataset\n",
    "        \"\"\"\n",
    "        # open xml file\n",
    "        xml_data = ''\n",
    "        try:\n",
    "            xml_data = open(path, 'r', encoding=\"utf-8\").read()\n",
    "        except UnicodeDecodeError as ude:\n",
    "            print('Failed to read %s as utf-8' % path)\n",
    "            lines = []\n",
    "            for line in open(path, 'rb').readlines():\n",
    "                line = line.decode('utf-8','ignore') #.encode(\"utf-8\")\n",
    "                lines.append(line)\n",
    "            xml_data = '\\n'.join(lines)\n",
    "        return self.parse_string(xml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to read Reuters/reuters21578/reut2-017.sgm as utf-8\n",
      "Cannot find date patter in: 31-MAR-1987 605:12:19.12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from lxml import etree\n",
    "from lxml import objectify\n",
    "from datetime import datetime\n",
    "\n",
    "Liste = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
    "\n",
    "parser = ReutersSGMLParser()\n",
    "data = parser.empty_row()\n",
    "for j in Liste :\n",
    "    for path in  ['Reuters/reuters21578/reut2-0%i.sgm'%j]:\n",
    "    # parse current document\n",
    "        rows = parser.parse(path)\n",
    "    # append rows into dataset\n",
    "        for key in data.keys():\n",
    "            data[key] = data[key] + rows[key]\n",
    "\n",
    "df = pd.DataFrame(data, columns=data.keys())\n",
    "#df = df.astype(dtype= {\"date\":\"datetime64[]\"})\n",
    "df.head()\n",
    "\n",
    "#il y a 20578 articles\n",
    "\n",
    "lieu = []\n",
    "for i in df.places:\n",
    "    lieu.append(i)\n",
    "#print(lieu)\n",
    "#print(type(lieu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21578\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "texte = []\n",
    "for i in df.title:\n",
    "    for j in df.body:\n",
    "        tout = i+j\n",
    "    texte.append(tout)\n",
    "print(len(texte))\n",
    "print(type(texte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAHIA COCOA REVIEWThe American Stock Exchange said it has\n",
      "introduced options with expirations of up to three years on the\n",
      "Institutional Index.\n",
      "    With the ticker symbol <XII>, the index is a guage of the\n",
      "core equity holdings of the nation's largest institutions, the\n",
      "exchange explained.\n",
      "    The new listings represent the first long-term options to\n",
      "be traded by the Amex, it added.\n",
      "    It said the long-term Institutional Index options began\n",
      "trading Monday with expirations of December 1988 <XIV> and\n",
      "December 1989 <XIX>.\n",
      "   \n",
      "    The Amex said a third long-term option with an expiration\n",
      "of December 1990 will begin trading following the December 1987\n",
      "expiration.\n",
      "    It said strike prices on the long-term options have been\n",
      "set at 50 point intervals with initial strikes of 250, 300 and\n",
      "350. To avoid conflicting strike price codes, the 350 stike\n",
      "prices will carry the ticker symbols <XVV> for the option\n",
      "expiring in December 1988 and <XVX> for the option expiring in\n",
      "December 1989.\n",
      " Reuter\n"
     ]
    }
   ],
   "source": [
    "for j in texte :\n",
    "    print(j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alexj/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 4016941  tokens en incluant la ponctuation.\n",
      "Il y a 3761395  tokens sans inclure la ponctuation.\n",
      "Il y a 173110 phrases dans l'ensemble du corpus.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "# tokenizer comprenant les mots avec une apostrophe (l', qu') et les ponctuations séparément\n",
    "# une telle tokenization nous permet d'avoir une bonne idée du nombre de token\n",
    "nb_instances= 0\n",
    "for i in texte:\n",
    "    l=len(word_tokenize(i))\n",
    "    nb_instances+=l\n",
    "print(\"Il y a\", nb_instances, \" tokens en incluant la ponctuation.\") # nombre de tokens avec ponctuation\n",
    "\n",
    "import re\n",
    "nb_instances2= 0\n",
    "for i in texte:\n",
    "    j = re.sub(\",|;|\\.\", \" \", i)\n",
    "    l2=len(word_tokenize(j))\n",
    "    nb_instances2 += l2\n",
    "print(\"Il y a\", nb_instances2, \" tokens sans inclure la ponctuation.\") # nombre de tokens sans ponctuation\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nb_instances3= 0\n",
    "for i in texte:\n",
    "    longueur_text=len(sent_tokenize(i))\n",
    "    nb_instances3 += longueur_text\n",
    "print(\"Il y a\", nb_instances3, \"phrases dans l'ensemble du corpus.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorisation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Récupérer les instances (X) et les classes (y) et vectoriser\n",
    "y = lieu\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "V = CountVectorizer(ngram_range = (1,2) )\n",
    "X = V.fit_transform(texte)\n",
    "\n",
    "## séparer train test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 0.3*21578\n",
    "train = 21578 - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,3 pour la taille du test soit environ 6473.4 articles. Donc environ 15104.6 articles pour le train.\n"
     ]
    }
   ],
   "source": [
    "print(\"0,3 pour la taille du test soit environ\", test, \"articles. Donc environ\", train, \"articles pour le train.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifications et Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le perceptron, réseau de neurones simple, classifieur linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bons résultats 4285\n",
      "Erreurs: 2189\n"
     ]
    }
   ],
   "source": [
    "#classifier\n",
    "\n",
    "ppn = Perceptron(eta0=0.1, random_state=0)\n",
    "ppn.fit(X_train, y_train)\n",
    "y_pred = ppn.predict(X_test)\n",
    "\n",
    "# On fait la somme de tous les cas où la valeur dans y_test est bien trouvée dans y_pred\n",
    "print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "print('Erreurs: %d' % (y_test != y_pred).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Les données de classification : elles permettent d'évaluer la qualité de la classification. Ici, on calcule ces données avec les résultats donnés par le Perceptron.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                          0.74      0.64      0.69       811\n",
      "            algeria       0.00      0.00      0.00         2\n",
      "             angola       0.00      0.00      0.00         0\n",
      "          argentina       1.00      0.33      0.50        15\n",
      "              aruba       0.00      0.00      0.00         1\n",
      "          australia       0.00      0.00      0.00        60\n",
      "            austria       0.00      0.00      0.00         5\n",
      "            bahrain       1.00      0.25      0.40         8\n",
      "         bangladesh       0.83      0.83      0.83         6\n",
      "            belgium       0.50      0.04      0.07        56\n",
      "            bermuda       0.00      0.00      0.00         2\n",
      "            bolivia       0.00      0.00      0.00         5\n",
      "           botswana       0.00      0.00      0.00         1\n",
      "             brazil       0.62      0.71      0.66        52\n",
      "              burma       0.00      0.00      0.00         1\n",
      "           cameroon       0.00      0.00      0.00         1\n",
      "             canada       0.86      0.18      0.30       280\n",
      "               chad       1.00      1.00      1.00         1\n",
      "              chile       0.00      0.00      0.00         2\n",
      "              china       0.79      0.42      0.55        36\n",
      "           colombia       1.00      0.33      0.50         6\n",
      "         costa-rica       0.00      0.00      0.00         4\n",
      "               cuba       0.67      0.33      0.44         6\n",
      "             cyprus       0.00      0.00      0.00         5\n",
      "            denmark       1.00      0.30      0.46        10\n",
      " dominican-republic       0.00      0.00      0.00         1\n",
      "       east-germany       0.00      0.00      0.00         1\n",
      "            ecuador       0.76      1.00      0.87        13\n",
      "              egypt       1.00      0.20      0.33         5\n",
      "               fiji       0.00      0.00      0.00         1\n",
      "            finland       1.00      0.12      0.22         8\n",
      "             france       0.77      0.19      0.31       103\n",
      "              ghana       0.00      0.00      0.00         3\n",
      "             greece       0.33      0.50      0.40         4\n",
      "             guyana       0.00      0.00      0.00         1\n",
      "              haiti       0.00      0.00      0.00         3\n",
      "          hong-kong       0.00      0.00      0.00        35\n",
      "            hungary       1.00      0.25      0.40         4\n",
      "            iceland       0.00      0.00      0.00         0\n",
      "              india       0.48      0.79      0.59        14\n",
      "          indonesia       1.00      0.48      0.65        21\n",
      "               iran       0.00      0.00      0.00        15\n",
      "               iraq       0.00      0.00      0.00         3\n",
      "             israel       0.00      0.00      0.00         0\n",
      "              italy       0.94      0.42      0.58        38\n",
      "        ivory-coast       0.00      0.00      0.00         4\n",
      "              japan       0.74      0.63      0.68       221\n",
      "             jordan       0.01      0.33      0.01         3\n",
      "              kenya       0.00      0.00      0.00         2\n",
      "             kuwait       0.00      0.00      0.00         7\n",
      "            lebanon       0.00      0.00      0.00         1\n",
      "         luxembourg       0.00      0.00      0.00        14\n",
      "         madagascar       0.00      0.00      0.00         2\n",
      "             malawi       0.00      0.00      0.00         1\n",
      "           malaysia       0.73      0.61      0.67        18\n",
      "          mauritius       0.00      0.00      0.00         1\n",
      "             mexico       1.00      0.20      0.33         5\n",
      "            morocco       0.00      0.00      0.00         1\n",
      "        netherlands       0.70      0.70      0.70        56\n",
      "        new-zealand       1.00      0.06      0.11        34\n",
      "          nicaragua       0.00      0.00      0.00         2\n",
      "            nigeria       0.00      0.00      0.00         8\n",
      "        north-korea       0.00      0.00      0.00         3\n",
      "             norway       0.33      0.25      0.29         8\n",
      "           pakistan       0.83      0.71      0.77         7\n",
      "   papua-new-guinea       0.00      0.00      0.00         0\n",
      "               peru       0.80      0.44      0.57         9\n",
      "        philippines       0.00      0.00      0.00        23\n",
      "             poland       0.00      0.00      0.00         3\n",
      "           portugal       0.00      0.00      0.00         5\n",
      "       saudi-arabia       0.40      0.22      0.29         9\n",
      "          singapore       0.60      0.69      0.64        13\n",
      "            somalia       0.00      0.00      0.00         1\n",
      "       south-africa       0.00      0.00      0.00        26\n",
      "        south-korea       0.00      0.00      0.00        16\n",
      "              spain       0.00      0.00      0.00        18\n",
      "          sri-lanka       0.71      0.71      0.71         7\n",
      "              sudan       0.00      0.00      0.00         1\n",
      "             sweden       0.00      0.00      0.00        19\n",
      "        switzerland       0.92      0.19      0.32        57\n",
      "             taiwan       0.75      0.23      0.35        26\n",
      "           tanzania       1.00      0.75      0.86         4\n",
      "           thailand       0.88      0.47      0.61        15\n",
      "               togo       0.00      0.00      0.00         1\n",
      "            tunisia       0.00      0.00      0.00         1\n",
      "             turkey       1.00      0.25      0.40         8\n",
      "                uae       1.00      0.50      0.67        10\n",
      "             uganda       0.00      0.00      0.00         5\n",
      "                 uk       0.89      0.17      0.28       375\n",
      "                usa       0.86      0.88      0.87      3606\n",
      "               ussr       0.50      0.83      0.62        18\n",
      "          venezuela       0.83      0.38      0.53        13\n",
      "       west-germany       0.79      0.40      0.53       113\n",
      "yemen-arab-republic       0.00      0.00      0.00         1\n",
      "yemen-demo-republic       0.00      0.00      0.00         1\n",
      "         yugoslavia       0.00      0.00      0.00        10\n",
      "             zambia       1.00      0.38      0.55         8\n",
      "           zimbabwe       0.71      1.00      0.83         5\n",
      "\n",
      "           accuracy                           0.66      6474\n",
      "          macro avg       0.37      0.22      0.24      6474\n",
      "       weighted avg       0.79      0.66      0.69      6474\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Classification report permet de msurer l'exactitude d'une clissification selon plusieurs paramètres\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la précision est la proportion des items pertinents parmi l'ensemble des items proposés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le rappel est la proportion des items pertinents proposés parmi l'ensemble des items pertinents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vrai négatif : absent, absent\n",
    "# Vrai positif : présent, présent\n",
    "# Faux négatif : présent(dans la référence), absent(dans l'hypothèse)\n",
    "# Faux positif : absent, présent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support : nombre d'instances concernées\n",
    "\n",
    "# micro f-mesure : moyenne des F-mesure pondérée (une classe compte en fonction de sa taille)\n",
    "\n",
    "# macro f-mesure : moyenne des F-mesure de chaque classe (indépendamment de leur taille)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[521   0  89 ...   0   0   0]\n",
      " [  0   0   2 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   6 ...   0   0   0]\n",
      " [  1   0   1 ...   0   3   0]\n",
      " [  0   0   0 ...   0   0   5]]\n"
     ]
    }
   ],
   "source": [
    "#La matrice de confusion\n",
    "\n",
    "matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "print(matrice_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deuxième évaluation : Un arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = tree.DecisionTreeClassifier()\n",
    "DT = DT.fit(X_train, y_train)\n",
    "y_pred = DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[514   0   0 ...   2   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  3   0   7 ...   0   0   0]\n",
      " ...\n",
      " [  1   0   0 ...   5   0   0]\n",
      " [  1   0   0 ...   0   2   0]\n",
      " [  0   0   0 ...   0   0   1]]\n",
      "Bons résultats 4836\n",
      "Erreurs: 1638\n"
     ]
    }
   ],
   "source": [
    "# encore une matrice de confusion\n",
    "matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "print(matrice_confusion)\n",
    "\n",
    "print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "print('Erreurs: %d' % (y_test != y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                          0.69      0.63      0.66       811\n",
      "            algeria       0.00      0.00      0.00         2\n",
      "          argentina       0.88      0.47      0.61        15\n",
      "              aruba       0.00      0.00      0.00         1\n",
      "          australia       0.69      0.57      0.62        60\n",
      "            austria       0.00      0.00      0.00         5\n",
      "            bahrain       0.56      0.62      0.59         8\n",
      "         bangladesh       0.40      0.33      0.36         6\n",
      "            belgium       0.52      0.59      0.55        56\n",
      "            bermuda       0.00      0.00      0.00         2\n",
      "            bolivia       0.14      0.20      0.17         5\n",
      "           botswana       0.00      0.00      0.00         1\n",
      "             brazil       0.72      0.65      0.69        52\n",
      "              burma       0.00      0.00      0.00         1\n",
      "           cameroon       0.00      0.00      0.00         1\n",
      "             canada       0.61      0.47      0.53       280\n",
      "               chad       0.00      0.00      0.00         1\n",
      "              chile       0.00      0.00      0.00         2\n",
      "              china       0.76      0.81      0.78        36\n",
      "           colombia       1.00      0.50      0.67         6\n",
      "         costa-rica       0.00      0.00      0.00         4\n",
      "               cuba       1.00      0.17      0.29         6\n",
      "             cyprus       0.00      0.00      0.00         5\n",
      "            denmark       0.50      0.10      0.17        10\n",
      " dominican-republic       0.00      0.00      0.00         1\n",
      "       east-germany       0.00      0.00      0.00         1\n",
      "            ecuador       0.72      1.00      0.84        13\n",
      "              egypt       0.00      0.00      0.00         5\n",
      "               fiji       0.00      0.00      0.00         1\n",
      "            finland       0.67      0.50      0.57         8\n",
      "             france       0.60      0.58      0.59       103\n",
      "              ghana       0.00      0.00      0.00         3\n",
      "             greece       0.50      0.25      0.33         4\n",
      "             guyana       0.00      0.00      0.00         1\n",
      "              haiti       0.00      0.00      0.00         3\n",
      "          hong-kong       0.47      0.23      0.31        35\n",
      "            hungary       1.00      0.25      0.40         4\n",
      "              india       0.73      0.57      0.64        14\n",
      "          indonesia       0.88      0.71      0.79        21\n",
      "               iran       0.38      0.20      0.26        15\n",
      "               iraq       0.00      0.00      0.00         3\n",
      "            ireland       0.00      0.00      0.00         0\n",
      "             israel       0.00      0.00      0.00         0\n",
      "              italy       0.83      0.53      0.65        38\n",
      "        ivory-coast       0.00      0.00      0.00         4\n",
      "              japan       0.67      0.70      0.68       221\n",
      "             jordan       0.00      0.00      0.00         3\n",
      "              kenya       0.00      0.00      0.00         2\n",
      "             kuwait       0.50      0.29      0.36         7\n",
      "            lebanon       0.00      0.00      0.00         1\n",
      "         luxembourg       0.50      0.14      0.22        14\n",
      "         madagascar       0.00      0.00      0.00         2\n",
      "             malawi       0.00      0.00      0.00         1\n",
      "           malaysia       0.80      0.44      0.57        18\n",
      "          mauritius       0.00      0.00      0.00         1\n",
      "             mexico       0.33      0.20      0.25         5\n",
      "            morocco       0.00      0.00      0.00         1\n",
      "         mozambique       0.00      0.00      0.00         0\n",
      "        netherlands       0.78      0.57      0.66        56\n",
      "        new-zealand       0.52      0.32      0.40        34\n",
      "          nicaragua       0.00      0.00      0.00         2\n",
      "            nigeria       0.50      0.12      0.20         8\n",
      "        north-korea       0.00      0.00      0.00         3\n",
      "             norway       0.67      0.25      0.36         8\n",
      "           pakistan       0.75      0.86      0.80         7\n",
      "             panama       0.00      0.00      0.00         0\n",
      "               peru       0.83      0.56      0.67         9\n",
      "        philippines       0.62      0.57      0.59        23\n",
      "             poland       0.50      0.33      0.40         3\n",
      "           portugal       0.00      0.00      0.00         5\n",
      "       saudi-arabia       0.45      0.56      0.50         9\n",
      "          singapore       0.45      0.38      0.42        13\n",
      "            somalia       0.00      0.00      0.00         1\n",
      "       south-africa       0.56      0.35      0.43        26\n",
      "        south-korea       0.75      0.75      0.75        16\n",
      "              spain       0.76      0.72      0.74        18\n",
      "          sri-lanka       0.80      0.57      0.67         7\n",
      "              sudan       0.00      0.00      0.00         1\n",
      "             sweden       0.74      0.74      0.74        19\n",
      "        switzerland       0.71      0.60      0.65        57\n",
      "             taiwan       0.73      0.73      0.73        26\n",
      "           tanzania       0.75      0.75      0.75         4\n",
      "           thailand       0.90      0.60      0.72        15\n",
      "               togo       0.00      0.00      0.00         1\n",
      "            tunisia       0.00      0.00      0.00         1\n",
      "             turkey       0.40      0.25      0.31         8\n",
      "                uae       0.54      0.70      0.61        10\n",
      "             uganda       1.00      0.60      0.75         5\n",
      "                 uk       0.64      0.49      0.56       375\n",
      "                usa       0.80      0.90      0.85      3606\n",
      "               ussr       0.57      0.44      0.50        18\n",
      "          venezuela       0.38      0.23      0.29        13\n",
      "       west-germany       0.65      0.58      0.61       113\n",
      "yemen-arab-republic       0.00      0.00      0.00         1\n",
      "yemen-demo-republic       0.00      0.00      0.00         1\n",
      "         yugoslavia       0.71      0.50      0.59        10\n",
      "             zambia       1.00      0.25      0.40         8\n",
      "           zimbabwe       1.00      0.20      0.33         5\n",
      "\n",
      "           accuracy                           0.75      6474\n",
      "          macro avg       0.39      0.29      0.32      6474\n",
      "       weighted avg       0.73      0.75      0.73      6474\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Classification report permet de msurer l'exactitude d'une clissification selon plusieurs paramètres\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# résultats moins bons que précédemment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approfondissement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regardons l'impact du paramètres random_state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec la valeur par défaut de random state\n",
      "[[502   1   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   2   0]\n",
      " [  3   0   7 ...   0   0   0]\n",
      " ...\n",
      " [  1   0   0 ...   5   0   0]\n",
      " [  1   0   0 ...   0   2   0]\n",
      " [  0   0   0 ...   0   0   1]]\n",
      "(array([0.6962552 , 0.        , 0.875     , 0.        , 0.61111111,\n",
      "       0.        , 0.375     , 0.42857143, 0.51724138, 0.        ,\n",
      "       0.14285714, 0.        , 0.66666667, 0.        , 0.        ,\n",
      "       0.57327586, 0.        , 0.        , 0.75675676, 0.66666667,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.76470588, 0.        , 0.        , 0.66666667,\n",
      "       0.62365591, 0.        , 0.11111111, 0.        , 0.        ,\n",
      "       0.5       , 0.5       , 0.8       , 0.9375    , 0.5       ,\n",
      "       0.        , 0.        , 0.82608696, 0.        , 0.69369369,\n",
      "       0.        , 0.        , 0.5       , 0.        , 0.4       ,\n",
      "       0.        , 0.        , 0.72727273, 0.        , 0.25      ,\n",
      "       0.        , 0.61111111, 0.52173913, 0.        , 1.        ,\n",
      "       0.        , 1.        , 1.        , 1.        , 0.75      ,\n",
      "       0.5       , 0.        , 0.46153846, 0.8       , 0.        ,\n",
      "       0.71428571, 0.75      , 0.66666667, 0.8       , 0.        ,\n",
      "       0.66666667, 0.69387755, 0.76      , 0.75      , 0.75      ,\n",
      "       0.        , 0.        , 0.33333333, 0.54545455, 1.        ,\n",
      "       0.60064935, 0.80252101, 0.64285714, 0.375     , 0.61261261,\n",
      "       0.        , 0.        , 1.        , 0.33333333, 1.        ]), array([0.6189889 , 0.        , 0.46666667, 0.        , 0.55      ,\n",
      "       0.        , 0.375     , 0.5       , 0.53571429, 0.        ,\n",
      "       0.2       , 0.        , 0.69230769, 0.        , 0.        ,\n",
      "       0.475     , 0.        , 0.        , 0.77777778, 0.66666667,\n",
      "       0.        , 0.16666667, 0.        , 0.        , 0.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.5       ,\n",
      "       0.5631068 , 0.        , 0.25      , 0.        , 0.        ,\n",
      "       0.25714286, 0.25      , 0.57142857, 0.71428571, 0.2       ,\n",
      "       0.        , 0.        , 0.5       , 0.        , 0.69683258,\n",
      "       0.        , 0.        , 0.14285714, 0.        , 0.14285714,\n",
      "       0.        , 0.        , 0.44444444, 0.        , 0.2       ,\n",
      "       0.        , 0.58928571, 0.35294118, 0.        , 0.125     ,\n",
      "       0.        , 0.25      , 0.71428571, 0.55555556, 0.65217391,\n",
      "       0.33333333, 0.        , 0.66666667, 0.30769231, 0.        ,\n",
      "       0.38461538, 0.75      , 0.77777778, 0.57142857, 0.        ,\n",
      "       0.73684211, 0.59649123, 0.73076923, 0.75      , 0.6       ,\n",
      "       0.        , 0.        , 0.25      , 0.6       , 0.6       ,\n",
      "       0.49333333, 0.9004437 , 0.5       , 0.23076923, 0.60176991,\n",
      "       0.        , 0.        , 0.5       , 0.25      , 0.2       ]), array([0.65535248, 0.        , 0.60869565, 0.        , 0.57894737,\n",
      "       0.        , 0.375     , 0.46153846, 0.52631579, 0.        ,\n",
      "       0.16666667, 0.        , 0.67924528, 0.        , 0.        ,\n",
      "       0.51953125, 0.        , 0.        , 0.76712329, 0.66666667,\n",
      "       0.        , 0.28571429, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.86666667, 0.        , 0.        , 0.57142857,\n",
      "       0.59183673, 0.        , 0.15384615, 0.        , 0.        ,\n",
      "       0.33962264, 0.33333333, 0.66666667, 0.81081081, 0.28571429,\n",
      "       0.        , 0.        , 0.62295082, 0.        , 0.69525959,\n",
      "       0.        , 0.        , 0.22222222, 0.        , 0.21052632,\n",
      "       0.        , 0.        , 0.55172414, 0.        , 0.22222222,\n",
      "       0.        , 0.6       , 0.42105263, 0.        , 0.22222222,\n",
      "       0.        , 0.4       , 0.83333333, 0.71428571, 0.69767442,\n",
      "       0.4       , 0.        , 0.54545455, 0.44444444, 0.        ,\n",
      "       0.5       , 0.75      , 0.71794872, 0.66666667, 0.        ,\n",
      "       0.7       , 0.64150943, 0.74509804, 0.75      , 0.66666667,\n",
      "       0.        , 0.        , 0.28571429, 0.57142857, 0.75      ,\n",
      "       0.54172767, 0.84866702, 0.5625    , 0.28571429, 0.60714286,\n",
      "       0.        , 0.        , 0.66666667, 0.28571429, 0.33333333]), array([ 811,    2,   15,    1,   60,    5,    8,    6,   56,    2,    5,\n",
      "          1,   52,    1,    1,  280,    1,    2,   36,    6,    4,    6,\n",
      "          5,   10,    1,    1,   13,    5,    1,    8,  103,    3,    4,\n",
      "          1,    3,   35,    4,   14,   21,   15,    3,    0,   38,    4,\n",
      "        221,    3,    2,    7,    1,   14,    2,    1,   18,    1,    5,\n",
      "          1,   56,   34,    2,    8,    3,    8,    7,    9,   23,    3,\n",
      "          5,    9,   13,    1,   26,   16,   18,    7,    1,   19,   57,\n",
      "         26,    4,   15,    1,    1,    8,   10,    5,  375, 3606,   18,\n",
      "         13,  113,    1,    1,   10,    8,    5]))\n",
      "Bons résultats 4812\n",
      "Erreurs: 1662\n",
      "Accuracy: 0.74\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[507   1   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   2   0]\n",
      " [  3   0   7 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  1   0   0 ...   0   2   0]\n",
      " [  0   0   0 ...   0   0   1]]\n",
      "(array([0.70416667, 0.        , 0.77777778, 0.        , 0.64      ,\n",
      "       0.        , 0.42857143, 0.66666667, 0.53448276, 0.        ,\n",
      "       0.16666667, 0.        , 0.72      , 0.        , 0.        ,\n",
      "       0.5990991 , 0.        , 0.        , 0.77777778, 0.75      ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.72222222, 0.        , 0.        , 0.66666667,\n",
      "       0.64210526, 0.        , 0.125     , 0.        , 0.        ,\n",
      "       0.33333333, 1.        , 0.72727273, 0.82352941, 0.42857143,\n",
      "       0.        , 0.        , 0.        , 0.76      , 0.        ,\n",
      "       0.70319635, 0.        , 0.        , 0.66666667, 0.        ,\n",
      "       0.5       , 0.        , 0.        , 0.58333333, 0.        ,\n",
      "       0.5       , 0.        , 0.        , 0.66666667, 0.47826087,\n",
      "       0.        , 0.5       , 0.        , 0.25      , 0.71428571,\n",
      "       0.        , 0.        , 0.83333333, 0.76470588, 0.5       ,\n",
      "       0.        , 0.42857143, 1.        , 0.        , 0.69230769,\n",
      "       0.75      , 0.54166667, 0.8       , 0.        , 0.77777778,\n",
      "       0.76595745, 0.73076923, 0.75      , 0.9       , 0.        ,\n",
      "       0.        , 0.25      , 0.66666667, 1.        , 0.64184397,\n",
      "       0.79926561, 0.69230769, 0.375     , 0.61904762, 0.        ,\n",
      "       0.        , 0.71428571, 0.        , 0.33333333, 0.5       ]), array([0.62515413, 0.        , 0.46666667, 0.        , 0.53333333,\n",
      "       0.        , 0.375     , 0.66666667, 0.55357143, 0.        ,\n",
      "       0.2       , 0.        , 0.69230769, 0.        , 0.        ,\n",
      "       0.475     , 0.        , 0.        , 0.77777778, 0.5       ,\n",
      "       0.        , 0.16666667, 0.        , 0.        , 0.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.5       ,\n",
      "       0.59223301, 0.        , 0.25      , 0.        , 0.        ,\n",
      "       0.22857143, 0.25      , 0.57142857, 0.66666667, 0.2       ,\n",
      "       0.        , 0.        , 0.        , 0.5       , 0.        ,\n",
      "       0.69683258, 0.        , 0.        , 0.28571429, 0.        ,\n",
      "       0.14285714, 0.        , 0.        , 0.38888889, 0.        ,\n",
      "       0.2       , 0.        , 0.        , 0.57142857, 0.32352941,\n",
      "       0.        , 0.125     , 0.        , 0.25      , 0.71428571,\n",
      "       0.        , 0.        , 0.55555556, 0.56521739, 0.33333333,\n",
      "       0.        , 0.66666667, 0.38461538, 0.        , 0.34615385,\n",
      "       0.75      , 0.72222222, 0.57142857, 0.        , 0.73684211,\n",
      "       0.63157895, 0.73076923, 0.75      , 0.6       , 0.        ,\n",
      "       0.        , 0.25      , 0.6       , 0.6       , 0.48266667,\n",
      "       0.90543539, 0.5       , 0.23076923, 0.57522124, 0.        ,\n",
      "       0.        , 0.5       , 0.        , 0.25      , 0.2       ]), array([0.66231221, 0.        , 0.58333333, 0.        , 0.58181818,\n",
      "       0.        , 0.4       , 0.66666667, 0.54385965, 0.        ,\n",
      "       0.18181818, 0.        , 0.70588235, 0.        , 0.        ,\n",
      "       0.52988048, 0.        , 0.        , 0.77777778, 0.6       ,\n",
      "       0.        , 0.28571429, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.83870968, 0.        , 0.        , 0.57142857,\n",
      "       0.61616162, 0.        , 0.16666667, 0.        , 0.        ,\n",
      "       0.27118644, 0.4       , 0.64      , 0.73684211, 0.27272727,\n",
      "       0.        , 0.        , 0.        , 0.6031746 , 0.        ,\n",
      "       0.7       , 0.        , 0.        , 0.4       , 0.        ,\n",
      "       0.22222222, 0.        , 0.        , 0.46666667, 0.        ,\n",
      "       0.28571429, 0.        , 0.        , 0.61538462, 0.38596491,\n",
      "       0.        , 0.2       , 0.        , 0.25      , 0.71428571,\n",
      "       0.        , 0.        , 0.66666667, 0.65      , 0.4       ,\n",
      "       0.        , 0.52173913, 0.55555556, 0.        , 0.46153846,\n",
      "       0.75      , 0.61904762, 0.66666667, 0.        , 0.75675676,\n",
      "       0.69230769, 0.73076923, 0.75      , 0.72      , 0.        ,\n",
      "       0.        , 0.25      , 0.63157895, 0.75      , 0.55098935,\n",
      "       0.84904434, 0.58064516, 0.28571429, 0.59633028, 0.        ,\n",
      "       0.        , 0.58823529, 0.        , 0.28571429, 0.28571429]), array([ 811,    2,   15,    1,   60,    5,    8,    6,   56,    2,    5,\n",
      "          1,   52,    1,    1,  280,    1,    2,   36,    6,    4,    6,\n",
      "          5,   10,    1,    1,   13,    5,    1,    8,  103,    3,    4,\n",
      "          1,    3,   35,    4,   14,   21,   15,    3,    0,    0,   38,\n",
      "          4,  221,    3,    2,    7,    1,   14,    2,    1,   18,    1,\n",
      "          5,    1,    0,   56,   34,    2,    8,    3,    8,    7,    0,\n",
      "          0,    9,   23,    3,    5,    9,   13,    1,   26,   16,   18,\n",
      "          7,    1,   19,   57,   26,    4,   15,    1,    1,    8,   10,\n",
      "          5,  375, 3606,   18,   13,  113,    1,    1,   10,    0,    8,\n",
      "          5]))\n",
      "Bons résultats 4826\n",
      "Erreurs: 1648\n",
      "Accuracy: 0.75\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[510   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   2   0]\n",
      " [  3   0   7 ...   0   0   0]\n",
      " ...\n",
      " [  1   0   0 ...   5   0   0]\n",
      " [  1   0   0 ...   0   2   0]\n",
      " [  0   0   0 ...   0   0   1]]\n",
      "(array([0.68181818, 0.        , 0.875     , 0.        , 0.69565217,\n",
      "       0.        , 0.2       , 0.4       , 0.54237288, 0.        ,\n",
      "       0.1       , 0.        , 0.75510204, 0.        , 0.        ,\n",
      "       0.60775862, 0.        , 0.        , 0.72222222, 0.6       ,\n",
      "       0.        , 1.        , 0.        , 0.5       , 0.        ,\n",
      "       0.        , 0.72222222, 0.        , 0.        , 0.57142857,\n",
      "       0.64835165, 0.        , 0.5       , 0.        , 0.        ,\n",
      "       0.44444444, 0.5       , 0.72727273, 0.9375    , 0.42857143,\n",
      "       0.        , 0.        , 0.        , 0.82608696, 0.        ,\n",
      "       0.68695652, 0.        , 0.        , 0.5       , 0.        ,\n",
      "       0.5       , 0.        , 0.        , 0.61538462, 0.        ,\n",
      "       0.25      , 0.        , 0.6875    , 0.6       , 0.        ,\n",
      "       1.        , 0.        , 1.        , 0.75      , 0.        ,\n",
      "       1.        , 0.72222222, 0.5       , 0.        , 0.41666667,\n",
      "       0.83333333, 0.        , 0.66666667, 0.71428571, 0.7       ,\n",
      "       0.8       , 0.        , 0.82352941, 0.70833333, 0.76      ,\n",
      "       0.8       , 0.75      , 0.        , 0.        , 0.5       ,\n",
      "       0.54545455, 1.        , 0.62162162, 0.80327056, 0.5       ,\n",
      "       0.25      , 0.60747664, 0.        , 0.        , 1.        ,\n",
      "       0.33333333, 0.5       ]), array([0.62885327, 0.        , 0.46666667, 0.        , 0.53333333,\n",
      "       0.        , 0.375     , 0.33333333, 0.57142857, 0.        ,\n",
      "       0.2       , 0.        , 0.71153846, 0.        , 0.        ,\n",
      "       0.50357143, 0.        , 0.        , 0.72222222, 0.5       ,\n",
      "       0.        , 0.16666667, 0.        , 0.1       , 0.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.5       ,\n",
      "       0.57281553, 0.        , 0.25      , 0.        , 0.        ,\n",
      "       0.22857143, 0.25      , 0.57142857, 0.71428571, 0.2       ,\n",
      "       0.        , 0.        , 0.        , 0.5       , 0.        ,\n",
      "       0.71493213, 0.        , 0.        , 0.14285714, 0.        ,\n",
      "       0.14285714, 0.        , 0.        , 0.44444444, 0.        ,\n",
      "       0.2       , 0.        , 0.58928571, 0.35294118, 0.        ,\n",
      "       0.125     , 0.        , 0.25      , 0.85714286, 0.        ,\n",
      "       0.55555556, 0.56521739, 0.33333333, 0.        , 0.55555556,\n",
      "       0.38461538, 0.        , 0.38461538, 0.625     , 0.77777778,\n",
      "       0.57142857, 0.        , 0.73684211, 0.59649123, 0.73076923,\n",
      "       1.        , 0.6       , 0.        , 0.        , 0.25      ,\n",
      "       0.6       , 0.6       , 0.49066667, 0.89905713, 0.5       ,\n",
      "       0.23076923, 0.57522124, 0.        , 0.        , 0.5       ,\n",
      "       0.25      , 0.2       ]), array([0.65426555, 0.        , 0.60869565, 0.        , 0.60377358,\n",
      "       0.        , 0.26086957, 0.36363636, 0.55652174, 0.        ,\n",
      "       0.13333333, 0.        , 0.73267327, 0.        , 0.        ,\n",
      "       0.55078125, 0.        , 0.        , 0.72222222, 0.54545455,\n",
      "       0.        , 0.28571429, 0.        , 0.16666667, 0.        ,\n",
      "       0.        , 0.83870968, 0.        , 0.        , 0.53333333,\n",
      "       0.60824742, 0.        , 0.33333333, 0.        , 0.        ,\n",
      "       0.30188679, 0.33333333, 0.64      , 0.81081081, 0.27272727,\n",
      "       0.        , 0.        , 0.        , 0.62295082, 0.        ,\n",
      "       0.70066519, 0.        , 0.        , 0.22222222, 0.        ,\n",
      "       0.22222222, 0.        , 0.        , 0.51612903, 0.        ,\n",
      "       0.22222222, 0.        , 0.63461538, 0.44444444, 0.        ,\n",
      "       0.22222222, 0.        , 0.4       , 0.8       , 0.        ,\n",
      "       0.71428571, 0.63414634, 0.4       , 0.        , 0.47619048,\n",
      "       0.52631579, 0.        , 0.48780488, 0.66666667, 0.73684211,\n",
      "       0.66666667, 0.        , 0.77777778, 0.64761905, 0.74509804,\n",
      "       0.88888889, 0.66666667, 0.        , 0.        , 0.33333333,\n",
      "       0.57142857, 0.75      , 0.54843517, 0.84846899, 0.5       ,\n",
      "       0.24      , 0.59090909, 0.        , 0.        , 0.66666667,\n",
      "       0.28571429, 0.28571429]), array([ 811,    2,   15,    1,   60,    5,    8,    6,   56,    2,    5,\n",
      "          1,   52,    1,    1,  280,    1,    2,   36,    6,    4,    6,\n",
      "          5,   10,    1,    1,   13,    5,    1,    8,  103,    3,    4,\n",
      "          1,    3,   35,    4,   14,   21,   15,    3,    0,    0,   38,\n",
      "          4,  221,    3,    2,    7,    1,   14,    2,    1,   18,    1,\n",
      "          5,    1,   56,   34,    2,    8,    3,    8,    7,    0,    9,\n",
      "         23,    3,    5,    9,   13,    1,   26,   16,   18,    7,    1,\n",
      "         19,   57,   26,    4,   15,    1,    1,    8,   10,    5,  375,\n",
      "       3606,   18,   13,  113,    1,    1,   10,    8,    5]))\n",
      "Bons résultats 4820\n",
      "Erreurs: 1654\n",
      "Accuracy: 0.74\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Avec la valeur par défaut de random state\")\n",
    "for i in range(3):\n",
    "  DT = tree.DecisionTreeClassifier()\n",
    "  DT = DT.fit(X_train, y_train)\n",
    "  y_pred = DT.predict(X_test)\n",
    "  matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "  print(matrice_confusion)\n",
    "  stats = precision_recall_fscore_support(y_test, y_pred)\n",
    "  print(stats)\n",
    "  print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "  print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "  print ('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "  print(\"--\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En fixant random state\n",
      "[[508   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  3   0   7 ...   0   0   0]\n",
      " ...\n",
      " [  1   0   0 ...   5   0   0]\n",
      " [  1   0   0 ...   0   2   0]\n",
      " [  0   0   0 ...   0   0   1]]\n",
      "(array([0.70653686, 0.        , 0.875     , 0.        , 0.60344828,\n",
      "       0.        , 0.38461538, 0.4       , 0.52631579, 0.        ,\n",
      "       0.16666667, 0.        , 0.825     , 0.        , 0.        ,\n",
      "       0.60619469, 0.        , 0.        , 0.70731707, 0.44444444,\n",
      "       0.        , 1.        , 0.        , 0.5       , 0.        ,\n",
      "       0.        , 0.72222222, 0.        , 0.        , 0.8       ,\n",
      "       0.61702128, 0.        , 0.33333333, 0.        , 0.        ,\n",
      "       0.45833333, 1.        , 0.66666667, 0.88235294, 0.5       ,\n",
      "       0.        , 0.        , 0.        , 0.86956522, 0.        ,\n",
      "       0.69642857, 0.        , 0.5       , 0.66666667, 0.        ,\n",
      "       0.25      , 0.        , 0.        , 0.8       , 0.        ,\n",
      "       0.33333333, 0.        , 0.73333333, 0.42857143, 0.        ,\n",
      "       0.5       , 0.        , 1.        , 0.66666667, 0.83333333,\n",
      "       0.54166667, 0.5       , 0.        , 0.38461538, 0.83333333,\n",
      "       0.        , 0.64285714, 0.73333333, 0.66666667, 0.8       ,\n",
      "       0.        , 0.7       , 0.68      , 0.73076923, 0.6       ,\n",
      "       0.81818182, 0.        , 0.        , 0.28571429, 0.66666667,\n",
      "       1.        , 0.61744966, 0.80314961, 0.61538462, 0.27272727,\n",
      "       0.62886598, 0.        , 0.        , 0.83333333, 0.66666667,\n",
      "       0.5       ]), array([0.62638718, 0.        , 0.46666667, 0.        , 0.58333333,\n",
      "       0.        , 0.625     , 0.33333333, 0.53571429, 0.        ,\n",
      "       0.2       , 0.        , 0.63461538, 0.        , 0.        ,\n",
      "       0.48928571, 0.        , 0.        , 0.80555556, 0.66666667,\n",
      "       0.        , 0.16666667, 0.        , 0.1       , 0.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.5       ,\n",
      "       0.5631068 , 0.        , 0.25      , 0.        , 0.        ,\n",
      "       0.31428571, 0.25      , 0.57142857, 0.71428571, 0.2       ,\n",
      "       0.        , 0.        , 0.        , 0.52631579, 0.        ,\n",
      "       0.70588235, 0.        , 0.5       , 0.28571429, 0.        ,\n",
      "       0.07142857, 0.        , 0.        , 0.44444444, 0.        ,\n",
      "       0.2       , 0.        , 0.58928571, 0.35294118, 0.        ,\n",
      "       0.125     , 0.        , 0.25      , 0.85714286, 0.55555556,\n",
      "       0.56521739, 0.33333333, 0.        , 0.55555556, 0.38461538,\n",
      "       0.        , 0.34615385, 0.6875    , 0.66666667, 0.57142857,\n",
      "       0.        , 0.73684211, 0.59649123, 0.73076923, 0.75      ,\n",
      "       0.6       , 0.        , 0.        , 0.25      , 0.4       ,\n",
      "       0.6       , 0.49066667, 0.90515807, 0.44444444, 0.23076923,\n",
      "       0.53982301, 0.        , 0.        , 0.5       , 0.25      ,\n",
      "       0.2       ]), array([0.66405229, 0.        , 0.60869565, 0.        , 0.59322034,\n",
      "       0.        , 0.47619048, 0.36363636, 0.53097345, 0.        ,\n",
      "       0.18181818, 0.        , 0.7173913 , 0.        , 0.        ,\n",
      "       0.54150198, 0.        , 0.        , 0.75324675, 0.53333333,\n",
      "       0.        , 0.28571429, 0.        , 0.16666667, 0.        ,\n",
      "       0.        , 0.83870968, 0.        , 0.        , 0.61538462,\n",
      "       0.58883249, 0.        , 0.28571429, 0.        , 0.        ,\n",
      "       0.37288136, 0.4       , 0.61538462, 0.78947368, 0.28571429,\n",
      "       0.        , 0.        , 0.        , 0.6557377 , 0.        ,\n",
      "       0.7011236 , 0.        , 0.5       , 0.4       , 0.        ,\n",
      "       0.11111111, 0.        , 0.        , 0.57142857, 0.        ,\n",
      "       0.25      , 0.        , 0.65346535, 0.38709677, 0.        ,\n",
      "       0.2       , 0.        , 0.4       , 0.75      , 0.66666667,\n",
      "       0.55319149, 0.4       , 0.        , 0.45454545, 0.52631579,\n",
      "       0.        , 0.45      , 0.70967742, 0.66666667, 0.66666667,\n",
      "       0.        , 0.71794872, 0.63551402, 0.73076923, 0.66666667,\n",
      "       0.69230769, 0.        , 0.        , 0.26666667, 0.5       ,\n",
      "       0.75      , 0.54680535, 0.85110821, 0.51612903, 0.25      ,\n",
      "       0.58095238, 0.        , 0.        , 0.625     , 0.36363636,\n",
      "       0.28571429]), array([ 811,    2,   15,    1,   60,    5,    8,    6,   56,    2,    5,\n",
      "          1,   52,    1,    1,  280,    1,    2,   36,    6,    4,    6,\n",
      "          5,   10,    1,    1,   13,    5,    1,    8,  103,    3,    4,\n",
      "          1,    3,   35,    4,   14,   21,   15,    3,    0,    0,   38,\n",
      "          4,  221,    3,    2,    7,    1,   14,    2,    1,   18,    1,\n",
      "          5,    1,   56,   34,    2,    8,    3,    8,    7,    9,   23,\n",
      "          3,    5,    9,   13,    1,   26,   16,   18,    7,    1,   19,\n",
      "         57,   26,    4,   15,    1,    1,    8,   10,    5,  375, 3606,\n",
      "         18,   13,  113,    1,    1,   10,    8,    5]))\n",
      "Bons résultats 4831\n",
      "Erreurs: 1643\n",
      "Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[508   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  3   0   7 ...   0   0   0]\n",
      " ...\n",
      " [  1   0   0 ...   5   0   0]\n",
      " [  1   0   0 ...   0   2   0]\n",
      " [  0   0   0 ...   0   0   1]]\n",
      "(array([0.70653686, 0.        , 0.875     , 0.        , 0.60344828,\n",
      "       0.        , 0.38461538, 0.4       , 0.52631579, 0.        ,\n",
      "       0.16666667, 0.        , 0.825     , 0.        , 0.        ,\n",
      "       0.60619469, 0.        , 0.        , 0.70731707, 0.44444444,\n",
      "       0.        , 1.        , 0.        , 0.5       , 0.        ,\n",
      "       0.        , 0.72222222, 0.        , 0.        , 0.8       ,\n",
      "       0.61702128, 0.        , 0.33333333, 0.        , 0.        ,\n",
      "       0.45833333, 1.        , 0.66666667, 0.88235294, 0.5       ,\n",
      "       0.        , 0.        , 0.        , 0.86956522, 0.        ,\n",
      "       0.69642857, 0.        , 0.5       , 0.66666667, 0.        ,\n",
      "       0.25      , 0.        , 0.        , 0.8       , 0.        ,\n",
      "       0.33333333, 0.        , 0.73333333, 0.42857143, 0.        ,\n",
      "       0.5       , 0.        , 1.        , 0.66666667, 0.83333333,\n",
      "       0.54166667, 0.5       , 0.        , 0.38461538, 0.83333333,\n",
      "       0.        , 0.64285714, 0.73333333, 0.66666667, 0.8       ,\n",
      "       0.        , 0.7       , 0.68      , 0.73076923, 0.6       ,\n",
      "       0.81818182, 0.        , 0.        , 0.28571429, 0.66666667,\n",
      "       1.        , 0.61744966, 0.80314961, 0.61538462, 0.27272727,\n",
      "       0.62886598, 0.        , 0.        , 0.83333333, 0.66666667,\n",
      "       0.5       ]), array([0.62638718, 0.        , 0.46666667, 0.        , 0.58333333,\n",
      "       0.        , 0.625     , 0.33333333, 0.53571429, 0.        ,\n",
      "       0.2       , 0.        , 0.63461538, 0.        , 0.        ,\n",
      "       0.48928571, 0.        , 0.        , 0.80555556, 0.66666667,\n",
      "       0.        , 0.16666667, 0.        , 0.1       , 0.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.5       ,\n",
      "       0.5631068 , 0.        , 0.25      , 0.        , 0.        ,\n",
      "       0.31428571, 0.25      , 0.57142857, 0.71428571, 0.2       ,\n",
      "       0.        , 0.        , 0.        , 0.52631579, 0.        ,\n",
      "       0.70588235, 0.        , 0.5       , 0.28571429, 0.        ,\n",
      "       0.07142857, 0.        , 0.        , 0.44444444, 0.        ,\n",
      "       0.2       , 0.        , 0.58928571, 0.35294118, 0.        ,\n",
      "       0.125     , 0.        , 0.25      , 0.85714286, 0.55555556,\n",
      "       0.56521739, 0.33333333, 0.        , 0.55555556, 0.38461538,\n",
      "       0.        , 0.34615385, 0.6875    , 0.66666667, 0.57142857,\n",
      "       0.        , 0.73684211, 0.59649123, 0.73076923, 0.75      ,\n",
      "       0.6       , 0.        , 0.        , 0.25      , 0.4       ,\n",
      "       0.6       , 0.49066667, 0.90515807, 0.44444444, 0.23076923,\n",
      "       0.53982301, 0.        , 0.        , 0.5       , 0.25      ,\n",
      "       0.2       ]), array([0.66405229, 0.        , 0.60869565, 0.        , 0.59322034,\n",
      "       0.        , 0.47619048, 0.36363636, 0.53097345, 0.        ,\n",
      "       0.18181818, 0.        , 0.7173913 , 0.        , 0.        ,\n",
      "       0.54150198, 0.        , 0.        , 0.75324675, 0.53333333,\n",
      "       0.        , 0.28571429, 0.        , 0.16666667, 0.        ,\n",
      "       0.        , 0.83870968, 0.        , 0.        , 0.61538462,\n",
      "       0.58883249, 0.        , 0.28571429, 0.        , 0.        ,\n",
      "       0.37288136, 0.4       , 0.61538462, 0.78947368, 0.28571429,\n",
      "       0.        , 0.        , 0.        , 0.6557377 , 0.        ,\n",
      "       0.7011236 , 0.        , 0.5       , 0.4       , 0.        ,\n",
      "       0.11111111, 0.        , 0.        , 0.57142857, 0.        ,\n",
      "       0.25      , 0.        , 0.65346535, 0.38709677, 0.        ,\n",
      "       0.2       , 0.        , 0.4       , 0.75      , 0.66666667,\n",
      "       0.55319149, 0.4       , 0.        , 0.45454545, 0.52631579,\n",
      "       0.        , 0.45      , 0.70967742, 0.66666667, 0.66666667,\n",
      "       0.        , 0.71794872, 0.63551402, 0.73076923, 0.66666667,\n",
      "       0.69230769, 0.        , 0.        , 0.26666667, 0.5       ,\n",
      "       0.75      , 0.54680535, 0.85110821, 0.51612903, 0.25      ,\n",
      "       0.58095238, 0.        , 0.        , 0.625     , 0.36363636,\n",
      "       0.28571429]), array([ 811,    2,   15,    1,   60,    5,    8,    6,   56,    2,    5,\n",
      "          1,   52,    1,    1,  280,    1,    2,   36,    6,    4,    6,\n",
      "          5,   10,    1,    1,   13,    5,    1,    8,  103,    3,    4,\n",
      "          1,    3,   35,    4,   14,   21,   15,    3,    0,    0,   38,\n",
      "          4,  221,    3,    2,    7,    1,   14,    2,    1,   18,    1,\n",
      "          5,    1,   56,   34,    2,    8,    3,    8,    7,    9,   23,\n",
      "          3,    5,    9,   13,    1,   26,   16,   18,    7,    1,   19,\n",
      "         57,   26,    4,   15,    1,    1,    8,   10,    5,  375, 3606,\n",
      "         18,   13,  113,    1,    1,   10,    8,    5]))\n",
      "Bons résultats 4831\n",
      "Erreurs: 1643\n",
      "Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[508   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  3   0   7 ...   0   0   0]\n",
      " ...\n",
      " [  1   0   0 ...   5   0   0]\n",
      " [  1   0   0 ...   0   2   0]\n",
      " [  0   0   0 ...   0   0   1]]\n",
      "(array([0.70653686, 0.        , 0.875     , 0.        , 0.60344828,\n",
      "       0.        , 0.38461538, 0.4       , 0.52631579, 0.        ,\n",
      "       0.16666667, 0.        , 0.825     , 0.        , 0.        ,\n",
      "       0.60619469, 0.        , 0.        , 0.70731707, 0.44444444,\n",
      "       0.        , 1.        , 0.        , 0.5       , 0.        ,\n",
      "       0.        , 0.72222222, 0.        , 0.        , 0.8       ,\n",
      "       0.61702128, 0.        , 0.33333333, 0.        , 0.        ,\n",
      "       0.45833333, 1.        , 0.66666667, 0.88235294, 0.5       ,\n",
      "       0.        , 0.        , 0.        , 0.86956522, 0.        ,\n",
      "       0.69642857, 0.        , 0.5       , 0.66666667, 0.        ,\n",
      "       0.25      , 0.        , 0.        , 0.8       , 0.        ,\n",
      "       0.33333333, 0.        , 0.73333333, 0.42857143, 0.        ,\n",
      "       0.5       , 0.        , 1.        , 0.66666667, 0.83333333,\n",
      "       0.54166667, 0.5       , 0.        , 0.38461538, 0.83333333,\n",
      "       0.        , 0.64285714, 0.73333333, 0.66666667, 0.8       ,\n",
      "       0.        , 0.7       , 0.68      , 0.73076923, 0.6       ,\n",
      "       0.81818182, 0.        , 0.        , 0.28571429, 0.66666667,\n",
      "       1.        , 0.61744966, 0.80314961, 0.61538462, 0.27272727,\n",
      "       0.62886598, 0.        , 0.        , 0.83333333, 0.66666667,\n",
      "       0.5       ]), array([0.62638718, 0.        , 0.46666667, 0.        , 0.58333333,\n",
      "       0.        , 0.625     , 0.33333333, 0.53571429, 0.        ,\n",
      "       0.2       , 0.        , 0.63461538, 0.        , 0.        ,\n",
      "       0.48928571, 0.        , 0.        , 0.80555556, 0.66666667,\n",
      "       0.        , 0.16666667, 0.        , 0.1       , 0.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.5       ,\n",
      "       0.5631068 , 0.        , 0.25      , 0.        , 0.        ,\n",
      "       0.31428571, 0.25      , 0.57142857, 0.71428571, 0.2       ,\n",
      "       0.        , 0.        , 0.        , 0.52631579, 0.        ,\n",
      "       0.70588235, 0.        , 0.5       , 0.28571429, 0.        ,\n",
      "       0.07142857, 0.        , 0.        , 0.44444444, 0.        ,\n",
      "       0.2       , 0.        , 0.58928571, 0.35294118, 0.        ,\n",
      "       0.125     , 0.        , 0.25      , 0.85714286, 0.55555556,\n",
      "       0.56521739, 0.33333333, 0.        , 0.55555556, 0.38461538,\n",
      "       0.        , 0.34615385, 0.6875    , 0.66666667, 0.57142857,\n",
      "       0.        , 0.73684211, 0.59649123, 0.73076923, 0.75      ,\n",
      "       0.6       , 0.        , 0.        , 0.25      , 0.4       ,\n",
      "       0.6       , 0.49066667, 0.90515807, 0.44444444, 0.23076923,\n",
      "       0.53982301, 0.        , 0.        , 0.5       , 0.25      ,\n",
      "       0.2       ]), array([0.66405229, 0.        , 0.60869565, 0.        , 0.59322034,\n",
      "       0.        , 0.47619048, 0.36363636, 0.53097345, 0.        ,\n",
      "       0.18181818, 0.        , 0.7173913 , 0.        , 0.        ,\n",
      "       0.54150198, 0.        , 0.        , 0.75324675, 0.53333333,\n",
      "       0.        , 0.28571429, 0.        , 0.16666667, 0.        ,\n",
      "       0.        , 0.83870968, 0.        , 0.        , 0.61538462,\n",
      "       0.58883249, 0.        , 0.28571429, 0.        , 0.        ,\n",
      "       0.37288136, 0.4       , 0.61538462, 0.78947368, 0.28571429,\n",
      "       0.        , 0.        , 0.        , 0.6557377 , 0.        ,\n",
      "       0.7011236 , 0.        , 0.5       , 0.4       , 0.        ,\n",
      "       0.11111111, 0.        , 0.        , 0.57142857, 0.        ,\n",
      "       0.25      , 0.        , 0.65346535, 0.38709677, 0.        ,\n",
      "       0.2       , 0.        , 0.4       , 0.75      , 0.66666667,\n",
      "       0.55319149, 0.4       , 0.        , 0.45454545, 0.52631579,\n",
      "       0.        , 0.45      , 0.70967742, 0.66666667, 0.66666667,\n",
      "       0.        , 0.71794872, 0.63551402, 0.73076923, 0.66666667,\n",
      "       0.69230769, 0.        , 0.        , 0.26666667, 0.5       ,\n",
      "       0.75      , 0.54680535, 0.85110821, 0.51612903, 0.25      ,\n",
      "       0.58095238, 0.        , 0.        , 0.625     , 0.36363636,\n",
      "       0.28571429]), array([ 811,    2,   15,    1,   60,    5,    8,    6,   56,    2,    5,\n",
      "          1,   52,    1,    1,  280,    1,    2,   36,    6,    4,    6,\n",
      "          5,   10,    1,    1,   13,    5,    1,    8,  103,    3,    4,\n",
      "          1,    3,   35,    4,   14,   21,   15,    3,    0,    0,   38,\n",
      "          4,  221,    3,    2,    7,    1,   14,    2,    1,   18,    1,\n",
      "          5,    1,   56,   34,    2,    8,    3,    8,    7,    9,   23,\n",
      "          3,    5,    9,   13,    1,   26,   16,   18,    7,    1,   19,\n",
      "         57,   26,    4,   15,    1,    1,    8,   10,    5,  375, 3606,\n",
      "         18,   13,  113,    1,    1,   10,    8,    5]))\n",
      "Bons résultats 4831\n",
      "Erreurs: 1643\n",
      "Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"En fixant random state\")\n",
    "for i in range(3):\n",
    "  DT = tree.DecisionTreeClassifier(random_state=0)\n",
    "  DT = DT.fit(X_train, y_train)\n",
    "  y_pred = DT.predict(X_test)\n",
    "  matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "  print(matrice_confusion)\n",
    "  stats = precision_recall_fscore_support(y_test, y_pred)\n",
    "  print(stats)\n",
    "  print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "  print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "  print ('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Différents paramètres que l'on peut faire varier : max_depth, min_samples_split, min_samples_leaf et max_features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On teste max_depth\n",
      "Avec max_depth= 1\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Bons résultats 3690\n",
      "Erreurs: 2784\n",
      "Accuracy: 0.57\n",
      "Avec max_depth= 2\n",
      "[[202   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3750\n",
      "Erreurs: 2724\n",
      "Accuracy: 0.58\n",
      "Avec max_depth= 3\n",
      "[[204   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3825\n",
      "Erreurs: 2649\n",
      "Accuracy: 0.59\n",
      "Avec max_depth= 4\n",
      "[[270   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3911\n",
      "Erreurs: 2563\n",
      "Accuracy: 0.60\n",
      "Avec max_depth= 5\n",
      "[[271   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3925\n",
      "Erreurs: 2549\n",
      "Accuracy: 0.61\n",
      "Avec max_depth= 6\n",
      "[[268   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3968\n",
      "Erreurs: 2506\n",
      "Accuracy: 0.61\n",
      "Avec max_depth= 7\n",
      "[[271   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4019\n",
      "Erreurs: 2455\n",
      "Accuracy: 0.62\n",
      "Avec max_depth= 8\n",
      "[[271   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4066\n",
      "Erreurs: 2408\n",
      "Accuracy: 0.63\n",
      "Avec max_depth= 9\n",
      "[[272   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4106\n",
      "Erreurs: 2368\n",
      "Accuracy: 0.63\n",
      "Avec max_depth= 10\n",
      "[[318   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4152\n",
      "Erreurs: 2322\n",
      "Accuracy: 0.64\n",
      "Avec max_depth= 11\n",
      "[[316   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4186\n",
      "Erreurs: 2288\n",
      "Accuracy: 0.65\n",
      "Avec max_depth= 12\n",
      "[[348   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4205\n",
      "Erreurs: 2269\n",
      "Accuracy: 0.65\n",
      "Avec max_depth= 13\n",
      "[[349   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4222\n",
      "Erreurs: 2252\n",
      "Accuracy: 0.65\n",
      "Avec max_depth= 14\n",
      "[[348   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4257\n",
      "Erreurs: 2217\n",
      "Accuracy: 0.66\n",
      "Avec max_depth= 15\n",
      "[[350   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4273\n",
      "Erreurs: 2201\n",
      "Accuracy: 0.66\n",
      "Avec max_depth= 16\n",
      "[[348   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4284\n",
      "Erreurs: 2190\n",
      "Accuracy: 0.66\n",
      "Avec max_depth= 17\n",
      "[[391   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4304\n",
      "Erreurs: 2170\n",
      "Accuracy: 0.66\n",
      "Avec max_depth= 18\n",
      "[[386   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4328\n",
      "Erreurs: 2146\n",
      "Accuracy: 0.67\n",
      "Avec max_depth= 19\n",
      "[[389   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4349\n",
      "Erreurs: 2125\n",
      "Accuracy: 0.67\n",
      "Avec max_depth= 20\n",
      "[[384   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4372\n",
      "Erreurs: 2102\n",
      "Accuracy: 0.68\n",
      "Avec max_depth= 21\n",
      "[[400   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4387\n",
      "Erreurs: 2087\n",
      "Accuracy: 0.68\n",
      "Avec max_depth= 22\n",
      "[[398   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4406\n",
      "Erreurs: 2068\n",
      "Accuracy: 0.68\n",
      "Avec max_depth= 23\n",
      "[[399   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4422\n",
      "Erreurs: 2052\n",
      "Accuracy: 0.68\n",
      "Avec max_depth= 24\n",
      "[[407   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4439\n",
      "Erreurs: 2035\n",
      "Accuracy: 0.69\n",
      "Avec max_depth= 25\n",
      "[[397   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4440\n",
      "Erreurs: 2034\n",
      "Accuracy: 0.69\n",
      "Avec max_depth= 26\n",
      "[[399   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4453\n",
      "Erreurs: 2021\n",
      "Accuracy: 0.69\n",
      "Avec max_depth= 27\n",
      "[[405   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4463\n",
      "Erreurs: 2011\n",
      "Accuracy: 0.69\n",
      "Avec max_depth= 28\n",
      "[[408   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4473\n",
      "Erreurs: 2001\n",
      "Accuracy: 0.69\n",
      "Avec max_depth= 29\n",
      "[[404   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4465\n",
      "Erreurs: 2009\n",
      "Accuracy: 0.69\n",
      "Avec max_depth= 30\n",
      "[[417   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4482\n",
      "Erreurs: 1992\n",
      "Accuracy: 0.69\n",
      "Avec max_depth= 31\n",
      "[[421   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4491\n",
      "Erreurs: 1983\n",
      "Accuracy: 0.69\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-4b2b5281acf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mDT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mDT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mmatrice_confusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \"\"\"\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    891\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"On teste max_depth\")\n",
    "for i in range(1, 20):\n",
    "  DT = tree.DecisionTreeClassifier(max_depth=i)\n",
    "  DT = DT.fit(X_train, y_train)\n",
    "  y_pred = DT.predict(X_test)\n",
    "  matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "  print(\"Avec max_depth=\", i)\n",
    "  print(matrice_confusion)\n",
    "  print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "  print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "  print ('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meilleur résultat obtenu :\n",
    "Avec max_depth= 96\n",
    "[[1265   49]\n",
    " [  30  375]]\n",
    "(array([0.97683398, 0.88443396]), array([0.96270928, 0.92592593]), array([0.9697202 , 0.90470446]), array([1314,  405]))\n",
    "Bons résultats 1640\n",
    "Erreurs: 79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On teste min_samples_split:\n",
      "Avec max_depth= 1\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Bons résultats 3690\n",
      "Erreurs: 2784\n",
      "Accuracy: 0.57\n",
      "Avec max_depth= 2\n",
      "[[202   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3750\n",
      "Erreurs: 2724\n",
      "Accuracy: 0.58\n",
      "Avec max_depth= 3\n",
      "[[204   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3825\n",
      "Erreurs: 2649\n",
      "Accuracy: 0.59\n",
      "Avec max_depth= 4\n",
      "[[270   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3910\n",
      "Erreurs: 2564\n",
      "Accuracy: 0.60\n",
      "Avec max_depth= 5\n",
      "[[271   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3923\n",
      "Erreurs: 2551\n",
      "Accuracy: 0.61\n",
      "Avec max_depth= 6\n",
      "[[268   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3968\n",
      "Erreurs: 2506\n",
      "Accuracy: 0.61\n",
      "Avec max_depth= 7\n",
      "[[272   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4018\n",
      "Erreurs: 2456\n",
      "Accuracy: 0.62\n",
      "Avec max_depth= 8\n",
      "[[271   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4064\n",
      "Erreurs: 2410\n",
      "Accuracy: 0.63\n",
      "Avec max_depth= 9\n",
      "[[271   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4101\n",
      "Erreurs: 2373\n",
      "Accuracy: 0.63\n",
      "Avec max_depth= 10\n",
      "[[320   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4149\n",
      "Erreurs: 2325\n",
      "Accuracy: 0.64\n",
      "Avec max_depth= 11\n",
      "[[318   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4181\n",
      "Erreurs: 2293\n",
      "Accuracy: 0.65\n",
      "Avec max_depth= 12\n",
      "[[349   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4206\n",
      "Erreurs: 2268\n",
      "Accuracy: 0.65\n",
      "Avec max_depth= 13\n",
      "[[349   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4230\n",
      "Erreurs: 2244\n",
      "Accuracy: 0.65\n",
      "Avec max_depth= 14\n",
      "[[348   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4254\n",
      "Erreurs: 2220\n",
      "Accuracy: 0.66\n",
      "Avec max_depth= 15\n",
      "[[345   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4269\n",
      "Erreurs: 2205\n",
      "Accuracy: 0.66\n",
      "Avec max_depth= 16\n",
      "[[347   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4281\n",
      "Erreurs: 2193\n",
      "Accuracy: 0.66\n",
      "Avec max_depth= 17\n",
      "[[391   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4311\n",
      "Erreurs: 2163\n",
      "Accuracy: 0.67\n",
      "Avec max_depth= 18\n",
      "[[388   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4340\n",
      "Erreurs: 2134\n",
      "Accuracy: 0.67\n",
      "Avec max_depth= 19\n",
      "[[387   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4361\n",
      "Erreurs: 2113\n",
      "Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "print(\"On teste min_samples_split:\")\n",
    "for i in range(1, 20):\n",
    "  DT = tree.DecisionTreeClassifier(max_depth=i)\n",
    "  DT = DT.fit(X_train, y_train)\n",
    "  y_pred = DT.predict(X_test)\n",
    "  matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "  print(\"Avec max_depth=\", i)\n",
    "  print(matrice_confusion)\n",
    "  print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "  print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "  print ('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On teste min_samples_leaf:\n",
      "Avec max_depth= 1\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Bons résultats 3690\n",
      "Erreurs: 2784\n",
      "Accuracy: 0.57\n",
      "Avec max_depth= 2\n",
      "[[202   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3750\n",
      "Erreurs: 2724\n",
      "Accuracy: 0.58\n",
      "Avec max_depth= 3\n",
      "[[204   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3825\n",
      "Erreurs: 2649\n",
      "Accuracy: 0.59\n",
      "Avec max_depth= 4\n",
      "[[270   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3911\n",
      "Erreurs: 2563\n",
      "Accuracy: 0.60\n",
      "Avec max_depth= 5\n",
      "[[271   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3924\n",
      "Erreurs: 2550\n",
      "Accuracy: 0.61\n",
      "Avec max_depth= 6\n",
      "[[270   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3970\n",
      "Erreurs: 2504\n",
      "Accuracy: 0.61\n",
      "Avec max_depth= 7\n",
      "[[272   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4016\n",
      "Erreurs: 2458\n",
      "Accuracy: 0.62\n",
      "Avec max_depth= 8\n",
      "[[272   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4070\n",
      "Erreurs: 2404\n",
      "Accuracy: 0.63\n",
      "Avec max_depth= 9\n",
      "[[273   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4107\n",
      "Erreurs: 2367\n",
      "Accuracy: 0.63\n",
      "Avec max_depth= 10\n",
      "[[319   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4149\n",
      "Erreurs: 2325\n",
      "Accuracy: 0.64\n",
      "Avec max_depth= 11\n",
      "[[319   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4191\n",
      "Erreurs: 2283\n",
      "Accuracy: 0.65\n",
      "Avec max_depth= 12\n",
      "[[347   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4199\n",
      "Erreurs: 2275\n",
      "Accuracy: 0.65\n",
      "Avec max_depth= 13\n",
      "[[352   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4226\n",
      "Erreurs: 2248\n",
      "Accuracy: 0.65\n",
      "Avec max_depth= 14\n",
      "[[346   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4246\n",
      "Erreurs: 2228\n",
      "Accuracy: 0.66\n",
      "Avec max_depth= 15\n",
      "[[346   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4271\n",
      "Erreurs: 2203\n",
      "Accuracy: 0.66\n",
      "Avec max_depth= 16\n",
      "[[349   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4284\n",
      "Erreurs: 2190\n",
      "Accuracy: 0.66\n",
      "Avec max_depth= 17\n",
      "[[392   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4305\n",
      "Erreurs: 2169\n",
      "Accuracy: 0.66\n",
      "Avec max_depth= 18\n",
      "[[386   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4333\n",
      "Erreurs: 2141\n",
      "Accuracy: 0.67\n",
      "Avec max_depth= 19\n",
      "[[386   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4354\n",
      "Erreurs: 2120\n",
      "Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "print(\"On teste min_samples_leaf:\")\n",
    "for i in range(1, 20):\n",
    "  DT = tree.DecisionTreeClassifier(max_depth=i)\n",
    "  DT = DT.fit(X_train, y_train)\n",
    "  y_pred = DT.predict(X_test)\n",
    "  matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "  print(\"Avec max_depth=\", i)\n",
    "  print(matrice_confusion)\n",
    "  print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "  print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "  print ('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On teste max_features:\n",
      "Avec max_depth= 1\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Bons résultats 3690\n",
      "Erreurs: 2784\n",
      "Accuracy: 0.57\n",
      "Avec max_depth= 2\n",
      "[[202   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3750\n",
      "Erreurs: 2724\n",
      "Accuracy: 0.58\n",
      "Avec max_depth= 3\n",
      "[[204   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3825\n",
      "Erreurs: 2649\n",
      "Accuracy: 0.59\n",
      "Avec max_depth= 4\n",
      "[[270   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3910\n",
      "Erreurs: 2564\n",
      "Accuracy: 0.60\n",
      "Avec max_depth= 5\n",
      "[[271   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3922\n",
      "Erreurs: 2552\n",
      "Accuracy: 0.61\n",
      "Avec max_depth= 6\n",
      "[[269   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 3969\n",
      "Erreurs: 2505\n",
      "Accuracy: 0.61\n",
      "Avec max_depth= 7\n",
      "[[270   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4016\n",
      "Erreurs: 2458\n",
      "Accuracy: 0.62\n",
      "Avec max_depth= 8\n",
      "[[272   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4070\n",
      "Erreurs: 2404\n",
      "Accuracy: 0.63\n",
      "Avec max_depth= 9\n",
      "[[270   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4099\n",
      "Erreurs: 2375\n",
      "Accuracy: 0.63\n",
      "Avec max_depth= 10\n",
      "[[320   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4155\n",
      "Erreurs: 2319\n",
      "Accuracy: 0.64\n",
      "Avec max_depth= 11\n",
      "[[318   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4185\n",
      "Erreurs: 2289\n",
      "Accuracy: 0.65\n",
      "Avec max_depth= 12\n",
      "[[349   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4205\n",
      "Erreurs: 2269\n",
      "Accuracy: 0.65\n",
      "Avec max_depth= 13\n",
      "[[350   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4225\n",
      "Erreurs: 2249\n",
      "Accuracy: 0.65\n",
      "Avec max_depth= 14\n",
      "[[348   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4248\n",
      "Erreurs: 2226\n",
      "Accuracy: 0.66\n",
      "Avec max_depth= 15\n",
      "[[347   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4268\n",
      "Erreurs: 2206\n",
      "Accuracy: 0.66\n",
      "Avec max_depth= 16\n",
      "[[348   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4287\n",
      "Erreurs: 2187\n",
      "Accuracy: 0.66\n",
      "Avec max_depth= 17\n",
      "[[390   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4308\n",
      "Erreurs: 2166\n",
      "Accuracy: 0.67\n",
      "Avec max_depth= 18\n",
      "[[384   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4335\n",
      "Erreurs: 2139\n",
      "Accuracy: 0.67\n",
      "Avec max_depth= 19\n",
      "[[386   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "Bons résultats 4353\n",
      "Erreurs: 2121\n",
      "Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "print(\"On teste max_features:\")\n",
    "for i in range(1, 20):\n",
    "  DT = tree.DecisionTreeClassifier(max_depth=i)\n",
    "  DT = DT.fit(X_train, y_train)\n",
    "  y_pred = DT.predict(X_test)\n",
    "  matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "  print(\"Avec max_depth=\", i)\n",
    "  print(matrice_confusion)\n",
    "  print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "  print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "  print ('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour ces trois derniers paramètres on ne passe jamais sous la barre des 85 erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autres caracétristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nb_phrases= 0\n",
    "for i in texte:\n",
    "    longueur_text=len(sent_tokenize(i))\n",
    "    nb_phrases += longueur_text\n",
    "    \n",
    "X_stylo = []#notre nouvelle matrice de description\n",
    "for text in texte:\n",
    "    mots=word_tokenize(text)\n",
    "    phrases = sent_tokenize(text)\n",
    "    NB_mots = len(mots)\n",
    "    NB_caracteres = len(text)\n",
    "    for x in mots :\n",
    "        moyenne_taille_mots = statistics.mean([len(x)])\n",
    "    moyenne_taille_phrases = NB_mots/nb_phrases\n",
    "    caracteristiques = [nb_phrases, NB_mots, NB_caracteres, moyenne_taille_mots, moyenne_taille_phrases]\n",
    "    X_stylo.append(caracteristiques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[567   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  1   0   0 ...   0   0   0]\n",
      " [  1   0   0 ...   0   0   0]\n",
      " [  1   0   0 ...   0   0   0]]\n",
      "(array([0.77038043, 0.        , 0.        , 0.        , 0.16666667,\n",
      "       0.        , 0.        , 0.        , 0.33333333, 0.        ,\n",
      "       0.        , 0.        , 0.22222222, 0.        , 0.        ,\n",
      "       0.18181818, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.14427861, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.19266055,\n",
      "       0.64659832, 0.33333333, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        ]), array([0.69913687, 0.        , 0.        , 0.        , 0.01666667,\n",
      "       0.        , 0.        , 0.        , 0.01785714, 0.        ,\n",
      "       0.        , 0.        , 0.03846154, 0.        , 0.        ,\n",
      "       0.00714286, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.13122172, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.05263158,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.056     ,\n",
      "       0.96200776, 0.05555556, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        ]), array([0.73303167, 0.        , 0.        , 0.        , 0.03030303,\n",
      "       0.        , 0.        , 0.        , 0.03389831, 0.        ,\n",
      "       0.        , 0.        , 0.06557377, 0.        , 0.        ,\n",
      "       0.0137457 , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.13744076, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.0952381 ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.08677686,\n",
      "       0.77338089, 0.0952381 , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        ]), array([ 811,    2,   15,    1,   60,    5,    8,    6,   56,    2,    5,\n",
      "          1,   52,    1,    1,  280,    1,    2,   36,    6,    4,    6,\n",
      "          5,   10,    1,    1,   13,    5,    1,    8,  103,    3,    4,\n",
      "          1,    3,   35,    4,   14,   21,   15,    3,   38,    4,  221,\n",
      "          3,    2,    7,    1,   14,    2,    1,   18,    1,    5,    1,\n",
      "         56,   34,    2,    8,    3,    8,    7,    9,   23,    3,    5,\n",
      "          9,   13,    1,   26,   16,   18,    7,    1,   19,   57,   26,\n",
      "          4,   15,    1,    1,    8,   10,    5,  375, 3606,   18,   13,\n",
      "        113,    1,    1,   10,    8,    5]))\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                          0.77      0.70      0.73       811\n",
      "            algeria       0.00      0.00      0.00         2\n",
      "          argentina       0.00      0.00      0.00        15\n",
      "              aruba       0.00      0.00      0.00         1\n",
      "          australia       0.17      0.02      0.03        60\n",
      "            austria       0.00      0.00      0.00         5\n",
      "            bahrain       0.00      0.00      0.00         8\n",
      "         bangladesh       0.00      0.00      0.00         6\n",
      "            belgium       0.33      0.02      0.03        56\n",
      "            bermuda       0.00      0.00      0.00         2\n",
      "            bolivia       0.00      0.00      0.00         5\n",
      "           botswana       0.00      0.00      0.00         1\n",
      "             brazil       0.22      0.04      0.07        52\n",
      "              burma       0.00      0.00      0.00         1\n",
      "           cameroon       0.00      0.00      0.00         1\n",
      "             canada       0.18      0.01      0.01       280\n",
      "               chad       0.00      0.00      0.00         1\n",
      "              chile       0.00      0.00      0.00         2\n",
      "              china       0.00      0.00      0.00        36\n",
      "           colombia       0.00      0.00      0.00         6\n",
      "         costa-rica       0.00      0.00      0.00         4\n",
      "               cuba       0.00      0.00      0.00         6\n",
      "             cyprus       0.00      0.00      0.00         5\n",
      "            denmark       0.00      0.00      0.00        10\n",
      " dominican-republic       0.00      0.00      0.00         1\n",
      "       east-germany       0.00      0.00      0.00         1\n",
      "            ecuador       0.00      0.00      0.00        13\n",
      "              egypt       0.00      0.00      0.00         5\n",
      "               fiji       0.00      0.00      0.00         1\n",
      "            finland       0.00      0.00      0.00         8\n",
      "             france       0.00      0.00      0.00       103\n",
      "              ghana       0.00      0.00      0.00         3\n",
      "             greece       0.00      0.00      0.00         4\n",
      "             guyana       0.00      0.00      0.00         1\n",
      "              haiti       0.00      0.00      0.00         3\n",
      "          hong-kong       0.00      0.00      0.00        35\n",
      "            hungary       0.00      0.00      0.00         4\n",
      "              india       0.00      0.00      0.00        14\n",
      "          indonesia       0.00      0.00      0.00        21\n",
      "               iran       0.00      0.00      0.00        15\n",
      "               iraq       0.00      0.00      0.00         3\n",
      "              italy       0.00      0.00      0.00        38\n",
      "        ivory-coast       0.00      0.00      0.00         4\n",
      "              japan       0.14      0.13      0.14       221\n",
      "             jordan       0.00      0.00      0.00         3\n",
      "              kenya       0.00      0.00      0.00         2\n",
      "             kuwait       0.00      0.00      0.00         7\n",
      "            lebanon       0.00      0.00      0.00         1\n",
      "         luxembourg       0.00      0.00      0.00        14\n",
      "         madagascar       0.00      0.00      0.00         2\n",
      "             malawi       0.00      0.00      0.00         1\n",
      "           malaysia       0.00      0.00      0.00        18\n",
      "          mauritius       0.00      0.00      0.00         1\n",
      "             mexico       0.00      0.00      0.00         5\n",
      "            morocco       0.00      0.00      0.00         1\n",
      "        netherlands       0.00      0.00      0.00        56\n",
      "        new-zealand       0.00      0.00      0.00        34\n",
      "          nicaragua       0.00      0.00      0.00         2\n",
      "            nigeria       0.00      0.00      0.00         8\n",
      "        north-korea       0.00      0.00      0.00         3\n",
      "             norway       0.00      0.00      0.00         8\n",
      "           pakistan       0.00      0.00      0.00         7\n",
      "               peru       0.00      0.00      0.00         9\n",
      "        philippines       0.00      0.00      0.00        23\n",
      "             poland       0.00      0.00      0.00         3\n",
      "           portugal       0.00      0.00      0.00         5\n",
      "       saudi-arabia       0.00      0.00      0.00         9\n",
      "          singapore       0.00      0.00      0.00        13\n",
      "            somalia       0.00      0.00      0.00         1\n",
      "       south-africa       0.00      0.00      0.00        26\n",
      "        south-korea       0.00      0.00      0.00        16\n",
      "              spain       0.00      0.00      0.00        18\n",
      "          sri-lanka       0.00      0.00      0.00         7\n",
      "              sudan       0.00      0.00      0.00         1\n",
      "             sweden       0.50      0.05      0.10        19\n",
      "        switzerland       0.00      0.00      0.00        57\n",
      "             taiwan       0.00      0.00      0.00        26\n",
      "           tanzania       0.00      0.00      0.00         4\n",
      "           thailand       0.00      0.00      0.00        15\n",
      "               togo       0.00      0.00      0.00         1\n",
      "            tunisia       0.00      0.00      0.00         1\n",
      "             turkey       0.00      0.00      0.00         8\n",
      "                uae       0.00      0.00      0.00        10\n",
      "             uganda       0.00      0.00      0.00         5\n",
      "                 uk       0.19      0.06      0.09       375\n",
      "                usa       0.65      0.96      0.77      3606\n",
      "               ussr       0.33      0.06      0.10        18\n",
      "          venezuela       0.00      0.00      0.00        13\n",
      "       west-germany       0.00      0.00      0.00       113\n",
      "yemen-arab-republic       0.00      0.00      0.00         1\n",
      "yemen-demo-republic       0.00      0.00      0.00         1\n",
      "         yugoslavia       0.00      0.00      0.00        10\n",
      "             zambia       0.00      0.00      0.00         8\n",
      "           zimbabwe       0.00      0.00      0.00         5\n",
      "\n",
      "           accuracy                           0.63      6474\n",
      "          macro avg       0.04      0.02      0.02      6474\n",
      "       weighted avg       0.49      0.63      0.53      6474\n",
      "\n",
      "Accuracy: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_stylo, y, test_size=0.3, random_state=0)\n",
    "DT = tree.DecisionTreeClassifier()\n",
    "DT = DT.fit(X_train, y_train)\n",
    "y_pred = DT.predict(X_test)\n",
    "matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "print(matrice_confusion)\n",
    "stats = precision_recall_fscore_support(y_test, y_pred)\n",
    "print(stats)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "print ('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taux d'exactitude très mauvais puisqu'on fait moins que le hasard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Et maintenant on combine le BOW et le stylométrique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21578\n",
      "93417\n",
      "21578\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "## on regarde la \"forme\" de X\n",
    "print(X.shape[0])#NB lignes   -> instances\n",
    "print(X.shape[1])#Nb colonnes -> caractéristiques\n",
    "\n",
    "##on crée une sparse matrix avec notre X_stylo\n",
    "from scipy.sparse import csr_matrix\n",
    "sparse_stylo = csr_matrix(X_stylo)\n",
    "print(sparse_stylo.shape[0])#NB lignes   -> instances\n",
    "print(sparse_stylo.shape[1])#Nb colonnes -> caractéristiques\n",
    "\n",
    "## on a le même nombre de ligne, on fait donc une conctaténation horizontale :\n",
    "from scipy.sparse import hstack\n",
    "X_fusion = hstack((X, sparse_stylo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résultats:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[643   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  3   0   8 ...   0   0   0]\n",
      " ...\n",
      " [  1   0   0 ...   5   0   0]\n",
      " [  1   0   0 ...   0   1   0]\n",
      " [  0   0   0 ...   0   0   3]]\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                          0.79      0.79      0.79       811\n",
      "            algeria       0.00      0.00      0.00         2\n",
      "          argentina       0.89      0.53      0.67        15\n",
      "              aruba       0.00      0.00      0.00         1\n",
      "          australia       0.42      0.43      0.43        60\n",
      "            austria       0.00      0.00      0.00         5\n",
      "            bahrain       0.00      0.00      0.00         8\n",
      "         bangladesh       0.33      0.17      0.22         6\n",
      "            belgium       0.43      0.38      0.40        56\n",
      "            bermuda       0.00      0.00      0.00         2\n",
      "            bolivia       0.17      0.20      0.18         5\n",
      "           botswana       0.00      0.00      0.00         1\n",
      "             brazil       0.64      0.62      0.63        52\n",
      "           bulgaria       0.00      0.00      0.00         0\n",
      "              burma       0.00      0.00      0.00         1\n",
      "           cameroon       0.00      0.00      0.00         1\n",
      "             canada       0.59      0.39      0.47       280\n",
      "               chad       0.00      0.00      0.00         1\n",
      "              chile       0.00      0.00      0.00         2\n",
      "              china       0.85      0.61      0.71        36\n",
      "           colombia       0.14      0.17      0.15         6\n",
      "         costa-rica       0.00      0.00      0.00         4\n",
      "               cuba       1.00      0.17      0.29         6\n",
      "             cyprus       0.00      0.00      0.00         5\n",
      "            denmark       0.50      0.20      0.29        10\n",
      " dominican-republic       0.00      0.00      0.00         1\n",
      "       east-germany       0.00      0.00      0.00         1\n",
      "            ecuador       0.75      0.69      0.72        13\n",
      "              egypt       0.00      0.00      0.00         5\n",
      "               fiji       0.00      0.00      0.00         1\n",
      "            finland       0.50      0.12      0.20         8\n",
      "             france       0.66      0.46      0.54       103\n",
      "              ghana       0.00      0.00      0.00         3\n",
      "             greece       1.00      0.25      0.40         4\n",
      "             guyana       0.00      0.00      0.00         1\n",
      "              haiti       0.00      0.00      0.00         3\n",
      "          hong-kong       0.22      0.14      0.17        35\n",
      "            hungary       0.50      0.25      0.33         4\n",
      "              india       1.00      0.43      0.60        14\n",
      "          indonesia       0.67      0.67      0.67        21\n",
      "               iran       0.50      0.20      0.29        15\n",
      "               iraq       0.00      0.00      0.00         3\n",
      "              italy       0.62      0.39      0.48        38\n",
      "        ivory-coast       0.00      0.00      0.00         4\n",
      "            jamaica       0.00      0.00      0.00         0\n",
      "              japan       0.62      0.63      0.63       221\n",
      "             jordan       0.00      0.00      0.00         3\n",
      "              kenya       0.00      0.00      0.00         2\n",
      "             kuwait       0.00      0.00      0.00         7\n",
      "            lebanon       0.00      0.00      0.00         1\n",
      "         luxembourg       0.25      0.07      0.11        14\n",
      "         madagascar       0.00      0.00      0.00         2\n",
      "             malawi       0.00      0.00      0.00         1\n",
      "           malaysia       0.56      0.28      0.37        18\n",
      "          mauritius       0.00      0.00      0.00         1\n",
      "             mexico       0.50      0.20      0.29         5\n",
      "            morocco       0.00      0.00      0.00         1\n",
      "        netherlands       0.57      0.50      0.53        56\n",
      "        new-zealand       0.73      0.32      0.45        34\n",
      "          nicaragua       0.00      0.00      0.00         2\n",
      "            nigeria       1.00      0.12      0.22         8\n",
      "        north-korea       0.00      0.00      0.00         3\n",
      "             norway       0.50      0.38      0.43         8\n",
      "           pakistan       1.00      0.57      0.73         7\n",
      "             panama       0.00      0.00      0.00         0\n",
      "               peru       0.62      0.56      0.59         9\n",
      "        philippines       0.82      0.39      0.53        23\n",
      "             poland       0.00      0.00      0.00         3\n",
      "           portugal       0.00      0.00      0.00         5\n",
      "       saudi-arabia       0.67      0.22      0.33         9\n",
      "          singapore       0.60      0.23      0.33        13\n",
      "            somalia       0.00      0.00      0.00         1\n",
      "       south-africa       0.69      0.42      0.52        26\n",
      "        south-korea       0.91      0.62      0.74        16\n",
      "              spain       0.67      0.56      0.61        18\n",
      "          sri-lanka       1.00      0.14      0.25         7\n",
      "              sudan       0.00      0.00      0.00         1\n",
      "             sweden       0.46      0.58      0.51        19\n",
      "        switzerland       0.83      0.51      0.63        57\n",
      "             taiwan       0.81      0.81      0.81        26\n",
      "           tanzania       0.67      0.50      0.57         4\n",
      "           thailand       0.38      0.20      0.26        15\n",
      "               togo       0.00      0.00      0.00         1\n",
      "            tunisia       0.00      0.00      0.00         1\n",
      "             turkey       0.67      0.25      0.36         8\n",
      "                uae       0.75      0.30      0.43        10\n",
      "             uganda       1.00      0.20      0.33         5\n",
      "                 uk       0.48      0.37      0.41       375\n",
      "                usa       0.79      0.92      0.85      3606\n",
      "               ussr       0.38      0.28      0.32        18\n",
      "          venezuela       0.67      0.46      0.55        13\n",
      "       west-germany       0.66      0.48      0.55       113\n",
      "yemen-arab-republic       0.00      0.00      0.00         1\n",
      "yemen-demo-republic       0.00      0.00      0.00         1\n",
      "         yugoslavia       0.62      0.50      0.56        10\n",
      "             zambia       0.50      0.12      0.20         8\n",
      "           zimbabwe       0.75      0.60      0.67         5\n",
      "\n",
      "           accuracy                           0.74      6474\n",
      "          macro avg       0.36      0.22      0.26      6474\n",
      "       weighted avg       0.72      0.74      0.72      6474\n",
      "\n",
      "Bons résultats 4800\n",
      "Erreurs: 1674\n",
      "Accuracy: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/alexj/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_fusion, y, test_size=0.3, random_state=0)\n",
    "DT = tree.DecisionTreeClassifier()\n",
    "DT = DT.fit(X_train, y_train)\n",
    "y_pred = DT.predict(X_test)\n",
    "matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "print(matrice_confusion)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "print ('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#résultats moyens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autres classifieurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "LR = LogisticRegression()\n",
    "RDF = RandomForestClassifier()\n",
    "SVC = SVC()\n",
    "KN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                          0.00      0.00      0.00       811\n",
      "            algeria       0.00      0.00      0.00         2\n",
      "          argentina       0.00      0.00      0.00        15\n",
      "              aruba       0.00      0.00      0.00         1\n",
      "          australia       0.00      0.00      0.00        60\n",
      "            austria       0.00      0.00      0.00         5\n",
      "            bahrain       0.00      0.00      0.00         8\n",
      "         bangladesh       0.00      0.00      0.00         6\n",
      "            belgium       0.00      0.00      0.00        56\n",
      "            bermuda       0.00      0.00      0.00         2\n",
      "            bolivia       0.00      0.00      0.00         5\n",
      "           botswana       0.00      0.00      0.00         1\n",
      "             brazil       0.00      0.00      0.00        52\n",
      "              burma       0.00      0.00      0.00         1\n",
      "           cameroon       0.00      0.00      0.00         1\n",
      "             canada       0.00      0.00      0.00       280\n",
      "               chad       0.00      0.00      0.00         1\n",
      "              chile       0.00      0.00      0.00         2\n",
      "              china       0.00      0.00      0.00        36\n",
      "           colombia       0.00      0.00      0.00         6\n",
      "         costa-rica       0.00      0.00      0.00         4\n",
      "               cuba       0.00      0.00      0.00         6\n",
      "             cyprus       0.00      0.00      0.00         5\n",
      "            denmark       0.00      0.00      0.00        10\n",
      " dominican-republic       0.00      0.00      0.00         1\n",
      "       east-germany       0.00      0.00      0.00         1\n",
      "            ecuador       0.00      0.00      0.00        13\n",
      "              egypt       0.00      0.00      0.00         5\n",
      "               fiji       0.00      0.00      0.00         1\n",
      "            finland       0.00      0.00      0.00         8\n",
      "             france       0.00      0.00      0.00       103\n",
      "              ghana       0.00      0.00      0.00         3\n",
      "             greece       0.00      0.00      0.00         4\n",
      "             guyana       0.00      0.00      0.00         1\n",
      "              haiti       0.00      0.00      0.00         3\n",
      "          hong-kong       0.00      0.00      0.00        35\n",
      "            hungary       0.00      0.00      0.00         4\n",
      "              india       0.00      0.00      0.00        14\n",
      "          indonesia       0.00      0.00      0.00        21\n",
      "               iran       0.00      0.00      0.00        15\n",
      "               iraq       0.00      0.00      0.00         3\n",
      "              italy       0.00      0.00      0.00        38\n",
      "        ivory-coast       0.00      0.00      0.00         4\n",
      "              japan       0.00      0.00      0.00       221\n",
      "             jordan       0.00      0.00      0.00         3\n",
      "              kenya       0.00      0.00      0.00         2\n",
      "             kuwait       0.00      0.00      0.00         7\n",
      "            lebanon       0.00      0.00      0.00         1\n",
      "         luxembourg       0.00      0.00      0.00        14\n",
      "         madagascar       0.00      0.00      0.00         2\n",
      "             malawi       0.00      0.00      0.00         1\n",
      "           malaysia       0.00      0.00      0.00        18\n",
      "          mauritius       0.00      0.00      0.00         1\n",
      "             mexico       0.00      0.00      0.00         5\n",
      "            morocco       0.00      0.00      0.00         1\n",
      "        netherlands       0.00      0.00      0.00        56\n",
      "        new-zealand       0.00      0.00      0.00        34\n",
      "          nicaragua       0.00      0.00      0.00         2\n",
      "            nigeria       0.00      0.00      0.00         8\n",
      "        north-korea       0.00      0.00      0.00         3\n",
      "             norway       0.00      0.00      0.00         8\n",
      "           pakistan       0.00      0.00      0.00         7\n",
      "               peru       0.00      0.00      0.00         9\n",
      "        philippines       0.00      0.00      0.00        23\n",
      "             poland       0.00      0.00      0.00         3\n",
      "           portugal       0.00      0.00      0.00         5\n",
      "       saudi-arabia       0.00      0.00      0.00         9\n",
      "          singapore       0.00      0.00      0.00        13\n",
      "            somalia       0.00      0.00      0.00         1\n",
      "       south-africa       0.00      0.00      0.00        26\n",
      "        south-korea       0.00      0.00      0.00        16\n",
      "              spain       0.00      0.00      0.00        18\n",
      "          sri-lanka       0.00      0.00      0.00         7\n",
      "              sudan       0.00      0.00      0.00         1\n",
      "             sweden       0.00      0.00      0.00        19\n",
      "        switzerland       0.00      0.00      0.00        57\n",
      "             taiwan       0.00      0.00      0.00        26\n",
      "           tanzania       0.00      0.00      0.00         4\n",
      "           thailand       0.00      0.00      0.00        15\n",
      "               togo       0.00      0.00      0.00         1\n",
      "            tunisia       0.00      0.00      0.00         1\n",
      "             turkey       0.00      0.00      0.00         8\n",
      "                uae       0.00      0.00      0.00        10\n",
      "             uganda       0.00      0.00      0.00         5\n",
      "                 uk       0.00      0.00      0.00       375\n",
      "                usa       0.56      1.00      0.72      3606\n",
      "               ussr       0.00      0.00      0.00        18\n",
      "          venezuela       0.00      0.00      0.00        13\n",
      "       west-germany       0.00      0.00      0.00       113\n",
      "yemen-arab-republic       0.00      0.00      0.00         1\n",
      "yemen-demo-republic       0.00      0.00      0.00         1\n",
      "         yugoslavia       0.00      0.00      0.00        10\n",
      "             zambia       0.00      0.00      0.00         8\n",
      "           zimbabwe       0.00      0.00      0.00         5\n",
      "\n",
      "           accuracy                           0.56      6474\n",
      "          macro avg       0.01      0.01      0.01      6474\n",
      "       weighted avg       0.31      0.56      0.40      6474\n",
      "\n",
      "Bons résultats 3606\n",
      "Erreurs: 2868\n",
      "Accuracy: 0.56\n",
      "----------\n",
      "RandomForestClassifier()\n",
      "[[651   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  1   0   4 ...   0   0   0]\n",
      " ...\n",
      " [  1   0   0 ...   2   0   0]\n",
      " [  0   0   0 ...   0   1   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                          0.86      0.80      0.83       811\n",
      "            algeria       0.00      0.00      0.00         2\n",
      "          argentina       1.00      0.27      0.42        15\n",
      "              aruba       0.00      0.00      0.00         1\n",
      "          australia       0.78      0.35      0.48        60\n",
      "            austria       0.00      0.00      0.00         5\n",
      "            bahrain       0.50      0.12      0.20         8\n",
      "         bangladesh       0.50      0.17      0.25         6\n",
      "            belgium       0.69      0.52      0.59        56\n",
      "            bermuda       0.00      0.00      0.00         2\n",
      "            bolivia       0.00      0.00      0.00         5\n",
      "           botswana       0.00      0.00      0.00         1\n",
      "             brazil       0.88      0.44      0.59        52\n",
      "              burma       0.00      0.00      0.00         1\n",
      "           cameroon       0.00      0.00      0.00         1\n",
      "             canada       0.82      0.35      0.49       280\n",
      "               chad       0.00      0.00      0.00         1\n",
      "              chile       0.00      0.00      0.00         2\n",
      "              china       0.83      0.53      0.64        36\n",
      "           colombia       1.00      0.33      0.50         6\n",
      "         costa-rica       0.00      0.00      0.00         4\n",
      "               cuba       1.00      0.17      0.29         6\n",
      "             cyprus       0.00      0.00      0.00         5\n",
      "            denmark       1.00      0.10      0.18        10\n",
      " dominican-republic       0.00      0.00      0.00         1\n",
      "       east-germany       0.00      0.00      0.00         1\n",
      "            ecuador       0.77      0.77      0.77        13\n",
      "              egypt       0.00      0.00      0.00         5\n",
      "               fiji       0.00      0.00      0.00         1\n",
      "            finland       1.00      0.12      0.22         8\n",
      "             france       0.79      0.50      0.62       103\n",
      "              ghana       0.00      0.00      0.00         3\n",
      "             greece       1.00      0.25      0.40         4\n",
      "             guyana       0.00      0.00      0.00         1\n",
      "              haiti       0.00      0.00      0.00         3\n",
      "          hong-kong       0.86      0.17      0.29        35\n",
      "            hungary       1.00      0.25      0.40         4\n",
      "              india       0.67      0.14      0.24        14\n",
      "          indonesia       0.93      0.67      0.78        21\n",
      "               iran       1.00      0.13      0.24        15\n",
      "               iraq       0.00      0.00      0.00         3\n",
      "              italy       1.00      0.39      0.57        38\n",
      "        ivory-coast       0.00      0.00      0.00         4\n",
      "              japan       0.77      0.62      0.68       221\n",
      "             jordan       0.00      0.00      0.00         3\n",
      "              kenya       0.00      0.00      0.00         2\n",
      "             kuwait       0.00      0.00      0.00         7\n",
      "            lebanon       0.00      0.00      0.00         1\n",
      "         luxembourg       0.00      0.00      0.00        14\n",
      "         madagascar       0.00      0.00      0.00         2\n",
      "             malawi       0.00      0.00      0.00         1\n",
      "           malaysia       0.83      0.28      0.42        18\n",
      "          mauritius       0.00      0.00      0.00         1\n",
      "             mexico       1.00      0.20      0.33         5\n",
      "            morocco       0.00      0.00      0.00         1\n",
      "        netherlands       0.90      0.48      0.63        56\n",
      "        new-zealand       1.00      0.38      0.55        34\n",
      "          nicaragua       0.00      0.00      0.00         2\n",
      "            nigeria       0.00      0.00      0.00         8\n",
      "        north-korea       0.00      0.00      0.00         3\n",
      "             norway       0.50      0.12      0.20         8\n",
      "           pakistan       0.00      0.00      0.00         7\n",
      "               peru       1.00      0.22      0.36         9\n",
      "        philippines       0.88      0.30      0.45        23\n",
      "             poland       0.00      0.00      0.00         3\n",
      "           portugal       0.00      0.00      0.00         5\n",
      "       saudi-arabia       0.50      0.22      0.31         9\n",
      "          singapore       1.00      0.46      0.63        13\n",
      "            somalia       0.00      0.00      0.00         1\n",
      "       south-africa       0.87      0.50      0.63        26\n",
      "        south-korea       0.89      0.50      0.64        16\n",
      "              spain       0.80      0.67      0.73        18\n",
      "          sri-lanka       0.50      0.14      0.22         7\n",
      "              sudan       0.00      0.00      0.00         1\n",
      "             sweden       1.00      0.37      0.54        19\n",
      "        switzerland       0.78      0.37      0.50        57\n",
      "             taiwan       0.77      0.65      0.71        26\n",
      "           tanzania       1.00      0.50      0.67         4\n",
      "           thailand       0.83      0.33      0.48        15\n",
      "               togo       0.00      0.00      0.00         1\n",
      "            tunisia       0.00      0.00      0.00         1\n",
      "             turkey       1.00      0.25      0.40         8\n",
      "                uae       1.00      0.40      0.57        10\n",
      "             uganda       1.00      0.20      0.33         5\n",
      "                 uk       0.76      0.45      0.56       375\n",
      "                usa       0.75      0.97      0.85      3606\n",
      "               ussr       1.00      0.17      0.29        18\n",
      "          venezuela       0.71      0.38      0.50        13\n",
      "       west-germany       0.81      0.45      0.58       113\n",
      "yemen-arab-republic       0.00      0.00      0.00         1\n",
      "yemen-demo-republic       0.00      0.00      0.00         1\n",
      "         yugoslavia       1.00      0.20      0.33        10\n",
      "             zambia       1.00      0.12      0.22         8\n",
      "           zimbabwe       0.00      0.00      0.00         5\n",
      "\n",
      "           accuracy                           0.77      6474\n",
      "          macro avg       0.47      0.20      0.26      6474\n",
      "       weighted avg       0.77      0.77      0.74      6474\n",
      "\n",
      "Bons résultats 4980\n",
      "Erreurs: 1494\n",
      "Accuracy: 0.77\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                          0.00      0.00      0.00       811\n",
      "            algeria       0.00      0.00      0.00         2\n",
      "          argentina       0.00      0.00      0.00        15\n",
      "              aruba       0.00      0.00      0.00         1\n",
      "          australia       0.00      0.00      0.00        60\n",
      "            austria       0.00      0.00      0.00         5\n",
      "            bahrain       0.00      0.00      0.00         8\n",
      "         bangladesh       0.00      0.00      0.00         6\n",
      "            belgium       0.00      0.00      0.00        56\n",
      "            bermuda       0.00      0.00      0.00         2\n",
      "            bolivia       0.00      0.00      0.00         5\n",
      "           botswana       0.00      0.00      0.00         1\n",
      "             brazil       0.00      0.00      0.00        52\n",
      "              burma       0.00      0.00      0.00         1\n",
      "           cameroon       0.00      0.00      0.00         1\n",
      "             canada       0.00      0.00      0.00       280\n",
      "               chad       0.00      0.00      0.00         1\n",
      "              chile       0.00      0.00      0.00         2\n",
      "              china       0.00      0.00      0.00        36\n",
      "           colombia       0.00      0.00      0.00         6\n",
      "         costa-rica       0.00      0.00      0.00         4\n",
      "               cuba       0.00      0.00      0.00         6\n",
      "             cyprus       0.00      0.00      0.00         5\n",
      "            denmark       0.00      0.00      0.00        10\n",
      " dominican-republic       0.00      0.00      0.00         1\n",
      "       east-germany       0.00      0.00      0.00         1\n",
      "            ecuador       0.00      0.00      0.00        13\n",
      "              egypt       0.00      0.00      0.00         5\n",
      "               fiji       0.00      0.00      0.00         1\n",
      "            finland       0.00      0.00      0.00         8\n",
      "             france       0.00      0.00      0.00       103\n",
      "              ghana       0.00      0.00      0.00         3\n",
      "             greece       0.00      0.00      0.00         4\n",
      "             guyana       0.00      0.00      0.00         1\n",
      "              haiti       0.00      0.00      0.00         3\n",
      "          hong-kong       0.00      0.00      0.00        35\n",
      "            hungary       0.00      0.00      0.00         4\n",
      "              india       0.00      0.00      0.00        14\n",
      "          indonesia       0.00      0.00      0.00        21\n",
      "               iran       0.00      0.00      0.00        15\n",
      "               iraq       0.00      0.00      0.00         3\n",
      "              italy       0.00      0.00      0.00        38\n",
      "        ivory-coast       0.00      0.00      0.00         4\n",
      "              japan       0.00      0.00      0.00       221\n",
      "             jordan       0.00      0.00      0.00         3\n",
      "              kenya       0.00      0.00      0.00         2\n",
      "             kuwait       0.00      0.00      0.00         7\n",
      "            lebanon       0.00      0.00      0.00         1\n",
      "         luxembourg       0.00      0.00      0.00        14\n",
      "         madagascar       0.00      0.00      0.00         2\n",
      "             malawi       0.00      0.00      0.00         1\n",
      "           malaysia       0.00      0.00      0.00        18\n",
      "          mauritius       0.00      0.00      0.00         1\n",
      "             mexico       0.00      0.00      0.00         5\n",
      "            morocco       0.00      0.00      0.00         1\n",
      "        netherlands       0.00      0.00      0.00        56\n",
      "        new-zealand       0.00      0.00      0.00        34\n",
      "          nicaragua       0.00      0.00      0.00         2\n",
      "            nigeria       0.00      0.00      0.00         8\n",
      "        north-korea       0.00      0.00      0.00         3\n",
      "             norway       0.00      0.00      0.00         8\n",
      "           pakistan       0.00      0.00      0.00         7\n",
      "               peru       0.00      0.00      0.00         9\n",
      "        philippines       0.00      0.00      0.00        23\n",
      "             poland       0.00      0.00      0.00         3\n",
      "           portugal       0.00      0.00      0.00         5\n",
      "       saudi-arabia       0.00      0.00      0.00         9\n",
      "          singapore       0.00      0.00      0.00        13\n",
      "            somalia       0.00      0.00      0.00         1\n",
      "       south-africa       0.00      0.00      0.00        26\n",
      "        south-korea       0.00      0.00      0.00        16\n",
      "              spain       0.00      0.00      0.00        18\n",
      "          sri-lanka       0.00      0.00      0.00         7\n",
      "              sudan       0.00      0.00      0.00         1\n",
      "             sweden       0.00      0.00      0.00        19\n",
      "        switzerland       0.00      0.00      0.00        57\n",
      "             taiwan       0.00      0.00      0.00        26\n",
      "           tanzania       0.00      0.00      0.00         4\n",
      "           thailand       0.00      0.00      0.00        15\n",
      "               togo       0.00      0.00      0.00         1\n",
      "            tunisia       0.00      0.00      0.00         1\n",
      "             turkey       0.00      0.00      0.00         8\n",
      "                uae       0.00      0.00      0.00        10\n",
      "             uganda       0.00      0.00      0.00         5\n",
      "                 uk       0.00      0.00      0.00       375\n",
      "                usa       0.56      1.00      0.72      3606\n",
      "               ussr       0.00      0.00      0.00        18\n",
      "          venezuela       0.00      0.00      0.00        13\n",
      "       west-germany       0.00      0.00      0.00       113\n",
      "yemen-arab-republic       0.00      0.00      0.00         1\n",
      "yemen-demo-republic       0.00      0.00      0.00         1\n",
      "         yugoslavia       0.00      0.00      0.00        10\n",
      "             zambia       0.00      0.00      0.00         8\n",
      "           zimbabwe       0.00      0.00      0.00         5\n",
      "\n",
      "           accuracy                           0.56      6474\n",
      "          macro avg       0.01      0.01      0.01      6474\n",
      "       weighted avg       0.31      0.56      0.40      6474\n",
      "\n",
      "Bons résultats 3606\n",
      "Erreurs: 2868\n",
      "Accuracy: 0.56\n",
      "----------\n",
      "KNeighborsClassifier()\n",
      "[[645   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   5 ...   0   0   0]\n",
      " ...\n",
      " [  1   0   0 ...   0   0   0]\n",
      " [  1   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                          0.82      0.80      0.81       811\n",
      "            algeria       0.00      0.00      0.00         2\n",
      "          argentina       0.33      0.33      0.33        15\n",
      "              aruba       0.00      0.00      0.00         1\n",
      "          australia       0.33      0.20      0.25        60\n",
      "            austria       0.00      0.00      0.00         5\n",
      "            bahrain       0.33      0.12      0.18         8\n",
      "         bangladesh       0.00      0.00      0.00         6\n",
      "            belgium       0.29      0.09      0.14        56\n",
      "            bermuda       0.00      0.00      0.00         2\n",
      "            bolivia       0.00      0.00      0.00         5\n",
      "           botswana       0.00      0.00      0.00         1\n",
      "             brazil       0.26      0.10      0.14        52\n",
      "              burma       0.00      0.00      0.00         1\n",
      "           cameroon       0.00      0.00      0.00         1\n",
      "             canada       0.47      0.19      0.27       280\n",
      "               chad       0.00      0.00      0.00         1\n",
      "              chile       0.00      0.00      0.00         2\n",
      "              china       0.42      0.14      0.21        36\n",
      "           colombia       0.00      0.00      0.00         6\n",
      "         costa-rica       0.00      0.00      0.00         4\n",
      "               cuba       0.00      0.00      0.00         6\n",
      "             cyprus       0.00      0.00      0.00         5\n",
      "            denmark       0.00      0.00      0.00        10\n",
      " dominican-republic       0.00      0.00      0.00         1\n",
      "       east-germany       0.00      0.00      0.00         1\n",
      "            ecuador       0.67      0.15      0.25        13\n",
      "              egypt       0.50      0.20      0.29         5\n",
      "               fiji       0.00      0.00      0.00         1\n",
      "            finland       0.00      0.00      0.00         8\n",
      "             france       0.38      0.12      0.18       103\n",
      "              ghana       0.00      0.00      0.00         3\n",
      "             greece       0.50      0.25      0.33         4\n",
      "             guyana       0.00      0.00      0.00         1\n",
      "              haiti       0.00      0.00      0.00         3\n",
      "          hong-kong       0.03      0.03      0.03        35\n",
      "            hungary       0.00      0.00      0.00         4\n",
      "              india       0.00      0.00      0.00        14\n",
      "          indonesia       0.40      0.10      0.15        21\n",
      "               iran       1.00      0.07      0.12        15\n",
      "               iraq       0.00      0.00      0.00         3\n",
      "             israel       0.00      0.00      0.00         0\n",
      "              italy       0.17      0.05      0.08        38\n",
      "        ivory-coast       0.00      0.00      0.00         4\n",
      "              japan       0.59      0.32      0.41       221\n",
      "             jordan       0.00      0.00      0.00         3\n",
      "              kenya       0.00      0.00      0.00         2\n",
      "             kuwait       0.00      0.00      0.00         7\n",
      "            lebanon       0.00      0.00      0.00         1\n",
      "         luxembourg       0.25      0.07      0.11        14\n",
      "         madagascar       0.00      0.00      0.00         2\n",
      "             malawi       0.00      0.00      0.00         1\n",
      "           malaysia       0.00      0.00      0.00        18\n",
      "          mauritius       0.00      0.00      0.00         1\n",
      "             mexico       0.00      0.00      0.00         5\n",
      "            morocco       0.00      0.00      0.00         1\n",
      "        netherlands       1.00      0.07      0.13        56\n",
      "        new-zealand       0.17      0.03      0.05        34\n",
      "          nicaragua       0.00      0.00      0.00         2\n",
      "            nigeria       0.00      0.00      0.00         8\n",
      "        north-korea       0.00      0.00      0.00         3\n",
      "             norway       0.00      0.00      0.00         8\n",
      "           pakistan       1.00      0.14      0.25         7\n",
      "               peru       0.00      0.00      0.00         9\n",
      "        philippines       0.44      0.17      0.25        23\n",
      "             poland       0.00      0.00      0.00         3\n",
      "           portugal       0.00      0.00      0.00         5\n",
      "       saudi-arabia       0.00      0.00      0.00         9\n",
      "          singapore       0.33      0.08      0.12        13\n",
      "            somalia       0.00      0.00      0.00         1\n",
      "       south-africa       0.50      0.12      0.19        26\n",
      "        south-korea       0.67      0.12      0.21        16\n",
      "              spain       0.00      0.00      0.00        18\n",
      "          sri-lanka       0.00      0.00      0.00         7\n",
      "              sudan       0.00      0.00      0.00         1\n",
      "             sweden       0.00      0.00      0.00        19\n",
      "        switzerland       0.73      0.19      0.31        57\n",
      "             taiwan       0.62      0.19      0.29        26\n",
      "           tanzania       0.00      0.00      0.00         4\n",
      "           thailand       1.00      0.20      0.33        15\n",
      "               togo       0.00      0.00      0.00         1\n",
      "            tunisia       0.00      0.00      0.00         1\n",
      "             turkey       1.00      0.12      0.22         8\n",
      "                uae       0.00      0.00      0.00        10\n",
      "             uganda       0.00      0.00      0.00         5\n",
      "                 uk       0.49      0.33      0.40       375\n",
      "                usa       0.70      0.95      0.81      3606\n",
      "               ussr       0.50      0.06      0.10        18\n",
      "          venezuela       0.00      0.00      0.00        13\n",
      "       west-germany       0.29      0.04      0.08       113\n",
      "yemen-arab-republic       0.00      0.00      0.00         1\n",
      "yemen-demo-republic       0.00      0.00      0.00         1\n",
      "         yugoslavia       0.00      0.00      0.00        10\n",
      "             zambia       0.00      0.00      0.00         8\n",
      "           zimbabwe       0.00      0.00      0.00         5\n",
      "\n",
      "           accuracy                           0.69      6474\n",
      "          macro avg       0.18      0.06      0.08      6474\n",
      "       weighted avg       0.62      0.69      0.62      6474\n",
      "\n",
      "Bons résultats 4435\n",
      "Erreurs: 2039\n",
      "Accuracy: 0.69\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "liste = [LR, RDF, SVC, KN]\n",
    "\n",
    "for i in liste:\n",
    "    i = i.fit(X_train, y_train)\n",
    "    y_pred = i.predict(X_test)\n",
    "    matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(i)\n",
    "    print(matrice_confusion)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "    print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "    print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "    print ('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En faisant varier les n-grammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram_range : (1, 1)\n",
      "LogisticRegression() classifier : 0.5795\n",
      "RandomForestClassifier() classifier : 0.6965\n",
      "SVC() classifier : 0.5570\n",
      "KNeighborsClassifier() classifier : 0.6353\n",
      "Ngram_range : (1, 2)\n",
      "LogisticRegression() classifier : 0.5876\n",
      "RandomForestClassifier() classifier : 0.7413\n",
      "SVC() classifier : 0.5570\n",
      "KNeighborsClassifier() classifier : 0.6915\n",
      "Ngram_range : (1, 3)\n",
      "LogisticRegression() classifier : 0.5928\n",
      "RandomForestClassifier() classifier : 0.7705\n",
      "SVC() classifier : 0.5570\n",
      "KNeighborsClassifier() classifier : 0.7053\n",
      "Ngram_range : (1, 4)\n",
      "LogisticRegression() classifier : 0.5930\n",
      "RandomForestClassifier() classifier : 0.7734\n",
      "SVC() classifier : 0.5570\n",
      "KNeighborsClassifier() classifier : 0.7005\n"
     ]
    }
   ],
   "source": [
    "for min_N in range(1, 2):\n",
    "  for max_N in range(min_N, 5):\n",
    "    V = CountVectorizer(ngram_range = (min_N, max_N), analyzer = \"char\")\n",
    "    X = V.fit_transform(texte)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "    print(f\"Ngram_range : ({min_N}, {max_N})\")\n",
    "    for i in liste:\n",
    "        clf = i.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print('%s classifier : %.4f'%(i, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forêt aléatoire : zoom sur quelques paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bons résultats 5028\n",
      "Erreurs: 1446\n",
      "Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "    # On fait la somme de tous les cas où la valeur dans y_test est bien trouvée dans y_pred\n",
    "print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "print ('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ci-dessus : paramètres par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec max_depth = 1\n",
      "Bons résultats 3606\n",
      "Erreurs: 2868\n",
      "Accuracy: 0.56\n",
      "Avec max_depth = 2\n",
      "Bons résultats 3606\n",
      "Erreurs: 2868\n",
      "Accuracy: 0.56\n",
      "Avec max_depth = 3\n",
      "Bons résultats 3606\n",
      "Erreurs: 2868\n",
      "Accuracy: 0.56\n",
      "Avec max_depth = 4\n",
      "Bons résultats 3606\n",
      "Erreurs: 2868\n",
      "Accuracy: 0.56\n",
      "Avec max_depth = 5\n",
      "Bons résultats 3606\n",
      "Erreurs: 2868\n",
      "Accuracy: 0.56\n",
      "Avec max_depth = 6\n",
      "Bons résultats 3632\n",
      "Erreurs: 2842\n",
      "Accuracy: 0.56\n",
      "Avec max_depth = 7\n",
      "Bons résultats 3659\n",
      "Erreurs: 2815\n",
      "Accuracy: 0.57\n",
      "Avec max_depth = 8\n",
      "Bons résultats 3679\n",
      "Erreurs: 2795\n",
      "Accuracy: 0.57\n",
      "Avec max_depth = 9\n",
      "Bons résultats 3703\n",
      "Erreurs: 2771\n",
      "Accuracy: 0.57\n",
      "Avec max_depth = 10\n",
      "Bons résultats 3723\n",
      "Erreurs: 2751\n",
      "Accuracy: 0.58\n",
      "Avec max_depth = 11\n",
      "Bons résultats 3767\n",
      "Erreurs: 2707\n",
      "Accuracy: 0.58\n",
      "Avec max_depth = 12\n",
      "Bons résultats 3796\n",
      "Erreurs: 2678\n",
      "Accuracy: 0.59\n",
      "Avec max_depth = 13\n",
      "Bons résultats 3813\n",
      "Erreurs: 2661\n",
      "Accuracy: 0.59\n",
      "Avec max_depth = 14\n",
      "Bons résultats 4003\n",
      "Erreurs: 2471\n",
      "Accuracy: 0.62\n",
      "Avec max_depth = 15\n",
      "Bons résultats 4025\n",
      "Erreurs: 2449\n",
      "Accuracy: 0.62\n",
      "Avec max_depth = 16\n",
      "Bons résultats 4042\n",
      "Erreurs: 2432\n",
      "Accuracy: 0.62\n",
      "Avec max_depth = 17\n",
      "Bons résultats 4077\n",
      "Erreurs: 2397\n",
      "Accuracy: 0.63\n",
      "Avec max_depth = 18\n",
      "Bons résultats 4137\n",
      "Erreurs: 2337\n",
      "Accuracy: 0.64\n",
      "Avec max_depth = 19\n",
      "Bons résultats 4173\n",
      "Erreurs: 2301\n",
      "Accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "for i in range(1,20):\n",
    "    clf = RandomForestClassifier(max_depth=i, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # On fait la somme de tous les cas où la valeur dans y_test est bien trouvée dans y_pred\n",
    "    print(\"Avec max_depth =\", i)\n",
    "    print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "    print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "    print ('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En supprimant la ponctuation et les stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rappels pour la cellule ci-après (ces éléments de codes ont été exécutés plus avant)\n",
    "# LR = LogisticRegression()\n",
    "# RDF = RandomForestClassifier()\n",
    "# SVC = SVC()\n",
    "# KN = KNeighborsClassifier()\n",
    "# Liste = [LR, RDF, SVC, KN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ponctuation(chaine):\n",
    "    ponctuations = [\",\", \"'\", '\"', \"-\", \"\\.\"]\n",
    "    for stopword in ponctuations:\n",
    "        chaine = re.sub(f\" {stopword} \", \" \", chaine)\n",
    "    return chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(chaine):\n",
    "    final_stopwords_list = stopwords.words('english')\n",
    "    s = chaine\n",
    "    for stopword in final_stopwords_list:\n",
    "        chaine = re.sub(f\" {stopword} \", \" \", chaine)\n",
    "    return chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_size : 0.3, Pretraitement: stopwords\n",
      "LogisticRegression()\n",
      "[[415   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  3   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  3   0   0 ...   0   0   0]\n",
      " [  1   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "(array([0.34354305, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.34920635, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.5270936 , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.55828221,\n",
      "       0.70547514, 0.        , 0.        , 0.66666667, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        ]), array([0.51171393, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.15714286, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.01941748, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.4841629 , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.24266667,\n",
      "       0.93261231, 0.        , 0.        , 0.01769912, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        ]), array([0.4110946 , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.21674877, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.03738318, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.50471698, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.33828996,\n",
      "       0.80329631, 0.        , 0.        , 0.03448276, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        ]), array([ 811,    2,   15,    1,   60,    5,    8,    6,   56,    2,    5,\n",
      "          1,   52,    1,    1,  280,    1,    2,   36,    6,    4,    6,\n",
      "          5,   10,    1,    1,   13,    5,    1,    8,  103,    3,    4,\n",
      "          1,    3,   35,    4,   14,   21,   15,    3,   38,    4,  221,\n",
      "          3,    2,    7,    1,   14,    2,    1,   18,    1,    5,    1,\n",
      "         56,   34,    2,    8,    3,    8,    7,    9,   23,    3,    5,\n",
      "          9,   13,    1,   26,   16,   18,    7,    1,   19,   57,   26,\n",
      "          4,   15,    1,    1,    8,   10,    5,  375, 3606,   18,   13,\n",
      "        113,    1,    1,   10,    8,    5]))\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                          0.34      0.51      0.41       811\n",
      "            algeria       0.00      0.00      0.00         2\n",
      "          argentina       0.00      0.00      0.00        15\n",
      "              aruba       0.00      0.00      0.00         1\n",
      "          australia       0.00      0.00      0.00        60\n",
      "            austria       0.00      0.00      0.00         5\n",
      "            bahrain       0.00      0.00      0.00         8\n",
      "         bangladesh       0.00      0.00      0.00         6\n",
      "            belgium       0.00      0.00      0.00        56\n",
      "            bermuda       0.00      0.00      0.00         2\n",
      "            bolivia       0.00      0.00      0.00         5\n",
      "           botswana       0.00      0.00      0.00         1\n",
      "             brazil       0.00      0.00      0.00        52\n",
      "              burma       0.00      0.00      0.00         1\n",
      "           cameroon       0.00      0.00      0.00         1\n",
      "             canada       0.35      0.16      0.22       280\n",
      "               chad       0.00      0.00      0.00         1\n",
      "              chile       0.00      0.00      0.00         2\n",
      "              china       0.00      0.00      0.00        36\n",
      "           colombia       0.00      0.00      0.00         6\n",
      "         costa-rica       0.00      0.00      0.00         4\n",
      "               cuba       0.00      0.00      0.00         6\n",
      "             cyprus       0.00      0.00      0.00         5\n",
      "            denmark       0.00      0.00      0.00        10\n",
      " dominican-republic       0.00      0.00      0.00         1\n",
      "       east-germany       0.00      0.00      0.00         1\n",
      "            ecuador       0.00      0.00      0.00        13\n",
      "              egypt       0.00      0.00      0.00         5\n",
      "               fiji       0.00      0.00      0.00         1\n",
      "            finland       0.00      0.00      0.00         8\n",
      "             france       0.50      0.02      0.04       103\n",
      "              ghana       0.00      0.00      0.00         3\n",
      "             greece       0.00      0.00      0.00         4\n",
      "             guyana       0.00      0.00      0.00         1\n",
      "              haiti       0.00      0.00      0.00         3\n",
      "          hong-kong       0.00      0.00      0.00        35\n",
      "            hungary       0.00      0.00      0.00         4\n",
      "              india       0.00      0.00      0.00        14\n",
      "          indonesia       0.00      0.00      0.00        21\n",
      "               iran       0.00      0.00      0.00        15\n",
      "               iraq       0.00      0.00      0.00         3\n",
      "              italy       0.00      0.00      0.00        38\n",
      "        ivory-coast       0.00      0.00      0.00         4\n",
      "              japan       0.53      0.48      0.50       221\n",
      "             jordan       0.00      0.00      0.00         3\n",
      "              kenya       0.00      0.00      0.00         2\n",
      "             kuwait       0.00      0.00      0.00         7\n",
      "            lebanon       0.00      0.00      0.00         1\n",
      "         luxembourg       0.00      0.00      0.00        14\n",
      "         madagascar       0.00      0.00      0.00         2\n",
      "             malawi       0.00      0.00      0.00         1\n",
      "           malaysia       0.00      0.00      0.00        18\n",
      "          mauritius       0.00      0.00      0.00         1\n",
      "             mexico       0.00      0.00      0.00         5\n",
      "            morocco       0.00      0.00      0.00         1\n",
      "        netherlands       0.00      0.00      0.00        56\n",
      "        new-zealand       0.00      0.00      0.00        34\n",
      "          nicaragua       0.00      0.00      0.00         2\n",
      "            nigeria       0.00      0.00      0.00         8\n",
      "        north-korea       0.00      0.00      0.00         3\n",
      "             norway       0.00      0.00      0.00         8\n",
      "           pakistan       0.00      0.00      0.00         7\n",
      "               peru       0.00      0.00      0.00         9\n",
      "        philippines       0.00      0.00      0.00        23\n",
      "             poland       0.00      0.00      0.00         3\n",
      "           portugal       0.00      0.00      0.00         5\n",
      "       saudi-arabia       0.00      0.00      0.00         9\n",
      "          singapore       0.00      0.00      0.00        13\n",
      "            somalia       0.00      0.00      0.00         1\n",
      "       south-africa       0.00      0.00      0.00        26\n",
      "        south-korea       0.00      0.00      0.00        16\n",
      "              spain       0.00      0.00      0.00        18\n",
      "          sri-lanka       0.00      0.00      0.00         7\n",
      "              sudan       0.00      0.00      0.00         1\n",
      "             sweden       0.00      0.00      0.00        19\n",
      "        switzerland       0.00      0.00      0.00        57\n",
      "             taiwan       0.00      0.00      0.00        26\n",
      "           tanzania       0.00      0.00      0.00         4\n",
      "           thailand       0.00      0.00      0.00        15\n",
      "               togo       0.00      0.00      0.00         1\n",
      "            tunisia       0.00      0.00      0.00         1\n",
      "             turkey       0.00      0.00      0.00         8\n",
      "                uae       0.00      0.00      0.00        10\n",
      "             uganda       0.00      0.00      0.00         5\n",
      "                 uk       0.56      0.24      0.34       375\n",
      "                usa       0.71      0.93      0.80      3606\n",
      "               ussr       0.00      0.00      0.00        18\n",
      "          venezuela       0.00      0.00      0.00        13\n",
      "       west-germany       0.67      0.02      0.03       113\n",
      "yemen-arab-republic       0.00      0.00      0.00         1\n",
      "yemen-demo-republic       0.00      0.00      0.00         1\n",
      "         yugoslavia       0.00      0.00      0.00        10\n",
      "             zambia       0.00      0.00      0.00         8\n",
      "           zimbabwe       0.00      0.00      0.00         5\n",
      "\n",
      "           accuracy                           0.62      6474\n",
      "          macro avg       0.04      0.03      0.02      6474\n",
      "       weighted avg       0.52      0.62      0.55      6474\n",
      "\n",
      "Bons résultats 4024\n",
      "Erreurs: 2450\n",
      "Accuracy: 0.62\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "[[532   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   7 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   5   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "(array([0.86363636, 0.        , 1.        , 0.        , 0.7804878 ,\n",
      "       0.        , 1.        , 0.75      , 0.9       , 0.        ,\n",
      "       1.        , 0.        , 0.8125    , 0.        , 0.        ,\n",
      "       0.74637681, 0.        , 0.        , 0.96428571, 1.        ,\n",
      "       0.        , 1.        , 0.        , 1.        , 0.        ,\n",
      "       0.        , 0.8       , 1.        , 0.        , 1.        ,\n",
      "       0.77777778, 0.        , 1.        , 0.        , 0.        ,\n",
      "       1.        , 1.        , 1.        , 0.86956522, 0.75      ,\n",
      "       0.        , 1.        , 0.        , 0.76683938, 0.        ,\n",
      "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
      "       0.        , 0.78571429, 0.        , 1.        , 0.        ,\n",
      "       0.93939394, 1.        , 0.        , 0.        , 0.        ,\n",
      "       1.        , 1.        , 1.        , 0.875     , 0.        ,\n",
      "       0.        , 1.        , 1.        , 0.        , 0.93333333,\n",
      "       0.9       , 0.75      , 1.        , 0.        , 1.        ,\n",
      "       0.89285714, 0.77777778, 1.        , 0.8       , 0.        ,\n",
      "       0.        , 1.        , 1.        , 1.        , 0.77165354,\n",
      "       0.75165492, 1.        , 0.83333333, 0.8       , 0.        ,\n",
      "       0.        , 1.        , 0.        , 0.        ]), array([0.65598027, 0.        , 0.46666667, 0.        , 0.53333333,\n",
      "       0.        , 0.125     , 0.5       , 0.32142857, 0.        ,\n",
      "       0.2       , 0.        , 0.75      , 0.        , 0.        ,\n",
      "       0.36785714, 0.        , 0.        , 0.75      , 0.83333333,\n",
      "       0.        , 0.16666667, 0.        , 0.2       , 0.        ,\n",
      "       0.        , 0.92307692, 0.2       , 0.        , 0.125     ,\n",
      "       0.47572816, 0.        , 0.25      , 0.        , 0.        ,\n",
      "       0.2       , 0.25      , 0.07142857, 0.95238095, 0.2       ,\n",
      "       0.        , 0.39473684, 0.        , 0.66968326, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.07142857, 0.        ,\n",
      "       0.        , 0.61111111, 0.        , 0.2       , 0.        ,\n",
      "       0.55357143, 0.55882353, 0.        , 0.        , 0.        ,\n",
      "       0.125     , 0.14285714, 0.22222222, 0.60869565, 0.        ,\n",
      "       0.        , 0.22222222, 0.53846154, 0.        , 0.53846154,\n",
      "       0.5625    , 0.33333333, 0.28571429, 0.        , 0.15789474,\n",
      "       0.43859649, 0.80769231, 0.75      , 0.26666667, 0.        ,\n",
      "       0.        , 0.25      , 0.4       , 0.2       , 0.52266667,\n",
      "       0.97615086, 0.27777778, 0.76923077, 0.49557522, 0.        ,\n",
      "       0.        , 0.5       , 0.        , 0.        ]), array([0.74562018, 0.        , 0.63636364, 0.        , 0.63366337,\n",
      "       0.        , 0.22222222, 0.6       , 0.47368421, 0.        ,\n",
      "       0.33333333, 0.        , 0.78      , 0.        , 0.        ,\n",
      "       0.49282297, 0.        , 0.        , 0.84375   , 0.90909091,\n",
      "       0.        , 0.28571429, 0.        , 0.33333333, 0.        ,\n",
      "       0.        , 0.85714286, 0.33333333, 0.        , 0.22222222,\n",
      "       0.59036145, 0.        , 0.4       , 0.        , 0.        ,\n",
      "       0.33333333, 0.4       , 0.13333333, 0.90909091, 0.31578947,\n",
      "       0.        , 0.56603774, 0.        , 0.71497585, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.13333333, 0.        ,\n",
      "       0.        , 0.6875    , 0.        , 0.33333333, 0.        ,\n",
      "       0.69662921, 0.71698113, 0.        , 0.        , 0.        ,\n",
      "       0.22222222, 0.25      , 0.36363636, 0.71794872, 0.        ,\n",
      "       0.        , 0.36363636, 0.7       , 0.        , 0.68292683,\n",
      "       0.69230769, 0.46153846, 0.44444444, 0.        , 0.27272727,\n",
      "       0.58823529, 0.79245283, 0.85714286, 0.4       , 0.        ,\n",
      "       0.        , 0.4       , 0.57142857, 0.33333333, 0.62321145,\n",
      "       0.84931837, 0.43478261, 0.8       , 0.61202186, 0.        ,\n",
      "       0.        , 0.66666667, 0.        , 0.        ]), array([ 811,    2,   15,    1,   60,    5,    8,    6,   56,    2,    5,\n",
      "          1,   52,    1,    1,  280,    1,    2,   36,    6,    4,    6,\n",
      "          5,   10,    1,    1,   13,    5,    1,    8,  103,    3,    4,\n",
      "          1,    3,   35,    4,   14,   21,   15,    3,   38,    4,  221,\n",
      "          3,    2,    7,    1,   14,    2,    1,   18,    1,    5,    1,\n",
      "         56,   34,    2,    8,    3,    8,    7,    9,   23,    3,    5,\n",
      "          9,   13,    1,   26,   16,   18,    7,    1,   19,   57,   26,\n",
      "          4,   15,    1,    1,    8,   10,    5,  375, 3606,   18,   13,\n",
      "        113,    1,    1,   10,    8,    5]))\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                          0.86      0.66      0.75       811\n",
      "            algeria       0.00      0.00      0.00         2\n",
      "          argentina       1.00      0.47      0.64        15\n",
      "              aruba       0.00      0.00      0.00         1\n",
      "          australia       0.78      0.53      0.63        60\n",
      "            austria       0.00      0.00      0.00         5\n",
      "            bahrain       1.00      0.12      0.22         8\n",
      "         bangladesh       0.75      0.50      0.60         6\n",
      "            belgium       0.90      0.32      0.47        56\n",
      "            bermuda       0.00      0.00      0.00         2\n",
      "            bolivia       1.00      0.20      0.33         5\n",
      "           botswana       0.00      0.00      0.00         1\n",
      "             brazil       0.81      0.75      0.78        52\n",
      "              burma       0.00      0.00      0.00         1\n",
      "           cameroon       0.00      0.00      0.00         1\n",
      "             canada       0.75      0.37      0.49       280\n",
      "               chad       0.00      0.00      0.00         1\n",
      "              chile       0.00      0.00      0.00         2\n",
      "              china       0.96      0.75      0.84        36\n",
      "           colombia       1.00      0.83      0.91         6\n",
      "         costa-rica       0.00      0.00      0.00         4\n",
      "               cuba       1.00      0.17      0.29         6\n",
      "             cyprus       0.00      0.00      0.00         5\n",
      "            denmark       1.00      0.20      0.33        10\n",
      " dominican-republic       0.00      0.00      0.00         1\n",
      "       east-germany       0.00      0.00      0.00         1\n",
      "            ecuador       0.80      0.92      0.86        13\n",
      "              egypt       1.00      0.20      0.33         5\n",
      "               fiji       0.00      0.00      0.00         1\n",
      "            finland       1.00      0.12      0.22         8\n",
      "             france       0.78      0.48      0.59       103\n",
      "              ghana       0.00      0.00      0.00         3\n",
      "             greece       1.00      0.25      0.40         4\n",
      "             guyana       0.00      0.00      0.00         1\n",
      "              haiti       0.00      0.00      0.00         3\n",
      "          hong-kong       1.00      0.20      0.33        35\n",
      "            hungary       1.00      0.25      0.40         4\n",
      "              india       1.00      0.07      0.13        14\n",
      "          indonesia       0.87      0.95      0.91        21\n",
      "               iran       0.75      0.20      0.32        15\n",
      "               iraq       0.00      0.00      0.00         3\n",
      "              italy       1.00      0.39      0.57        38\n",
      "        ivory-coast       0.00      0.00      0.00         4\n",
      "              japan       0.77      0.67      0.71       221\n",
      "             jordan       0.00      0.00      0.00         3\n",
      "              kenya       0.00      0.00      0.00         2\n",
      "             kuwait       0.00      0.00      0.00         7\n",
      "            lebanon       0.00      0.00      0.00         1\n",
      "         luxembourg       1.00      0.07      0.13        14\n",
      "         madagascar       0.00      0.00      0.00         2\n",
      "             malawi       0.00      0.00      0.00         1\n",
      "           malaysia       0.79      0.61      0.69        18\n",
      "          mauritius       0.00      0.00      0.00         1\n",
      "             mexico       1.00      0.20      0.33         5\n",
      "            morocco       0.00      0.00      0.00         1\n",
      "        netherlands       0.94      0.55      0.70        56\n",
      "        new-zealand       1.00      0.56      0.72        34\n",
      "          nicaragua       0.00      0.00      0.00         2\n",
      "            nigeria       0.00      0.00      0.00         8\n",
      "        north-korea       0.00      0.00      0.00         3\n",
      "             norway       1.00      0.12      0.22         8\n",
      "           pakistan       1.00      0.14      0.25         7\n",
      "               peru       1.00      0.22      0.36         9\n",
      "        philippines       0.88      0.61      0.72        23\n",
      "             poland       0.00      0.00      0.00         3\n",
      "           portugal       0.00      0.00      0.00         5\n",
      "       saudi-arabia       1.00      0.22      0.36         9\n",
      "          singapore       1.00      0.54      0.70        13\n",
      "            somalia       0.00      0.00      0.00         1\n",
      "       south-africa       0.93      0.54      0.68        26\n",
      "        south-korea       0.90      0.56      0.69        16\n",
      "              spain       0.75      0.33      0.46        18\n",
      "          sri-lanka       1.00      0.29      0.44         7\n",
      "              sudan       0.00      0.00      0.00         1\n",
      "             sweden       1.00      0.16      0.27        19\n",
      "        switzerland       0.89      0.44      0.59        57\n",
      "             taiwan       0.78      0.81      0.79        26\n",
      "           tanzania       1.00      0.75      0.86         4\n",
      "           thailand       0.80      0.27      0.40        15\n",
      "               togo       0.00      0.00      0.00         1\n",
      "            tunisia       0.00      0.00      0.00         1\n",
      "             turkey       1.00      0.25      0.40         8\n",
      "                uae       1.00      0.40      0.57        10\n",
      "             uganda       1.00      0.20      0.33         5\n",
      "                 uk       0.77      0.52      0.62       375\n",
      "                usa       0.75      0.98      0.85      3606\n",
      "               ussr       1.00      0.28      0.43        18\n",
      "          venezuela       0.83      0.77      0.80        13\n",
      "       west-germany       0.80      0.50      0.61       113\n",
      "yemen-arab-republic       0.00      0.00      0.00         1\n",
      "yemen-demo-republic       0.00      0.00      0.00         1\n",
      "         yugoslavia       1.00      0.50      0.67        10\n",
      "             zambia       0.00      0.00      0.00         8\n",
      "           zimbabwe       0.00      0.00      0.00         5\n",
      "\n",
      "           accuracy                           0.77      6474\n",
      "          macro avg       0.53      0.24      0.31      6474\n",
      "       weighted avg       0.78      0.77      0.75      6474\n",
      "\n",
      "Bons résultats 5006\n",
      "Erreurs: 1468\n",
      "Accuracy: 0.77\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.55699722, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        ]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.71547619, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        ]), array([ 811,    2,   15,    1,   60,    5,    8,    6,   56,    2,    5,\n",
      "          1,   52,    1,    1,  280,    1,    2,   36,    6,    4,    6,\n",
      "          5,   10,    1,    1,   13,    5,    1,    8,  103,    3,    4,\n",
      "          1,    3,   35,    4,   14,   21,   15,    3,   38,    4,  221,\n",
      "          3,    2,    7,    1,   14,    2,    1,   18,    1,    5,    1,\n",
      "         56,   34,    2,    8,    3,    8,    7,    9,   23,    3,    5,\n",
      "          9,   13,    1,   26,   16,   18,    7,    1,   19,   57,   26,\n",
      "          4,   15,    1,    1,    8,   10,    5,  375, 3606,   18,   13,\n",
      "        113,    1,    1,   10,    8,    5]))\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                          0.00      0.00      0.00       811\n",
      "            algeria       0.00      0.00      0.00         2\n",
      "          argentina       0.00      0.00      0.00        15\n",
      "              aruba       0.00      0.00      0.00         1\n",
      "          australia       0.00      0.00      0.00        60\n",
      "            austria       0.00      0.00      0.00         5\n",
      "            bahrain       0.00      0.00      0.00         8\n",
      "         bangladesh       0.00      0.00      0.00         6\n",
      "            belgium       0.00      0.00      0.00        56\n",
      "            bermuda       0.00      0.00      0.00         2\n",
      "            bolivia       0.00      0.00      0.00         5\n",
      "           botswana       0.00      0.00      0.00         1\n",
      "             brazil       0.00      0.00      0.00        52\n",
      "              burma       0.00      0.00      0.00         1\n",
      "           cameroon       0.00      0.00      0.00         1\n",
      "             canada       0.00      0.00      0.00       280\n",
      "               chad       0.00      0.00      0.00         1\n",
      "              chile       0.00      0.00      0.00         2\n",
      "              china       0.00      0.00      0.00        36\n",
      "           colombia       0.00      0.00      0.00         6\n",
      "         costa-rica       0.00      0.00      0.00         4\n",
      "               cuba       0.00      0.00      0.00         6\n",
      "             cyprus       0.00      0.00      0.00         5\n",
      "            denmark       0.00      0.00      0.00        10\n",
      " dominican-republic       0.00      0.00      0.00         1\n",
      "       east-germany       0.00      0.00      0.00         1\n",
      "            ecuador       0.00      0.00      0.00        13\n",
      "              egypt       0.00      0.00      0.00         5\n",
      "               fiji       0.00      0.00      0.00         1\n",
      "            finland       0.00      0.00      0.00         8\n",
      "             france       0.00      0.00      0.00       103\n",
      "              ghana       0.00      0.00      0.00         3\n",
      "             greece       0.00      0.00      0.00         4\n",
      "             guyana       0.00      0.00      0.00         1\n",
      "              haiti       0.00      0.00      0.00         3\n",
      "          hong-kong       0.00      0.00      0.00        35\n",
      "            hungary       0.00      0.00      0.00         4\n",
      "              india       0.00      0.00      0.00        14\n",
      "          indonesia       0.00      0.00      0.00        21\n",
      "               iran       0.00      0.00      0.00        15\n",
      "               iraq       0.00      0.00      0.00         3\n",
      "              italy       0.00      0.00      0.00        38\n",
      "        ivory-coast       0.00      0.00      0.00         4\n",
      "              japan       0.00      0.00      0.00       221\n",
      "             jordan       0.00      0.00      0.00         3\n",
      "              kenya       0.00      0.00      0.00         2\n",
      "             kuwait       0.00      0.00      0.00         7\n",
      "            lebanon       0.00      0.00      0.00         1\n",
      "         luxembourg       0.00      0.00      0.00        14\n",
      "         madagascar       0.00      0.00      0.00         2\n",
      "             malawi       0.00      0.00      0.00         1\n",
      "           malaysia       0.00      0.00      0.00        18\n",
      "          mauritius       0.00      0.00      0.00         1\n",
      "             mexico       0.00      0.00      0.00         5\n",
      "            morocco       0.00      0.00      0.00         1\n",
      "        netherlands       0.00      0.00      0.00        56\n",
      "        new-zealand       0.00      0.00      0.00        34\n",
      "          nicaragua       0.00      0.00      0.00         2\n",
      "            nigeria       0.00      0.00      0.00         8\n",
      "        north-korea       0.00      0.00      0.00         3\n",
      "             norway       0.00      0.00      0.00         8\n",
      "           pakistan       0.00      0.00      0.00         7\n",
      "               peru       0.00      0.00      0.00         9\n",
      "        philippines       0.00      0.00      0.00        23\n",
      "             poland       0.00      0.00      0.00         3\n",
      "           portugal       0.00      0.00      0.00         5\n",
      "       saudi-arabia       0.00      0.00      0.00         9\n",
      "          singapore       0.00      0.00      0.00        13\n",
      "            somalia       0.00      0.00      0.00         1\n",
      "       south-africa       0.00      0.00      0.00        26\n",
      "        south-korea       0.00      0.00      0.00        16\n",
      "              spain       0.00      0.00      0.00        18\n",
      "          sri-lanka       0.00      0.00      0.00         7\n",
      "              sudan       0.00      0.00      0.00         1\n",
      "             sweden       0.00      0.00      0.00        19\n",
      "        switzerland       0.00      0.00      0.00        57\n",
      "             taiwan       0.00      0.00      0.00        26\n",
      "           tanzania       0.00      0.00      0.00         4\n",
      "           thailand       0.00      0.00      0.00        15\n",
      "               togo       0.00      0.00      0.00         1\n",
      "            tunisia       0.00      0.00      0.00         1\n",
      "             turkey       0.00      0.00      0.00         8\n",
      "                uae       0.00      0.00      0.00        10\n",
      "             uganda       0.00      0.00      0.00         5\n",
      "                 uk       0.00      0.00      0.00       375\n",
      "                usa       0.56      1.00      0.72      3606\n",
      "               ussr       0.00      0.00      0.00        18\n",
      "          venezuela       0.00      0.00      0.00        13\n",
      "       west-germany       0.00      0.00      0.00       113\n",
      "yemen-arab-republic       0.00      0.00      0.00         1\n",
      "yemen-demo-republic       0.00      0.00      0.00         1\n",
      "         yugoslavia       0.00      0.00      0.00        10\n",
      "             zambia       0.00      0.00      0.00         8\n",
      "           zimbabwe       0.00      0.00      0.00         5\n",
      "\n",
      "           accuracy                           0.56      6474\n",
      "          macro avg       0.01      0.01      0.01      6474\n",
      "       weighted avg       0.31      0.56      0.40      6474\n",
      "\n",
      "Bons résultats 3606\n",
      "Erreurs: 2868\n",
      "Accuracy: 0.56\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "[[528   0   1 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  1   0  11 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   3   0   0]\n",
      " [  2   0   0 ...   0   1   0]\n",
      " [  5   0   0 ...   0   0   0]]\n",
      "(array([0.65346535, 0.        , 0.34375   , 0.        , 0.39393939,\n",
      "       0.        , 0.125     , 0.09090909, 0.23880597, 0.        ,\n",
      "       0.125     , 0.        , 0.41935484, 0.        , 0.        ,\n",
      "       0.36498516, 0.5       , 0.        , 0.36111111, 0.83333333,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.5       , 0.        , 0.        , 0.25      ,\n",
      "       0.43956044, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.33333333, 0.        , 0.4       , 0.58333333, 0.85714286,\n",
      "       0.        , 0.28571429, 0.25      , 0.        , 0.54787234,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.25      ,\n",
      "       1.        , 0.        , 0.44444444, 0.        , 0.        ,\n",
      "       0.        , 0.56      , 0.81818182, 0.        , 1.        ,\n",
      "       0.        , 0.5       , 0.66666667, 0.        , 0.44444444,\n",
      "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
      "       0.77777778, 0.42857143, 0.57142857, 1.        , 0.        ,\n",
      "       0.85714286, 0.79310345, 0.46666667, 0.        , 0.5       ,\n",
      "       0.        , 0.        , 0.33333333, 0.5       , 0.        ,\n",
      "       0.58333333, 0.80598122, 0.6       , 0.33333333, 0.50980392,\n",
      "       0.        , 0.        , 1.        , 1.        , 0.        ]), array([0.65104809, 0.        , 0.73333333, 0.        , 0.43333333,\n",
      "       0.        , 0.125     , 0.16666667, 0.28571429, 0.        ,\n",
      "       0.4       , 0.        , 0.5       , 0.        , 0.        ,\n",
      "       0.43928571, 1.        , 0.        , 0.36111111, 0.83333333,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.38461538, 0.        , 0.        , 0.125     ,\n",
      "       0.38834951, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.14285714, 0.        , 0.14285714, 0.66666667, 0.4       ,\n",
      "       0.        , 0.21052632, 0.25      , 0.        , 0.46606335,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.07142857,\n",
      "       0.5       , 0.        , 0.22222222, 0.        , 0.        ,\n",
      "       0.        , 0.25      , 0.26470588, 0.        , 0.375     ,\n",
      "       0.        , 0.125     , 0.28571429, 0.        , 0.34782609,\n",
      "       0.        , 0.        , 0.        , 0.38461538, 0.        ,\n",
      "       0.53846154, 0.1875    , 0.22222222, 0.28571429, 0.        ,\n",
      "       0.31578947, 0.40350877, 0.26923077, 0.        , 0.13333333,\n",
      "       0.        , 0.        , 0.5       , 0.1       , 0.        ,\n",
      "       0.48533333, 0.90432612, 0.16666667, 0.07692308, 0.2300885 ,\n",
      "       0.        , 0.        , 0.3       , 0.125     , 0.        ]), array([0.65225448, 0.        , 0.46808511, 0.        , 0.41269841,\n",
      "       0.        , 0.125     , 0.11764706, 0.2601626 , 0.        ,\n",
      "       0.19047619, 0.        , 0.45614035, 0.        , 0.        ,\n",
      "       0.3987034 , 0.66666667, 0.        , 0.36111111, 0.83333333,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.43478261, 0.        , 0.        , 0.16666667,\n",
      "       0.41237113, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.2       , 0.        , 0.21052632, 0.62222222, 0.54545455,\n",
      "       0.        , 0.24242424, 0.25      , 0.        , 0.50366748,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.11111111,\n",
      "       0.66666667, 0.        , 0.2962963 , 0.        , 0.        ,\n",
      "       0.        , 0.34567901, 0.4       , 0.        , 0.54545455,\n",
      "       0.        , 0.2       , 0.4       , 0.        , 0.3902439 ,\n",
      "       0.        , 0.        , 0.        , 0.55555556, 0.        ,\n",
      "       0.63636364, 0.26086957, 0.32      , 0.44444444, 0.        ,\n",
      "       0.46153846, 0.53488372, 0.34146341, 0.        , 0.21052632,\n",
      "       0.        , 0.        , 0.4       , 0.16666667, 0.        ,\n",
      "       0.52983988, 0.85232619, 0.26086957, 0.125     , 0.31707317,\n",
      "       0.        , 0.        , 0.46153846, 0.22222222, 0.        ]), array([ 811,    2,   15,    1,   60,    5,    8,    6,   56,    2,    5,\n",
      "          1,   52,    1,    1,  280,    1,    2,   36,    6,    4,    6,\n",
      "          5,   10,    1,    1,   13,    5,    1,    8,  103,    3,    4,\n",
      "          1,    3,   35,    4,   14,   21,   15,    3,   38,    4,    0,\n",
      "        221,    3,    2,    7,    1,   14,    2,    1,   18,    1,    5,\n",
      "          1,   56,   34,    2,    8,    3,    8,    7,    9,   23,    3,\n",
      "          5,    9,   13,    1,   26,   16,   18,    7,    1,   19,   57,\n",
      "         26,    4,   15,    1,    1,    8,   10,    5,  375, 3606,   18,\n",
      "         13,  113,    1,    1,   10,    8,    5]))\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                          0.65      0.65      0.65       811\n",
      "            algeria       0.00      0.00      0.00         2\n",
      "          argentina       0.34      0.73      0.47        15\n",
      "              aruba       0.00      0.00      0.00         1\n",
      "          australia       0.39      0.43      0.41        60\n",
      "            austria       0.00      0.00      0.00         5\n",
      "            bahrain       0.12      0.12      0.12         8\n",
      "         bangladesh       0.09      0.17      0.12         6\n",
      "            belgium       0.24      0.29      0.26        56\n",
      "            bermuda       0.00      0.00      0.00         2\n",
      "            bolivia       0.12      0.40      0.19         5\n",
      "           botswana       0.00      0.00      0.00         1\n",
      "             brazil       0.42      0.50      0.46        52\n",
      "              burma       0.00      0.00      0.00         1\n",
      "           cameroon       0.00      0.00      0.00         1\n",
      "             canada       0.36      0.44      0.40       280\n",
      "               chad       0.50      1.00      0.67         1\n",
      "              chile       0.00      0.00      0.00         2\n",
      "              china       0.36      0.36      0.36        36\n",
      "           colombia       0.83      0.83      0.83         6\n",
      "         costa-rica       0.00      0.00      0.00         4\n",
      "               cuba       0.00      0.00      0.00         6\n",
      "             cyprus       0.00      0.00      0.00         5\n",
      "            denmark       0.00      0.00      0.00        10\n",
      " dominican-republic       0.00      0.00      0.00         1\n",
      "       east-germany       0.00      0.00      0.00         1\n",
      "            ecuador       0.50      0.38      0.43        13\n",
      "              egypt       0.00      0.00      0.00         5\n",
      "               fiji       0.00      0.00      0.00         1\n",
      "            finland       0.25      0.12      0.17         8\n",
      "             france       0.44      0.39      0.41       103\n",
      "              ghana       0.00      0.00      0.00         3\n",
      "             greece       0.00      0.00      0.00         4\n",
      "             guyana       0.00      0.00      0.00         1\n",
      "              haiti       0.00      0.00      0.00         3\n",
      "          hong-kong       0.33      0.14      0.20        35\n",
      "            hungary       0.00      0.00      0.00         4\n",
      "              india       0.40      0.14      0.21        14\n",
      "          indonesia       0.58      0.67      0.62        21\n",
      "               iran       0.86      0.40      0.55        15\n",
      "               iraq       0.00      0.00      0.00         3\n",
      "              italy       0.29      0.21      0.24        38\n",
      "        ivory-coast       0.25      0.25      0.25         4\n",
      "            jamaica       0.00      0.00      0.00         0\n",
      "              japan       0.55      0.47      0.50       221\n",
      "             jordan       0.00      0.00      0.00         3\n",
      "              kenya       0.00      0.00      0.00         2\n",
      "             kuwait       0.00      0.00      0.00         7\n",
      "            lebanon       0.00      0.00      0.00         1\n",
      "         luxembourg       0.25      0.07      0.11        14\n",
      "         madagascar       1.00      0.50      0.67         2\n",
      "             malawi       0.00      0.00      0.00         1\n",
      "           malaysia       0.44      0.22      0.30        18\n",
      "          mauritius       0.00      0.00      0.00         1\n",
      "             mexico       0.00      0.00      0.00         5\n",
      "            morocco       0.00      0.00      0.00         1\n",
      "        netherlands       0.56      0.25      0.35        56\n",
      "        new-zealand       0.82      0.26      0.40        34\n",
      "          nicaragua       0.00      0.00      0.00         2\n",
      "            nigeria       1.00      0.38      0.55         8\n",
      "        north-korea       0.00      0.00      0.00         3\n",
      "             norway       0.50      0.12      0.20         8\n",
      "           pakistan       0.67      0.29      0.40         7\n",
      "               peru       0.00      0.00      0.00         9\n",
      "        philippines       0.44      0.35      0.39        23\n",
      "             poland       0.00      0.00      0.00         3\n",
      "           portugal       0.00      0.00      0.00         5\n",
      "       saudi-arabia       0.00      0.00      0.00         9\n",
      "          singapore       1.00      0.38      0.56        13\n",
      "            somalia       0.00      0.00      0.00         1\n",
      "       south-africa       0.78      0.54      0.64        26\n",
      "        south-korea       0.43      0.19      0.26        16\n",
      "              spain       0.57      0.22      0.32        18\n",
      "          sri-lanka       1.00      0.29      0.44         7\n",
      "              sudan       0.00      0.00      0.00         1\n",
      "             sweden       0.86      0.32      0.46        19\n",
      "        switzerland       0.79      0.40      0.53        57\n",
      "             taiwan       0.47      0.27      0.34        26\n",
      "           tanzania       0.00      0.00      0.00         4\n",
      "           thailand       0.50      0.13      0.21        15\n",
      "               togo       0.00      0.00      0.00         1\n",
      "            tunisia       0.00      0.00      0.00         1\n",
      "             turkey       0.33      0.50      0.40         8\n",
      "                uae       0.50      0.10      0.17        10\n",
      "             uganda       0.00      0.00      0.00         5\n",
      "                 uk       0.58      0.49      0.53       375\n",
      "                usa       0.81      0.90      0.85      3606\n",
      "               ussr       0.60      0.17      0.26        18\n",
      "          venezuela       0.33      0.08      0.12        13\n",
      "       west-germany       0.51      0.23      0.32       113\n",
      "yemen-arab-republic       0.00      0.00      0.00         1\n",
      "yemen-demo-republic       0.00      0.00      0.00         1\n",
      "         yugoslavia       1.00      0.30      0.46        10\n",
      "             zambia       1.00      0.12      0.22         8\n",
      "           zimbabwe       0.00      0.00      0.00         5\n",
      "\n",
      "           accuracy                           0.70      6474\n",
      "          macro avg       0.28      0.18      0.20      6474\n",
      "       weighted avg       0.68      0.70      0.68      6474\n",
      "\n",
      "Bons résultats 4529\n",
      "Erreurs: 1945\n",
      "Accuracy: 0.70\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_size : 0.3, Pretraitement: ponctuation\n",
      "LogisticRegression()\n",
      "[[415   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  3   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  3   0   0 ...   0   0   0]\n",
      " [  1   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "(array([0.34354305, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.34920635, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.5270936 , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.55828221,\n",
      "       0.70547514, 0.        , 0.        , 0.66666667, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        ]), array([0.51171393, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.15714286, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.01941748, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.4841629 , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.24266667,\n",
      "       0.93261231, 0.        , 0.        , 0.01769912, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        ]), array([0.4110946 , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.21674877, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.03738318, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.50471698, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.33828996,\n",
      "       0.80329631, 0.        , 0.        , 0.03448276, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        ]), array([ 811,    2,   15,    1,   60,    5,    8,    6,   56,    2,    5,\n",
      "          1,   52,    1,    1,  280,    1,    2,   36,    6,    4,    6,\n",
      "          5,   10,    1,    1,   13,    5,    1,    8,  103,    3,    4,\n",
      "          1,    3,   35,    4,   14,   21,   15,    3,   38,    4,  221,\n",
      "          3,    2,    7,    1,   14,    2,    1,   18,    1,    5,    1,\n",
      "         56,   34,    2,    8,    3,    8,    7,    9,   23,    3,    5,\n",
      "          9,   13,    1,   26,   16,   18,    7,    1,   19,   57,   26,\n",
      "          4,   15,    1,    1,    8,   10,    5,  375, 3606,   18,   13,\n",
      "        113,    1,    1,   10,    8,    5]))\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                          0.34      0.51      0.41       811\n",
      "            algeria       0.00      0.00      0.00         2\n",
      "          argentina       0.00      0.00      0.00        15\n",
      "              aruba       0.00      0.00      0.00         1\n",
      "          australia       0.00      0.00      0.00        60\n",
      "            austria       0.00      0.00      0.00         5\n",
      "            bahrain       0.00      0.00      0.00         8\n",
      "         bangladesh       0.00      0.00      0.00         6\n",
      "            belgium       0.00      0.00      0.00        56\n",
      "            bermuda       0.00      0.00      0.00         2\n",
      "            bolivia       0.00      0.00      0.00         5\n",
      "           botswana       0.00      0.00      0.00         1\n",
      "             brazil       0.00      0.00      0.00        52\n",
      "              burma       0.00      0.00      0.00         1\n",
      "           cameroon       0.00      0.00      0.00         1\n",
      "             canada       0.35      0.16      0.22       280\n",
      "               chad       0.00      0.00      0.00         1\n",
      "              chile       0.00      0.00      0.00         2\n",
      "              china       0.00      0.00      0.00        36\n",
      "           colombia       0.00      0.00      0.00         6\n",
      "         costa-rica       0.00      0.00      0.00         4\n",
      "               cuba       0.00      0.00      0.00         6\n",
      "             cyprus       0.00      0.00      0.00         5\n",
      "            denmark       0.00      0.00      0.00        10\n",
      " dominican-republic       0.00      0.00      0.00         1\n",
      "       east-germany       0.00      0.00      0.00         1\n",
      "            ecuador       0.00      0.00      0.00        13\n",
      "              egypt       0.00      0.00      0.00         5\n",
      "               fiji       0.00      0.00      0.00         1\n",
      "            finland       0.00      0.00      0.00         8\n",
      "             france       0.50      0.02      0.04       103\n",
      "              ghana       0.00      0.00      0.00         3\n",
      "             greece       0.00      0.00      0.00         4\n",
      "             guyana       0.00      0.00      0.00         1\n",
      "              haiti       0.00      0.00      0.00         3\n",
      "          hong-kong       0.00      0.00      0.00        35\n",
      "            hungary       0.00      0.00      0.00         4\n",
      "              india       0.00      0.00      0.00        14\n",
      "          indonesia       0.00      0.00      0.00        21\n",
      "               iran       0.00      0.00      0.00        15\n",
      "               iraq       0.00      0.00      0.00         3\n",
      "              italy       0.00      0.00      0.00        38\n",
      "        ivory-coast       0.00      0.00      0.00         4\n",
      "              japan       0.53      0.48      0.50       221\n",
      "             jordan       0.00      0.00      0.00         3\n",
      "              kenya       0.00      0.00      0.00         2\n",
      "             kuwait       0.00      0.00      0.00         7\n",
      "            lebanon       0.00      0.00      0.00         1\n",
      "         luxembourg       0.00      0.00      0.00        14\n",
      "         madagascar       0.00      0.00      0.00         2\n",
      "             malawi       0.00      0.00      0.00         1\n",
      "           malaysia       0.00      0.00      0.00        18\n",
      "          mauritius       0.00      0.00      0.00         1\n",
      "             mexico       0.00      0.00      0.00         5\n",
      "            morocco       0.00      0.00      0.00         1\n",
      "        netherlands       0.00      0.00      0.00        56\n",
      "        new-zealand       0.00      0.00      0.00        34\n",
      "          nicaragua       0.00      0.00      0.00         2\n",
      "            nigeria       0.00      0.00      0.00         8\n",
      "        north-korea       0.00      0.00      0.00         3\n",
      "             norway       0.00      0.00      0.00         8\n",
      "           pakistan       0.00      0.00      0.00         7\n",
      "               peru       0.00      0.00      0.00         9\n",
      "        philippines       0.00      0.00      0.00        23\n",
      "             poland       0.00      0.00      0.00         3\n",
      "           portugal       0.00      0.00      0.00         5\n",
      "       saudi-arabia       0.00      0.00      0.00         9\n",
      "          singapore       0.00      0.00      0.00        13\n",
      "            somalia       0.00      0.00      0.00         1\n",
      "       south-africa       0.00      0.00      0.00        26\n",
      "        south-korea       0.00      0.00      0.00        16\n",
      "              spain       0.00      0.00      0.00        18\n",
      "          sri-lanka       0.00      0.00      0.00         7\n",
      "              sudan       0.00      0.00      0.00         1\n",
      "             sweden       0.00      0.00      0.00        19\n",
      "        switzerland       0.00      0.00      0.00        57\n",
      "             taiwan       0.00      0.00      0.00        26\n",
      "           tanzania       0.00      0.00      0.00         4\n",
      "           thailand       0.00      0.00      0.00        15\n",
      "               togo       0.00      0.00      0.00         1\n",
      "            tunisia       0.00      0.00      0.00         1\n",
      "             turkey       0.00      0.00      0.00         8\n",
      "                uae       0.00      0.00      0.00        10\n",
      "             uganda       0.00      0.00      0.00         5\n",
      "                 uk       0.56      0.24      0.34       375\n",
      "                usa       0.71      0.93      0.80      3606\n",
      "               ussr       0.00      0.00      0.00        18\n",
      "          venezuela       0.00      0.00      0.00        13\n",
      "       west-germany       0.67      0.02      0.03       113\n",
      "yemen-arab-republic       0.00      0.00      0.00         1\n",
      "yemen-demo-republic       0.00      0.00      0.00         1\n",
      "         yugoslavia       0.00      0.00      0.00        10\n",
      "             zambia       0.00      0.00      0.00         8\n",
      "           zimbabwe       0.00      0.00      0.00         5\n",
      "\n",
      "           accuracy                           0.62      6474\n",
      "          macro avg       0.04      0.03      0.02      6474\n",
      "       weighted avg       0.52      0.62      0.55      6474\n",
      "\n",
      "Bons résultats 4024\n",
      "Erreurs: 2450\n",
      "Accuracy: 0.62\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "[[554   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   6 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   7   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "(array([0.86292835, 0.        , 1.        , 0.        , 0.7804878 ,\n",
      "       0.        , 1.        , 0.8       , 0.76190476, 0.        ,\n",
      "       1.        , 0.        , 0.82222222, 0.        , 0.        ,\n",
      "       0.74264706, 0.        , 0.        , 0.90322581, 1.        ,\n",
      "       0.        , 1.        , 0.        , 0.66666667, 0.        ,\n",
      "       0.        , 0.6875    , 1.        , 0.        , 1.        ,\n",
      "       0.74603175, 0.        , 1.        , 0.        , 0.        ,\n",
      "       1.        , 1.        , 1.        , 0.9047619 , 1.        ,\n",
      "       0.        , 1.        , 0.        , 0.76842105, 0.        ,\n",
      "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
      "       0.        , 0.83333333, 0.        , 1.        , 0.        ,\n",
      "       0.93333333, 0.95238095, 0.        , 0.        , 0.        ,\n",
      "       1.        , 1.        , 1.        , 0.875     , 0.        ,\n",
      "       0.        , 0.66666667, 1.        , 0.        , 1.        ,\n",
      "       0.9       , 0.875     , 0.        , 0.        , 1.        ,\n",
      "       0.90909091, 0.80769231, 1.        , 0.8       , 0.        ,\n",
      "       0.        , 1.        , 1.        , 1.        , 0.77380952,\n",
      "       0.75364182, 1.        , 0.8       , 0.79166667, 0.        ,\n",
      "       0.        , 1.        , 0.        , 0.        ]), array([0.68310727, 0.        , 0.4       , 0.        , 0.53333333,\n",
      "       0.        , 0.125     , 0.66666667, 0.28571429, 0.        ,\n",
      "       0.2       , 0.        , 0.71153846, 0.        , 0.        ,\n",
      "       0.36071429, 0.        , 0.        , 0.77777778, 0.83333333,\n",
      "       0.        , 0.16666667, 0.        , 0.2       , 0.        ,\n",
      "       0.        , 0.84615385, 0.2       , 0.        , 0.25      ,\n",
      "       0.45631068, 0.        , 0.25      , 0.        , 0.        ,\n",
      "       0.2       , 0.25      , 0.07142857, 0.9047619 , 0.13333333,\n",
      "       0.        , 0.42105263, 0.        , 0.66063348, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.07142857, 0.        ,\n",
      "       0.        , 0.55555556, 0.        , 0.2       , 0.        ,\n",
      "       0.5       , 0.58823529, 0.        , 0.        , 0.        ,\n",
      "       0.125     , 0.14285714, 0.11111111, 0.60869565, 0.        ,\n",
      "       0.        , 0.22222222, 0.38461538, 0.        , 0.5       ,\n",
      "       0.5625    , 0.38888889, 0.        , 0.        , 0.15789474,\n",
      "       0.52631579, 0.80769231, 0.5       , 0.26666667, 0.        ,\n",
      "       0.        , 0.25      , 0.3       , 0.2       , 0.52      ,\n",
      "       0.97559623, 0.27777778, 0.61538462, 0.50442478, 0.        ,\n",
      "       0.        , 0.7       , 0.        , 0.        ]), array([0.76256022, 0.        , 0.57142857, 0.        , 0.63366337,\n",
      "       0.        , 0.22222222, 0.72727273, 0.41558442, 0.        ,\n",
      "       0.33333333, 0.        , 0.7628866 , 0.        , 0.        ,\n",
      "       0.48557692, 0.        , 0.        , 0.8358209 , 0.90909091,\n",
      "       0.        , 0.28571429, 0.        , 0.30769231, 0.        ,\n",
      "       0.        , 0.75862069, 0.33333333, 0.        , 0.4       ,\n",
      "       0.56626506, 0.        , 0.4       , 0.        , 0.        ,\n",
      "       0.33333333, 0.4       , 0.13333333, 0.9047619 , 0.23529412,\n",
      "       0.        , 0.59259259, 0.        , 0.71046229, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.13333333, 0.        ,\n",
      "       0.        , 0.66666667, 0.        , 0.33333333, 0.        ,\n",
      "       0.65116279, 0.72727273, 0.        , 0.        , 0.        ,\n",
      "       0.22222222, 0.25      , 0.2       , 0.71794872, 0.        ,\n",
      "       0.        , 0.33333333, 0.55555556, 0.        , 0.66666667,\n",
      "       0.69230769, 0.53846154, 0.        , 0.        , 0.27272727,\n",
      "       0.66666667, 0.80769231, 0.66666667, 0.4       , 0.        ,\n",
      "       0.        , 0.4       , 0.46153846, 0.33333333, 0.62200957,\n",
      "       0.85037467, 0.43478261, 0.69565217, 0.61621622, 0.        ,\n",
      "       0.        , 0.82352941, 0.        , 0.        ]), array([ 811,    2,   15,    1,   60,    5,    8,    6,   56,    2,    5,\n",
      "          1,   52,    1,    1,  280,    1,    2,   36,    6,    4,    6,\n",
      "          5,   10,    1,    1,   13,    5,    1,    8,  103,    3,    4,\n",
      "          1,    3,   35,    4,   14,   21,   15,    3,   38,    4,  221,\n",
      "          3,    2,    7,    1,   14,    2,    1,   18,    1,    5,    1,\n",
      "         56,   34,    2,    8,    3,    8,    7,    9,   23,    3,    5,\n",
      "          9,   13,    1,   26,   16,   18,    7,    1,   19,   57,   26,\n",
      "          4,   15,    1,    1,    8,   10,    5,  375, 3606,   18,   13,\n",
      "        113,    1,    1,   10,    8,    5]))\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                          0.86      0.68      0.76       811\n",
      "            algeria       0.00      0.00      0.00         2\n",
      "          argentina       1.00      0.40      0.57        15\n",
      "              aruba       0.00      0.00      0.00         1\n",
      "          australia       0.78      0.53      0.63        60\n",
      "            austria       0.00      0.00      0.00         5\n",
      "            bahrain       1.00      0.12      0.22         8\n",
      "         bangladesh       0.80      0.67      0.73         6\n",
      "            belgium       0.76      0.29      0.42        56\n",
      "            bermuda       0.00      0.00      0.00         2\n",
      "            bolivia       1.00      0.20      0.33         5\n",
      "           botswana       0.00      0.00      0.00         1\n",
      "             brazil       0.82      0.71      0.76        52\n",
      "              burma       0.00      0.00      0.00         1\n",
      "           cameroon       0.00      0.00      0.00         1\n",
      "             canada       0.74      0.36      0.49       280\n",
      "               chad       0.00      0.00      0.00         1\n",
      "              chile       0.00      0.00      0.00         2\n",
      "              china       0.90      0.78      0.84        36\n",
      "           colombia       1.00      0.83      0.91         6\n",
      "         costa-rica       0.00      0.00      0.00         4\n",
      "               cuba       1.00      0.17      0.29         6\n",
      "             cyprus       0.00      0.00      0.00         5\n",
      "            denmark       0.67      0.20      0.31        10\n",
      " dominican-republic       0.00      0.00      0.00         1\n",
      "       east-germany       0.00      0.00      0.00         1\n",
      "            ecuador       0.69      0.85      0.76        13\n",
      "              egypt       1.00      0.20      0.33         5\n",
      "               fiji       0.00      0.00      0.00         1\n",
      "            finland       1.00      0.25      0.40         8\n",
      "             france       0.75      0.46      0.57       103\n",
      "              ghana       0.00      0.00      0.00         3\n",
      "             greece       1.00      0.25      0.40         4\n",
      "             guyana       0.00      0.00      0.00         1\n",
      "              haiti       0.00      0.00      0.00         3\n",
      "          hong-kong       1.00      0.20      0.33        35\n",
      "            hungary       1.00      0.25      0.40         4\n",
      "              india       1.00      0.07      0.13        14\n",
      "          indonesia       0.90      0.90      0.90        21\n",
      "               iran       1.00      0.13      0.24        15\n",
      "               iraq       0.00      0.00      0.00         3\n",
      "              italy       1.00      0.42      0.59        38\n",
      "        ivory-coast       0.00      0.00      0.00         4\n",
      "              japan       0.77      0.66      0.71       221\n",
      "             jordan       0.00      0.00      0.00         3\n",
      "              kenya       0.00      0.00      0.00         2\n",
      "             kuwait       0.00      0.00      0.00         7\n",
      "            lebanon       0.00      0.00      0.00         1\n",
      "         luxembourg       1.00      0.07      0.13        14\n",
      "         madagascar       0.00      0.00      0.00         2\n",
      "             malawi       0.00      0.00      0.00         1\n",
      "           malaysia       0.83      0.56      0.67        18\n",
      "          mauritius       0.00      0.00      0.00         1\n",
      "             mexico       1.00      0.20      0.33         5\n",
      "            morocco       0.00      0.00      0.00         1\n",
      "        netherlands       0.93      0.50      0.65        56\n",
      "        new-zealand       0.95      0.59      0.73        34\n",
      "          nicaragua       0.00      0.00      0.00         2\n",
      "            nigeria       0.00      0.00      0.00         8\n",
      "        north-korea       0.00      0.00      0.00         3\n",
      "             norway       1.00      0.12      0.22         8\n",
      "           pakistan       1.00      0.14      0.25         7\n",
      "               peru       1.00      0.11      0.20         9\n",
      "        philippines       0.88      0.61      0.72        23\n",
      "             poland       0.00      0.00      0.00         3\n",
      "           portugal       0.00      0.00      0.00         5\n",
      "       saudi-arabia       0.67      0.22      0.33         9\n",
      "          singapore       1.00      0.38      0.56        13\n",
      "            somalia       0.00      0.00      0.00         1\n",
      "       south-africa       1.00      0.50      0.67        26\n",
      "        south-korea       0.90      0.56      0.69        16\n",
      "              spain       0.88      0.39      0.54        18\n",
      "          sri-lanka       0.00      0.00      0.00         7\n",
      "              sudan       0.00      0.00      0.00         1\n",
      "             sweden       1.00      0.16      0.27        19\n",
      "        switzerland       0.91      0.53      0.67        57\n",
      "             taiwan       0.81      0.81      0.81        26\n",
      "           tanzania       1.00      0.50      0.67         4\n",
      "           thailand       0.80      0.27      0.40        15\n",
      "               togo       0.00      0.00      0.00         1\n",
      "            tunisia       0.00      0.00      0.00         1\n",
      "             turkey       1.00      0.25      0.40         8\n",
      "                uae       1.00      0.30      0.46        10\n",
      "             uganda       1.00      0.20      0.33         5\n",
      "                 uk       0.77      0.52      0.62       375\n",
      "                usa       0.75      0.98      0.85      3606\n",
      "               ussr       1.00      0.28      0.43        18\n",
      "          venezuela       0.80      0.62      0.70        13\n",
      "       west-germany       0.79      0.50      0.62       113\n",
      "yemen-arab-republic       0.00      0.00      0.00         1\n",
      "yemen-demo-republic       0.00      0.00      0.00         1\n",
      "         yugoslavia       1.00      0.70      0.82        10\n",
      "             zambia       0.00      0.00      0.00         8\n",
      "           zimbabwe       0.00      0.00      0.00         5\n",
      "\n",
      "           accuracy                           0.77      6474\n",
      "          macro avg       0.51      0.24      0.30      6474\n",
      "       weighted avg       0.78      0.77      0.75      6474\n",
      "\n",
      "Bons résultats 5011\n",
      "Erreurs: 1463\n",
      "Accuracy: 0.77\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for pretraitement in [\"stopwords\", \"ponctuation\"]:\n",
    "    if pretraitement ==\"stopwords\":\n",
    "        liste_pretraite = [remove_stopwords(j) for j in texte]\n",
    "        X = V.fit_transform(liste_pretraite)\n",
    "    elif pretraitement ==\"ponctuation\":\n",
    "        liste_titres_pretraite = [remove_ponctuation(j) for j in texte]\n",
    "        X = V.fit_transform(liste_pretraite)    \n",
    "    else:\n",
    "        X = V.fit_transform(texte)\n",
    "    for split_size in [0.3]: #[0.1, 0.2, 0.3, 0.9]:\n",
    "        print(f\"Split_size : {split_size}, Pretraitement: {pretraitement}\")\n",
    "    #découpage train VS test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = split_size, random_state=0)\n",
    "    ##classification\n",
    "        for i in liste:\n",
    "            i = i.fit(X_train, y_train)\n",
    "            y_pred = i.predict(X_test)\n",
    "            matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "            print(i)\n",
    "            print(matrice_confusion)\n",
    "            stats = precision_recall_fscore_support(y_test, y_pred)\n",
    "            print(stats)\n",
    "            report = classification_report(y_test, y_pred)\n",
    "            print(report)\n",
    "            print('Bons résultats %d' % (y_test == y_pred).sum())\n",
    "            print('Erreurs: %d' % (y_test != y_pred).sum())\n",
    "            print ('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "            print(\"-\"*10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
