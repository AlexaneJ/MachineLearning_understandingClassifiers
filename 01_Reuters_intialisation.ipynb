{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<body>Sample One</body>, <body>Sample Two</body>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "s = \"\"\"<!DOCTYPE lewis SYSTEM \"lewis.dtd\"> \n",
    " <TEXT> \n",
    " <TITLE>One</TITLE> \n",
    " <BODY>Sample One</BODY> \n",
    " </TEXT> \n",
    " <TEXT> \n",
    " <TITLE>Two</TITLE> \n",
    " <BODY>Sample Two</BODY> \n",
    " </TEXT>\"\"\" \n",
    "soup = BeautifulSoup(s,'html.parser') \n",
    "soup.find_all('body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dic_expes_spams.json', 'Scikitlearn_Avance.ipynb', 'spamham.csv', '1001964.pdf', 'entra√Ænement', 'V1_rapport', 'Methodo_projet.pdf', 'Notes.odt', 'AlexaneJOUGLAR_V1.zip', 'Test_Classification_amelioration.ipynb', 'tweets.ipynb', 'tweet_sample(2).ipynb', 'tweet_sample.ipynb', 'Spam_ham', 'TD_formatPDF', 'Reuters', 'Reuters.ipynb', 'Tweets(2).ipynb', 'Tweets', 'SpamHam.ipynb', 'report_classifier=perceptron_dataset=spam.txt', 'Notes_notions.odt']\n"
     ]
    }
   ],
   "source": [
    "print(glob.glob('*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Reuters/reuters21578/reut2-000.sgm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for line in open('Reuters/reuters21578/reut2-000.sgm', 'rb').readlines():\n",
    "    line = line.decode('utf-8','ignore')\n",
    "    lines.append(line)\n",
    "xml_data = '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9-APR-1987 00:00:00.00'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "date_pattern = re.compile(r'[0-9]+-[A-Z]{3}-[0-9]{4} [0-9]{2}:[0-9]{2}:[0-9]{2}\\.[0-9]+')\n",
    "date_pattern.findall('9-APR-1987 00:00:00.00    # date added by S Finch as guesswork')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from lxml import objectify\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReutersSGMLParser():\n",
    "    \"\"\"A helper class for parsing Reuters-21578 XGML file formats\"\"\"\n",
    "    def __init__(self):\n",
    "        self.bad_char_pattern = re.compile(r\"&#\\d*;\")\n",
    "        self.document_pattern = re.compile(r\"<REUTERS.*?<\\/REUTERS>\", re.S)\n",
    "        self.date_pattern = re.compile(r'[0-9]+-[A-Z]{3}-[0-9]{4} *[0-9]{2}:[0-9]{2}:[0-9]{2}\\.[0-9]+')\n",
    "\n",
    "    def empty_row(self):\n",
    "        \"\"\"Get an empty rows which can be transformed into a dataframe\"\"\"\n",
    "        rows = {\n",
    "            'old_id'     : [],\n",
    "            'new_id'     : [],\n",
    "            'has_topics' : [],\n",
    "            'date'       : [],\n",
    "            'topics'     : [],\n",
    "            'places'     : [],\n",
    "            'people'     : [],\n",
    "            'orgs'       : [],\n",
    "            'exchanges'  : [],\n",
    "            'companies'  : [],\n",
    "            'title'      : [],\n",
    "            'dateline'   : [],\n",
    "            'body'       : [],\n",
    "            'author'     : [],\n",
    "            'cgi_split'  : [],\n",
    "            'lewis_split': []\n",
    "        }\n",
    "        return rows\n",
    "\n",
    "    def get_text(self, elem, tagname, d_tag = False):\n",
    "        \"\"\"Get the text of a tag or empty string\"\"\"\n",
    "        txt = getattr(elem, tagname, '')\n",
    "        if txt == '':\n",
    "            return ''\n",
    "        if d_tag:\n",
    "            txt = txt.D\n",
    "        txt = txt.text.strip()\n",
    "        return txt\n",
    "\n",
    "    def get_date(self, elem, tagname):\n",
    "        \"\"\"Get the datetime of a tag or empty string\"\"\"\n",
    "        date_str = getattr(elem, tagname, '')\n",
    "        if date_str == '':\n",
    "            return ''\n",
    "        date_str = date_str.text.strip()\n",
    "        try:\n",
    "            date_str = self.date_pattern.findall(date_str)[0]\n",
    "        except IndexError as ie:\n",
    "            print('Cannot find date patter in: %s' % date_str)\n",
    "            return ''\n",
    "        date = datetime.strptime(date_str, '%d-%b-%Y %H:%M:%S.%f')\n",
    "        return date\n",
    "\n",
    "    def parse_header(self, rows, doc):\n",
    "        \"\"\"parse the header.\n",
    "        e.g. <REUTERS TOPICS=\"YES\" LEWISSPLIT=\"TRAIN\" CGISPLIT=\"TRAINING-SET\" OLDID=\"5544\" NEWID=\"1\">\"\"\"\n",
    "        items = dict(doc.items())\n",
    "        rows[   'old_id'  ].append(items.get('OLDID', ''))\n",
    "        rows[   'new_id'  ].append(items.get('NEWID', ''))\n",
    "        rows[ 'has_topics'].append(bool(items.get('TOPICS', '')))\n",
    "        rows[ 'cgi_split' ].append(items.get('CGISPLIT', ''))\n",
    "        rows['lewis_split'].append(items.get('LEWISSPLIT', ''))\n",
    "\n",
    "    def parse_string(self, str):\n",
    "        # remove bad characters\n",
    "        xml_data = self.bad_char_pattern.sub('', str)\n",
    "        # find documents\n",
    "        documents = self.document_pattern.findall(xml_data)\n",
    "        # parse document's elements\n",
    "        rows = self.empty_row()\n",
    "        for doc in documents:\n",
    "            xml_doc = objectify.fromstring(doc)\n",
    "            # parse attributes of the header\n",
    "            self.parse_header(rows, xml_doc)\n",
    "            # read DATE\n",
    "            rows[  'date'  ].append(self.get_date(xml_doc, 'DATE'))\n",
    "            # read TOPICS\n",
    "            rows[  'topics'  ].append(self.get_text(xml_doc,'TOPICS', True))\n",
    "            # read PLACES\n",
    "            rows[  'places'  ].append(self.get_text(xml_doc, 'PLACES', True))\n",
    "            # read PEOPLE\n",
    "            rows[ 'people'  ].append(self.get_text(xml_doc, 'PEOPLE', True))\n",
    "            # read ORGS\n",
    "            rows[ 'orgs'  ].append(self.get_text(xml_doc, 'ORGS', True))\n",
    "            # read EXCHANGES\n",
    "            rows[ 'exchanges'  ].append(self.get_text(xml_doc, 'EXCHANGES', True))\n",
    "            # read COMPANIES\n",
    "            rows[ 'companies'  ].append(self.get_text(xml_doc, 'COMPANIES', True))\n",
    "            # read the TEXT tag\n",
    "            text = xml_doc.TEXT\n",
    "            rows[ 'title'  ].append(self.get_text(text, 'TITLE'))\n",
    "            rows['dateline'].append(self.get_text(text, 'DATELINE'))\n",
    "            rows[  'body'  ].append(self.get_text(text, 'BODY'))\n",
    "            rows[  'author'  ].append(self.get_text(text, 'AUTHOR'))\n",
    "        return rows\n",
    "\n",
    "    def parse(self, path):\n",
    "        \"\"\"parse a file from the Reuters dataset\n",
    "        \"\"\"\n",
    "        # open xml file\n",
    "        xml_data = ''\n",
    "        try:\n",
    "            xml_data = open(path, 'r', encoding=\"utf-8\").read()\n",
    "        except UnicodeDecodeError as ude:\n",
    "            print('Failed to read %s as utf-8' % path)\n",
    "            lines = []\n",
    "            for line in open(path, 'rb').readlines():\n",
    "                line = line.decode('utf-8','ignore') #.encode(\"utf-8\")\n",
    "                lines.append(line)\n",
    "            xml_data = '\\n'.join(lines)\n",
    "        return self.parse_string(xml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_id</th>\n",
       "      <th>new_id</th>\n",
       "      <th>has_topics</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>places</th>\n",
       "      <th>people</th>\n",
       "      <th>orgs</th>\n",
       "      <th>exchanges</th>\n",
       "      <th>companies</th>\n",
       "      <th>title</th>\n",
       "      <th>dateline</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>cgi_split</th>\n",
       "      <th>lewis_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5544</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1987-02-26 15:01:01.790</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>el-salvador</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>BAHIA COCOA REVIEW</td>\n",
       "      <td>SALVADOR, Feb 26 -</td>\n",
       "      <td>Showers continued throughout the week in\\nthe ...</td>\n",
       "      <td></td>\n",
       "      <td>TRAINING-SET</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5545</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1987-02-26 15:02:20.000</td>\n",
       "      <td></td>\n",
       "      <td>usa</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>STANDARD OIL &lt;SRD&gt; TO FORM FINANCIAL UNIT</td>\n",
       "      <td>CLEVELAND, Feb 26 -</td>\n",
       "      <td>Standard Oil Co and BP North America\\nInc said...</td>\n",
       "      <td></td>\n",
       "      <td>TRAINING-SET</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5546</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1987-02-26 15:03:27.510</td>\n",
       "      <td></td>\n",
       "      <td>usa</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>TEXAS COMMERCE BANCSHARES &lt;TCB&gt; FILES PLAN</td>\n",
       "      <td>HOUSTON, Feb 26 -</td>\n",
       "      <td>Texas Commerce Bancshares Inc's Texas\\nCommerc...</td>\n",
       "      <td></td>\n",
       "      <td>TRAINING-SET</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5547</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1987-02-26 15:07:13.720</td>\n",
       "      <td></td>\n",
       "      <td>usa</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>TALKING POINT/BANKAMERICA &lt;BAC&gt; EQUITY OFFER</td>\n",
       "      <td>LOS ANGELES, Feb 26 -</td>\n",
       "      <td>BankAmerica Corp is not under\\npressure to act...</td>\n",
       "      <td>by Janie Gabbett, Reuters</td>\n",
       "      <td>TRAINING-SET</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5548</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>1987-02-26 15:10:44.600</td>\n",
       "      <td>grain</td>\n",
       "      <td>usa</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NATIONAL AVERAGE PRICES FOR FARMER-OWNED RESERVE</td>\n",
       "      <td>WASHINGTON, Feb 26 -</td>\n",
       "      <td>The U.S. Agriculture Department\\nreported the ...</td>\n",
       "      <td></td>\n",
       "      <td>TRAINING-SET</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  old_id new_id  has_topics                    date topics       places  \\\n",
       "0   5544      1        True 1987-02-26 15:01:01.790  cocoa  el-salvador   \n",
       "1   5545      2        True 1987-02-26 15:02:20.000                 usa   \n",
       "2   5546      3        True 1987-02-26 15:03:27.510                 usa   \n",
       "3   5547      4        True 1987-02-26 15:07:13.720                 usa   \n",
       "4   5548      5        True 1987-02-26 15:10:44.600  grain          usa   \n",
       "\n",
       "  people orgs exchanges companies  \\\n",
       "0                                   \n",
       "1                                   \n",
       "2                                   \n",
       "3                                   \n",
       "4                                   \n",
       "\n",
       "                                              title               dateline  \\\n",
       "0                                BAHIA COCOA REVIEW     SALVADOR, Feb 26 -   \n",
       "1         STANDARD OIL <SRD> TO FORM FINANCIAL UNIT    CLEVELAND, Feb 26 -   \n",
       "2        TEXAS COMMERCE BANCSHARES <TCB> FILES PLAN      HOUSTON, Feb 26 -   \n",
       "3      TALKING POINT/BANKAMERICA <BAC> EQUITY OFFER  LOS ANGELES, Feb 26 -   \n",
       "4  NATIONAL AVERAGE PRICES FOR FARMER-OWNED RESERVE   WASHINGTON, Feb 26 -   \n",
       "\n",
       "                                                body  \\\n",
       "0  Showers continued throughout the week in\\nthe ...   \n",
       "1  Standard Oil Co and BP North America\\nInc said...   \n",
       "2  Texas Commerce Bancshares Inc's Texas\\nCommerc...   \n",
       "3  BankAmerica Corp is not under\\npressure to act...   \n",
       "4  The U.S. Agriculture Department\\nreported the ...   \n",
       "\n",
       "                      author     cgi_split lewis_split  \n",
       "0                             TRAINING-SET       TRAIN  \n",
       "1                             TRAINING-SET       TRAIN  \n",
       "2                             TRAINING-SET       TRAIN  \n",
       "3  by Janie Gabbett, Reuters  TRAINING-SET       TRAIN  \n",
       "4                             TRAINING-SET       TRAIN  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ReutersSGMLParser()\n",
    "data = parser.empty_row()\n",
    "for path in  ['Reuters/reuters21578/reut2-00.sgm']:\n",
    "    # parse current document\n",
    "    rows = parser.parse(path)\n",
    "    # append rows into dataset\n",
    "    for key in data.keys():\n",
    "        data[key] = data[key] + rows[key]\n",
    "\n",
    "df = pd.DataFrame(data, columns=data.keys())\n",
    "#df = df.astype(dtype= {\"date\":\"datetime64[]\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['usa', 'italy', 'canada', 'uk', 'switzerland', 'kenya', 'zimbabwe', 'belgium', 'sweden', 'netherlands', 'ussr', 'south-africa', 'syria', 'venezuela', 'chile', 'japan', 'nigeria', '', 'denmark', 'uganda', 'finland', 'west-germany', 'colombia', 'peru', 'brazil', 'france', 'iran', 'singapore', 'greece', 'spain', 'dominican-republic', 'sri-lanka', 'luxembourg', 'jamaica', 'poland', 'argentina', 'turkey', 'austria', 'australia', 'taiwan', 'bolivia', 'suriname', 'ivory-coast', 'new-zealand', 'hong-kong', 'bahrain', 'china', 'south-korea', 'indonesia', 'thailand', 'pakistan', 'india', 'papua-new-guinea', 'uae', 'egypt', 'tanzania', 'zambia', 'iraq', 'morocco', 'cuba', 'mexico', 'costa-rica', 'ecuador', 'algeria', 'malaysia', 'bangladesh', 'philippines', 'saudi-arabia', 'angola', 'ghana', 'yemen-arab-republic', 'hungary', 'portugal', 'israel', 'jordan', 'bulgaria', 'norway', 'burma', 'haiti', 'aruba', 'yugoslavia', 'cyprus', 'madagascar', 'ethiopia', 'nicaragua', 'guyana', 'east-germany', 'kuwait', 'lebanon', 'zaire', 'iceland', 'sudan', 'north-korea', 'panama', 'bermuda', 'chad', 'malawi', 'somalia', 'sierra-leone', 'ireland', 'trinidad-tobago', 'vietnam', 'libya', 'tunisia', 'botswana', 'mauritius', 'el-salvador', 'mozambique', 'cameroon', 'qatar', 'barbados', 'togo', 'fiji', 'uruguay', 'yemen-demo-republic']\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "pays = []\n",
    "for i in df.places:\n",
    "    if i not in pays:\n",
    "        pays.append(i)\n",
    "print(pays)\n",
    "print(len(pays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elargissement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Liste = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to read Reuters/reuters21578/reut2-017.sgm as utf-8\n",
      "Cannot find date patter in: 31-MAR-1987 605:12:19.12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_id</th>\n",
       "      <th>new_id</th>\n",
       "      <th>has_topics</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>places</th>\n",
       "      <th>people</th>\n",
       "      <th>orgs</th>\n",
       "      <th>exchanges</th>\n",
       "      <th>companies</th>\n",
       "      <th>title</th>\n",
       "      <th>dateline</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>cgi_split</th>\n",
       "      <th>lewis_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16321</td>\n",
       "      <td>1001</td>\n",
       "      <td>True</td>\n",
       "      <td>1987-03-03 09:18:21.260</td>\n",
       "      <td></td>\n",
       "      <td>usa</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SANDOZ PLANS WEEDKILLER JOINT VENTURE IN USSR</td>\n",
       "      <td>BASLE, March 3 -</td>\n",
       "      <td>Sandoz AG said it planned a joint venture\\nto ...</td>\n",
       "      <td></td>\n",
       "      <td>TRAINING-SET</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16322</td>\n",
       "      <td>1002</td>\n",
       "      <td>True</td>\n",
       "      <td>1987-03-03 09:19:31.960</td>\n",
       "      <td></td>\n",
       "      <td>usa</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>TAIWAN REJECTS TEXTILE MAKERS EXCHANGE RATE PLEA</td>\n",
       "      <td>TAIPEI, March 3 -</td>\n",
       "      <td>Central bank governor Chang Chi-cheng\\nrejecte...</td>\n",
       "      <td></td>\n",
       "      <td>TRAINING-SET</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16323</td>\n",
       "      <td>1003</td>\n",
       "      <td>True</td>\n",
       "      <td>1987-03-03 09:20:23.320</td>\n",
       "      <td>earn</td>\n",
       "      <td>usa</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NATIONAL FSI INC &lt;NFSI&gt; 4TH QTR LOSS</td>\n",
       "      <td>DALLAS, March 3 -</td>\n",
       "      <td>Shr loss six cts vs profit 19 cts\\n    Net los...</td>\n",
       "      <td></td>\n",
       "      <td>TRAINING-SET</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16324</td>\n",
       "      <td>1004</td>\n",
       "      <td>True</td>\n",
       "      <td>1987-03-03 09:21:39.110</td>\n",
       "      <td></td>\n",
       "      <td>usa</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>OCCIDENTAL &lt;OXY&gt; OFFICIAL RESIGNS</td>\n",
       "      <td>LOMBARD, Ill., March 3 -</td>\n",
       "      <td>MidCon Corp, a subsidiary of\\nOccidental Petro...</td>\n",
       "      <td></td>\n",
       "      <td>TRAINING-SET</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16325</td>\n",
       "      <td>1005</td>\n",
       "      <td>True</td>\n",
       "      <td>1987-03-03 09:25:48.880</td>\n",
       "      <td></td>\n",
       "      <td>italy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ITALY'S BNL TO ISSUE 120 MLN DLR CONVERTIBLE BOND</td>\n",
       "      <td>ROME, March 3 -</td>\n",
       "      <td>Italy's state-owned &lt;Banca Nazionale del\\nLavo...</td>\n",
       "      <td></td>\n",
       "      <td>TRAINING-SET</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  old_id new_id  has_topics                    date topics places people orgs  \\\n",
       "0  16321   1001        True 1987-03-03 09:18:21.260           usa               \n",
       "1  16322   1002        True 1987-03-03 09:19:31.960           usa               \n",
       "2  16323   1003        True 1987-03-03 09:20:23.320   earn    usa               \n",
       "3  16324   1004        True 1987-03-03 09:21:39.110           usa               \n",
       "4  16325   1005        True 1987-03-03 09:25:48.880         italy               \n",
       "\n",
       "  exchanges companies                                              title  \\\n",
       "0                          SANDOZ PLANS WEEDKILLER JOINT VENTURE IN USSR   \n",
       "1                       TAIWAN REJECTS TEXTILE MAKERS EXCHANGE RATE PLEA   \n",
       "2                                   NATIONAL FSI INC <NFSI> 4TH QTR LOSS   \n",
       "3                                      OCCIDENTAL <OXY> OFFICIAL RESIGNS   \n",
       "4                      ITALY'S BNL TO ISSUE 120 MLN DLR CONVERTIBLE BOND   \n",
       "\n",
       "                   dateline  \\\n",
       "0          BASLE, March 3 -   \n",
       "1         TAIPEI, March 3 -   \n",
       "2         DALLAS, March 3 -   \n",
       "3  LOMBARD, Ill., March 3 -   \n",
       "4           ROME, March 3 -   \n",
       "\n",
       "                                                body author     cgi_split  \\\n",
       "0  Sandoz AG said it planned a joint venture\\nto ...         TRAINING-SET   \n",
       "1  Central bank governor Chang Chi-cheng\\nrejecte...         TRAINING-SET   \n",
       "2  Shr loss six cts vs profit 19 cts\\n    Net los...         TRAINING-SET   \n",
       "3  MidCon Corp, a subsidiary of\\nOccidental Petro...         TRAINING-SET   \n",
       "4  Italy's state-owned <Banca Nazionale del\\nLavo...         TRAINING-SET   \n",
       "\n",
       "  lewis_split  \n",
       "0       TRAIN  \n",
       "1       TRAIN  \n",
       "2       TRAIN  \n",
       "3       TRAIN  \n",
       "4       TRAIN  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ReutersSGMLParser()\n",
    "data = parser.empty_row()\n",
    "for j in Liste :\n",
    "    for path in  ['Reuters/reuters21578/reut2-0%i.sgm'%j]:\n",
    "    # parse current document\n",
    "        rows = parser.parse(path)\n",
    "    # append rows into dataset\n",
    "        for key in data.keys():\n",
    "            data[key] = data[key] + rows[key]\n",
    "\n",
    "df = pd.DataFrame(data, columns=data.keys())\n",
    "#df = df.astype(dtype= {\"date\":\"datetime64[]\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Sandoz AG said it planned a joint venture\\nto ...\n",
       "1        Central bank governor Chang Chi-cheng\\nrejecte...\n",
       "2        Shr loss six cts vs profit 19 cts\\n    Net los...\n",
       "3        MidCon Corp, a subsidiary of\\nOccidental Petro...\n",
       "4        Italy's state-owned <Banca Nazionale del\\nLavo...\n",
       "                               ...                        \n",
       "20573    The Japan/India-Pakistan-Gulf/Japan\\nshipping ...\n",
       "20574    The Soviet Union's industrial output is\\ngrowi...\n",
       "20575    Six black miners have been killed\\nand two inj...\n",
       "20576    The prospect of a dominant alliance of\\nsocial...\n",
       "20577    The American Stock Exchange said it has\\nintro...\n",
       "Name: body, Length: 20578, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#il y a 20578 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 usa\n",
       "1                 usa\n",
       "2                 usa\n",
       "3                 usa\n",
       "4               italy\n",
       "             ...     \n",
       "20573       hong-kong\n",
       "20574            ussr\n",
       "20575    south-africa\n",
       "20576     switzerland\n",
       "20577             usa\n",
       "Name: places, Length: 20578, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['usa', 'italy', 'canada', 'uk', 'switzerland', 'kenya', 'zimbabwe', 'belgium', 'sweden', 'netherlands', 'ussr', 'south-africa', 'syria', 'venezuela', 'chile', 'japan', 'nigeria', '', 'denmark', 'uganda', 'finland', 'west-germany', 'colombia', 'peru', 'brazil', 'france', 'iran', 'singapore', 'greece', 'spain', 'dominican-republic', 'sri-lanka', 'luxembourg', 'jamaica', 'poland', 'argentina', 'turkey', 'austria', 'australia', 'taiwan', 'bolivia', 'suriname', 'ivory-coast', 'new-zealand', 'hong-kong', 'bahrain', 'china', 'south-korea', 'indonesia', 'thailand', 'pakistan', 'india', 'papua-new-guinea', 'uae', 'egypt', 'tanzania', 'zambia', 'iraq', 'morocco', 'cuba', 'mexico', 'costa-rica', 'ecuador', 'algeria', 'malaysia', 'bangladesh', 'philippines', 'saudi-arabia', 'angola', 'ghana', 'yemen-arab-republic', 'hungary', 'portugal', 'israel', 'jordan', 'bulgaria', 'norway', 'burma', 'haiti', 'aruba', 'yugoslavia', 'cyprus', 'madagascar', 'ethiopia', 'nicaragua', 'guyana', 'east-germany', 'kuwait', 'lebanon', 'zaire', 'iceland', 'sudan', 'north-korea', 'panama', 'bermuda', 'chad', 'malawi', 'somalia', 'sierra-leone', 'ireland', 'trinidad-tobago', 'vietnam', 'libya', 'tunisia', 'botswana', 'mauritius', 'el-salvador', 'mozambique', 'cameroon', 'qatar', 'barbados', 'togo', 'fiji', 'uruguay', 'yemen-demo-republic']\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "pays = []\n",
    "for i in df.places:\n",
    "    if i not in pays:\n",
    "        pays.append(i)\n",
    "print(pays)\n",
    "print(len(pays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lieu = []\n",
    "for i in df.places:\n",
    "    lieu.append(i)\n",
    "#print(lieu)\n",
    "#print(type(lieu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Sandoz AG said it planned a joint venture\\nto ...\n",
       "1        Central bank governor Chang Chi-cheng\\nrejecte...\n",
       "2        Shr loss six cts vs profit 19 cts\\n    Net los...\n",
       "3        MidCon Corp, a subsidiary of\\nOccidental Petro...\n",
       "4        Italy's state-owned <Banca Nazionale del\\nLavo...\n",
       "                               ...                        \n",
       "20573    The Japan/India-Pakistan-Gulf/Japan\\nshipping ...\n",
       "20574    The Soviet Union's industrial output is\\ngrowi...\n",
       "20575    Six black miners have been killed\\nand two inj...\n",
       "20576    The prospect of a dominant alliance of\\nsocial...\n",
       "20577    The American Stock Exchange said it has\\nintro...\n",
       "Name: body, Length: 20578, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20578\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "texte = []\n",
    "for j in df.body:\n",
    "    texte.append(j)\n",
    "print(len(texte))\n",
    "print(type(texte))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
